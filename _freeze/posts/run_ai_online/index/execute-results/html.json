{
  "hash": "88f7352da9faa3ea081fb647ed6ceae3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Run AI model online\"\n\nauthor: \"Tony D\"\ndate: \"2025-03-18\"\n\ncategories: \n  - AI\n  - R\n  - Python\n  \nimage: \"images/S__6840322.jpg\"\n\nexecute:\n  warning: false\n  error: false\n  eval: false\n---\n\nrun LLM model online with ellmer or chatter\n\n# ellmer for R\n\n::: {.cell}\n\n```{.r .cell-code}\npak::pkg_install('ellmer')\nlibrary(ellmer)\n```\n:::\n## google gemini\n\nget text from pdf\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nread_lines('story.txt')[1:5] |> \n  stringr::str_wrap(width = 50) |> \n  paste(collapse = '\\n') |> \n  paste('...') |> \n  cat()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ellmer)\nchat <- chat_openai(\n  system_prompt = \"\n  You are an information extractor AI.\n  The user will give you a story and you will \n  provide the following information in the response:\n  \n  Name of main character: <Insert name here>\n  \n  Names of supporting characters: <Insert comma-\n    separated list of names here>\n  \n  One-Sentence Summary: <Insert summary here. \n    Use one sentence only>\n  \n  Lesson learned: <Summarize what the hero \n    learned in two sentences>\n  \"\n)\n## Using model = \"gpt-4o\".\n```\n:::\n\n\n\n\n\n\n\n\n## ollama on local\n\n### set up ollama local\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ollamar)\nollamar::pull(\"llama3.1\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nollamar::list_models()\n```\n:::\n\n### difine model\n\n::: {.cell}\n\n```{.r .cell-code}\nchat=chat_ollama(\n  system_prompt = NULL,\n  turns = NULL,\n  base_url = \"http://localhost:11434\",\n  model=\"llama3.1\",\n  seed = NULL,\n  api_args = list(),\n  echo = NULL\n)\n\nchat$get_model()\n```\n:::\n\n\n### run LLM\n\n::: {.cell}\n\n```{.r .cell-code}\nchat$chat(\"Tell me three jokes about statisticians\")\n```\n:::\n\n### run on console\n\n::: {.cell}\n\n```{.r .cell-code}\nlive_console(chat)\n```\n:::\n\n![](images/clipboard-52512780.png){width=\"700\"}\n\n### check token usage\n\n::: {.cell}\n\n```{.r .cell-code}\ntoken_usage()\n```\n:::\n\n\n\n\n# chattr LLM pacakge for R\n\n## Step 1 Install package\n\n::: {.cell}\n\n```{.r .cell-code}\n#remotes::install_github(\"mlverse/chattr\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(chattr)\n```\n:::\n\n# Step 2 set key\n\n-   Login at https://platform.openai.com/\n\n-   Goto Settings (gear icon on top right)\n\n-   Find API Keys from menu on left\n\n-   Follow the process to Create new secret key\n\n-   Copy your secret key (it will only show once so make sure you copy it)\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(OpenAI_API_KEY=\"sk-xxxxxxxx\")\n```\n:::\n\n## Step 3 run ChatGPT as background job\n\n### select model\n\n::: {.cell}\n\n```{.r .cell-code}\n#copilot do not need OpenAI_API_KEY\nchattr_use(\"copilot\")\n```\n:::\n\n### add prompt\n\n::: {.cell}\n\n```{.r .cell-code}\nchattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n```\n:::\n\n### run ChatGPT as background jobs\n\nDo not use Copilot (GitHub) model for chattr(). Github will block this behavior.\n\n::: {.cell}\n\n```{.r .cell-code}\n# run \nchattr_app(as_job = TRUE)\n```\n:::\n\n![](images/clipboard-495301195.png)\n\nDone!\n\n![](https://blogs.rstudio.com/ai/posts/2024-04-04-chat-with-llms-using-chattr/images/buttons.png)\n\n## Or setup auto open Chat GPT when Rstudio start\n\n### Step 1 find Rprofile file\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"usethis\")  # Install if not already installed\nusethis::edit_r_profile()\n```\n:::\n\n### Step 2 edit Rprofile file as below\n\n::: {.cell filename='.RProfile'}\n\n```{.r .cell-code}\n#|eval: false\n# Load chattr app after RStudio is fully loaded\nsetHook(\"rstudio.sessionInit\", function(newSession) {\n  if (newSession) {\n    Sys.sleep(2)  # Wait 2 seconds before starting chattr to ensure RStudio is ready\n    tryCatch({\n      library(chattr)\n      chattr_use(\"copilot\")\n      #Sys.setenv(\"OPENAI_API_KEY\" = \"your-api-key-here\")\n      chattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n\n      chattr_app(as_job = TRUE)\n    }, error = function(e)\n      message(\"Error starting chattr: \", e$message))\n  }\n}, action = \"append\")\n```\n:::\n\n\n# chatlas for python\n\n\nhttps://github.com/posit-dev/chatlas\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}