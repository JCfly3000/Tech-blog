[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "SQL Handbook\nThis document provides a comprehensive guide to performing common data manipulation tasks using SQL, R, and Python. It serves as a reference for understanding how to achieve similar outcomes across these three popular data analysis tools.\n\n\nR Handboook\nThis project is a comprehensive guide to the R programming language, built with Quarto. It covers a wide range of topics, from the fundamentals of R to advanced applications in data manipulation, visualization, and publishing.\n\n\nPython Handbook\na comprehensive guide to Python for data science, covering a range of topics from the fundamentals to more advanced applications.\n\n\nStat Handbook\nThis collection of documents serves as a practical guide and a series of case studies in statistical analysis and machine learning. Each section explores a different dataset and a different set of techniques, providing a hands-on approach to learning and applying these methods.\n\n\nAI Handbook\na comprehensive resource for developers and data scientists looking to harness the power of Artificial Intelligence. This Quarto-based website provides a curated collection of tutorials, guides, and practical examples for using a variety of AI tools and models in both R and Python."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This page provides a brief introduction to the author of the blog and includes a link to their GitHub profile."
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html",
    "href": "posts/youtube_yt-dlp/index.html",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "",
    "text": "A guide to using yt-dlp, a command-line tool for downloading audio and video from YouTube and other sites.\nyt-dlp is a feature-rich command-line audio/video downloader with support for thousands of sites. The project is a fork of youtube-dl based on the now inactive youtube-dlc. This guide will walk you through the installation, update, and basic usage of yt-dlp for downloading YouTube videos.\nhttps://github.com/yt-dlp/yt-dlp"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#start-download-youtube",
    "href": "posts/youtube_yt-dlp/index.html#start-download-youtube",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "Start download youtube",
    "text": "Start download youtube\n\nCommand lineRPython\n\n\n\ndownload video with chrome cookies\nyt-dlp --cookies-from-browser chrome 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video with firefox cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\nyt-dlp --cookies-from-browser firefox 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video with export cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\n\n\nget video titles\nyt-dlp --cookies-from-browser firefox --get-title 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video to mp3 format\nyt-dlp --cookies-from-browser chrome -x --audio-format mp3 --audio-quality 0 'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\ndownload video with timestamp\nyt-dlp --cookies-from-browser chrome --download-sections '*00:02-03:00' 'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\ndownload video to mp4 with timestamp\nyt-dlp -f mp4 --cookies-from-browser chrome  --download-sections '*00:02-03:00'  'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\n\n\n\n\n\n\n\n\n="
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-chrome-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-chrome-cookies",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video with chrome cookies",
    "text": "download video with chrome cookies\nyt-dlp --cookies-from-browser chrome 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-firefox-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-firefox-cookies",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video with firefox cookies",
    "text": "download video with firefox cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\nyt-dlp --cookies-from-browser firefox 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-export-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-export-cookies",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video with export cookies",
    "text": "download video with export cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#get-video-titles",
    "href": "posts/youtube_yt-dlp/index.html#get-video-titles",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "get video titles",
    "text": "get video titles\nyt-dlp --cookies-from-browser firefox --get-title 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-to-mp3-format",
    "href": "posts/youtube_yt-dlp/index.html#download-video-to-mp3-format",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video to mp3 format",
    "text": "download video to mp3 format\nyt-dlp --cookies-from-browser chrome -x --audio-format mp3 --audio-quality 0 'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-timestamp",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-timestamp",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video with timestamp",
    "text": "download video with timestamp\nyt-dlp --cookies-from-browser chrome --download-sections '*00:02-03:00' 'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-to-mp4-with-timestamp",
    "href": "posts/youtube_yt-dlp/index.html#download-video-to-mp4-with-timestamp",
    "title": "Youtube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp",
    "section": "download video to mp4 with timestamp",
    "text": "download video to mp4 with timestamp\nyt-dlp -f mp4 --cookies-from-browser chrome  --download-sections '*00:02-03:00'  'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/web_scraping_in_Python/index.html",
    "href": "posts/web_scraping_in_Python/index.html",
    "title": "Web scraping in Python",
    "section": "",
    "text": "A guide to web scraping in Python using the requests and BeautifulSoup libraries. This document outlines the basic steps and required libraries for extracting data from websites.\nThis document serves as a placeholder for a guide to web scraping in Python. It currently includes the necessary imports for the requests, BeautifulSoup, StringIO, re, and pandas libraries, indicating that the full guide will cover a comprehensive workflow for extracting and processing data from websites. The content is currently incomplete, but it sets the stage for a detailed tutorial on this topic.\nA placeholder document for demonstrating web scraping techniques using Python. It currently only includes imports for requests, BeautifulSoup, StringIO, re, and pandas, indicating an intention to use these libraries for web scraping tasks. The content is incomplete.\n\npython web scraping with requests and BeautifulSoup\n\n\nCode\nimport requests\nfrom bs4 import BeautifulSoup\nfrom io import StringIO\nimport re\nimport pandas as pd\n\n\n\n\nReference"
  },
  {
    "objectID": "posts/LLM_model/index.html",
    "href": "posts/LLM_model/index.html",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "",
    "text": "An overview of Large Language Models (LLMs) and their performance across various benchmarks, including math, code, English, and science.\nThis document provides a comprehensive overview of Large Language Models (LLMs) and their performance across a variety of benchmarks. It categorizes the performance of different models by subject area, including mathematics, coding, English language understanding, and science. The document also provides links to resources where you can compare the performance of different LLM models online.\n(LLM)Large language model\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)\nCode\ndata001=read_excel('AI model.xlsx')\nhead(data001)"
  },
  {
    "objectID": "posts/LLM_model/index.html#math",
    "href": "posts/LLM_model/index.html#math",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "math",
    "text": "math\n\nAIME\nhttps://en.wikipedia.org/wiki/American_Invitational_Mathematics_Examination\n\n\nMATH-500"
  },
  {
    "objectID": "posts/LLM_model/index.html#code",
    "href": "posts/LLM_model/index.html#code",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "Code",
    "text": "Code"
  },
  {
    "objectID": "posts/LLM_model/index.html#codeforces",
    "href": "posts/LLM_model/index.html#codeforces",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "Codeforces",
    "text": "Codeforces"
  },
  {
    "objectID": "posts/LLM_model/index.html#livecodebench",
    "href": "posts/LLM_model/index.html#livecodebench",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "LiveCodeBench",
    "text": "LiveCodeBench"
  },
  {
    "objectID": "posts/LLM_model/index.html#english",
    "href": "posts/LLM_model/index.html#english",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "English",
    "text": "English\n\nMMLU\nMeasuring Massive Multitask Language Understanding (MMLU)\nhttps://en.wikipedia.org/wiki/MMLU"
  },
  {
    "objectID": "posts/LLM_model/index.html#science",
    "href": "posts/LLM_model/index.html#science",
    "title": "ÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã",
    "section": "Science",
    "text": "Science\n\nGPQA-Diamond\nGraduate-Level Google-Proof Q&A\nDescription: GPQA consists of 448 multiple-choice questions meticulously crafted by domain experts in biology, physics, and chemistry. These questions are intentionally designed to be high-quality and extremely difficult.\nExpert Accuracy: Even experts who hold or are pursuing PhDs in the corresponding domains achieve only 65% accuracy on these questions (or 74% when excluding clear mistakes identified in retrospect).\nGoogle-Proof: The questions are ‚ÄúGoogle-proof,‚Äù meaning that even with unrestricted access to the web, highly skilled non-expert validators only reach an accuracy of 34% despite spending over 30 minutes searching for answers.\nAI Systems Difficulty: State-of-the-art AI systems, including our strongest GPT-4 based baseline, achieve only 39% accuracy on this challenging dataset."
  },
  {
    "objectID": "posts/send_email/index.html",
    "href": "posts/send_email/index.html",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "",
    "text": "A guide to sending emails programmatically using the blastula package in R, covering credential setup, email composition, and sending from Gmail and Outlook.\nThis document provides a comprehensive guide to sending emails programmatically using R and Python. For R, it focuses on the blastula package, covering the entire workflow from creating SMTP credentials for Gmail and Outlook to composing and sending emails. It also demonstrates how to render Quarto content directly into an email body. The Python section is a placeholder for future content.\nUsing R or Python to send email"
  },
  {
    "objectID": "posts/send_email/index.html#load-library",
    "href": "posts/send_email/index.html#load-library",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "load library",
    "text": "load library\n\n\nCode\nlibrary(blastula)\nlibrary(keyring)"
  },
  {
    "objectID": "posts/send_email/index.html#step-1-create-smtp-credentials",
    "href": "posts/send_email/index.html#step-1-create-smtp-credentials",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "Step 1 create smtp credentials",
    "text": "Step 1 create smtp credentials\n\ngmail\n\n\nCode\ncreate_smtp_creds_key(\n  id = \"gmail001_creds\",\n  provider = \"gmail\",\n  user = \"verykoala@gmail.com\",\n  overwrite = TRUE\n  )\n\n\n\n\noutlook\n\n\nCode\n# create_smtp_creds_key(\n#   id = \"outlook001_creds\",\n#   provider = \"outlook\",\n#   user = \"jcpartner@outlook.com\",\n#   overwrite = TRUE\n#   )\n\ncreate_smtp_creds_file(file = \"ggnot_throwaway_creds\",\n                       user = \"jcpartner@outlook.com\",\n                       provider = \"outlook\")\n\n\n\n\nCode\n#delete_credential_key(\"gmail001_creds\")\n\n\n\n\nCode\nview_credential_keys()"
  },
  {
    "objectID": "posts/send_email/index.html#step-2-email-content",
    "href": "posts/send_email/index.html#step-2-email-content",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "Step 2 email content",
    "text": "Step 2 email content\n\n\nCode\nlibrary(blastula)\nmsg=compose_email(\n  body = md(\n  \"Hi there üëã,\n  \n  This is an email to let you now thatrunning job **finished**.\n\n  Best,&lt;br&gt;\n  Tony\"\n  )\n)\n\nmsg"
  },
  {
    "objectID": "posts/send_email/index.html#step-3-send-email",
    "href": "posts/send_email/index.html#step-3-send-email",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "Step 3 send email",
    "text": "Step 3 send email\n\nsend from gmailsend from outlook\n\n\n\n\nCode\nmsg %&gt;% \n  smtp_send(\n    from = 'verykoala@gmail.com',\n    to = \"jcflyingco@outlook.com\",\n    subject = \"Testing the email function\",\n    credentials = creds_key(id = \"gmail001_creds\")\n  )\n\n\n\n\n\n\nCode\nlibrary(Microsoft365R)\noutl &lt;- get_personal_outlook()\n\n\n\n\nCode\n# list the most recent emails in your Inbox\n#outl$list_emails()\n\n\n\n\nCode\nem &lt;- outl$create_email(msg, subject=\"Hello\", to=\"jcflyingco@outlook.com\")\n\n\n\n\nCode\nem$send()"
  },
  {
    "objectID": "posts/send_email/index.html#step3-option-b-send-email-with-quarto-content",
    "href": "posts/send_email/index.html#step3-option-b-send-email-with-quarto-content",
    "title": "‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂",
    "section": "Step3 (option B) send email with quarto content",
    "text": "Step3 (option B) send email with quarto content\ncreate email Rmd file(.quarto_email.Rmd):\n\n\n\n\nCode\n\n.quarto_email.Rmd\n\n---\ntitle: \"Quarto Email\"\noutput: blastula::blastula_email \n---\n\n\n\n# tesing\n\ntesting\n\n\n# Reference:\nhttps://www.youtube.com/watch?v=PihKq1GPlcc\n\n\n\n\ncreate email\n\n\nCode\nemail_obj=render_email('.quarto_email.Rmd')\n\n\nView the email\n\n\nCode\nemail_obj\n\n\n\nsend from gmailsend from outlook\n\n\n\n\nCode\nemail_obj%&gt;% \n  smtp_send(\n    from = 'verykoala@gmail.com',\n    to = \"jcflyingco@outlook.com\",\n    subject = \"Testing the email function\",\n    credentials = creds_key(id = \"gmail001_creds\")\n  )\n\n\n\n\n\n\nCode\nem &lt;- outl$create_email(email_obj, subject=\"Hello\", to=\"jcflyingco@outlook.com\")\nem$send()"
  },
  {
    "objectID": "posts/run_ai_local/index.html",
    "href": "posts/run_ai_local/index.html",
    "title": "Êú¨Âú∞ËøêË°åAIÊ®°Âûã",
    "section": "",
    "text": "A guide to running AI models locally using Ollama and Hugging Face, with examples in R, Python, and the terminal.\nThis document provides a comprehensive guide to running AI models locally on your machine. It covers two popular platforms: Ollama and Hugging Face. For Ollama, it details the installation process and demonstrates how to manage and run LLM models using R (with the ollamar and ellmer packages), Python, and the terminal. For Hugging Face, it shows how to use models for tasks like text generation through both high-level pipelines and direct model loading in Python. The guide also includes examples of running other local models from the terminal."
  },
  {
    "objectID": "posts/run_ai_local/index.html#download-and-install-the-ollama-app",
    "href": "posts/run_ai_local/index.html#download-and-install-the-ollama-app",
    "title": "Êú¨Âú∞ËøêË°åAIÊ®°Âûã",
    "section": "Download and install the Ollama app",
    "text": "Download and install the Ollama app\nhttps://ollama.com/download\nand open the app on computer"
  },
  {
    "objectID": "posts/run_ai_local/index.html#run-llm-model-on-ollama",
    "href": "posts/run_ai_local/index.html#run-llm-model-on-ollama",
    "title": "Êú¨Âú∞ËøêË°åAIÊ®°Âûã",
    "section": "Run LLM model on Ollama",
    "text": "Run LLM model on Ollama\n\nRun in R with ollamar pacakgeRun in R with ellmer packageRun in terminal\n\n\n\ndownload pacakge check connection\n\n\nCode\npak::pak(\"ollamar\")\npak::pkg_deps_tree(\"ollamar\")\n\n\n\n\nCode\nlibrary(ollamar)\ntest_connection() \n\n\ndownload model\n\n\nCode\nollamar::pull(\"llama3.1\")\n\n\nlist downloaded model\n\n\nCode\nlist_models()\n\n\nshow model detail\n\n\nCode\nollamar::show(\"gemma3\")\n\n\nrun model\n\n\nCode\nresp &lt;- generate(\"gemma3\", \"tell me a 5-word story\")\nresp\n\n\n\n\nCode\n# get just the text from the response object\nresp_process(resp, \"text\")\n\n\n\n\nCode\n# get the text as a tibble dataframe\nresp_process(resp, \"df\")\n\n\nusing multiple models\n\n\nCode\n(list_models())$name\n\n\n\n\nCode\nmodels_name=(list_models())$name[-1]\nmodels_name\n\n\n\n\nCode\ninput_prompt=\"tell me a 5-word story\"\n\n\n\n\nCode\nall_model=c()\n\nfor (i in models_name){\n  resp &lt;- generate(i, input_prompt)\n  #print(paste0(\"Model: \", i))\n  print(resp_process(resp, \"text\"))\n  #resp_process(resp, \"df\")\n  all_model=rbind(all_model, resp_process(resp, \"df\"))\n}\n\n\n\n\nCode\nall_model\n\n\n\n\n\n\n\n\n\n\nCode\n!ollama pull llama3.1\n\n\n\n\nCode\n!ollama run llama3.1 \"tell me a 5-word story\"\n\n\n\nRun in Python\ninstall package\n\n\nCode\n!pip install ollama\n\n\nlocal pacakge\n\n\nCode\nimport json\nimport pandas as pd\nfrom pandas import json_normalize\n\n\nfrom ollama import chat\nfrom ollama import ChatResponse\nimport ollama\n\n\ndownload model\n\n\nCode\n#ollama.pull('llama3.2:1b')\n\n\nlist all download model\n\n\nCode\nollama_model=ollama.list()\n\n\n\n\nCode\n# Extracting data from the ListResponse\ndata = []\nfor model in ollama_model.models:\n    model_data = {\n        'model': model.model,\n        'modified_at': model.modified_at,\n        'digest': model.digest,\n        'size': (model.size/1000000000),\n        'parent_model': model.details.parent_model,\n        'format': model.details.format,\n        'family': model.details.family,\n        'families': model.details.families,\n        'parameter_size': model.details.parameter_size,\n        'quantization_level': model.details.quantization_level\n    }\n    data.append(model_data)\n\n# Convert the list of dictionaries into a pandas DataFrame\nollama_model_df = pd.DataFrame(data)\n\n# Show the DataFrame\nprint(ollama_model_df)\n\n\nslow model detail\n\n\nCode\nollama.show('deepseek-r1:7b-qwen-distill-q4_K_M')\n\n\ndelete model\n\n\nCode\n#ollama.delete('llama3.2:1b')\n\n\nrun model\n\n\nCode\nresponse: ChatResponse=ollama.chat(model='deepseek-r1:7b-qwen-distill-q4_K_M', messages=[\n  {'role': 'system', \n  'content': '‰Ω†ÊòØ‰∏Ä‰∏™ËØó‰∫∫Ôºå‰Ω†Âè™ËÉΩËæìÂá∫‰∏≠Êñá'},\n  \n  {'role': 'assistant', \n  'content': ''},\n  \n  {'role': 'user', \n  'content': 'give me a 3 lines story'}\n  ])\n\n\n\n\nCode\nprint(response.message.content)\n\n\n\n\nCode\nresponse: ChatResponse =ollama.chat(model='gemma3', messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n\n\n\n\nCode\nprint(response.message.content)\n\n\ncreate model\n\n\nCode\nollama.create(model='example_model', from_='llama3.2', system=\"You are Mario from Super Mario Bros.\")\n\n\npush model to ollama\n\n\nCode\nollama.push('user/example_model')"
  },
  {
    "objectID": "posts/run_ai_online/index.html",
    "href": "posts/run_ai_online/index.html",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "",
    "text": "A guide to interacting with online Large Language Models (LLMs) using R and Python, with examples for Google Gemini, local Ollama, and ChatGPT.\nThis document provides a comprehensive guide to interacting with online Large Language Models (LLMs) using both R and Python. It demonstrates how to use the ellmer and chattr packages in R, and the chatlas library in Python, to connect to various LLM services, including Google Gemini, locally hosted Ollama models, and ChatGPT. The guide covers setting up API keys, defining models, sending prompts, and processing responses for tasks like text generation and translation.\nrun LLM model online with ellmer or chatter"
  },
  {
    "objectID": "posts/run_ai_online/index.html#google-gemini",
    "href": "posts/run_ai_online/index.html#google-gemini",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "google gemini",
    "text": "google gemini\n\ngemini-2.0-flash\n\n\nCode\nchat_gemini_model=chat_gemini(\n  system_prompt = NULL,\n  turns = NULL,\n  base_url = \"https://generativelanguage.googleapis.com/v1beta/\",\n  api_key = key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  api_args = list(),\n  echo = NULL\n)\n\nchat_gemini_model\n\n\n\n\nCode\nchat_gemini_model$chat(\"Tell me three jokes about statisticians\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#ollama-on-local",
    "href": "posts/run_ai_online/index.html#ollama-on-local",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "ollama on local",
    "text": "ollama on local\n\nset up ollama local\n\n\nCode\nlibrary(ollamar)\nollamar::pull(\"llama3.1\")\n\n\n\n\nCode\nollamar::list_models()\n\n\n\n\ndifine model\n\n\nCode\nchat=chat_ollama(\n  system_prompt = NULL,\n  turns = NULL,\n  base_url = \"http://localhost:11434\",\n  model=\"llama3.1\",\n  seed = NULL,\n  api_args = list(),\n  echo = NULL\n)\n\nchat$get_model()\n\n\n\n\nrun LLM\n\n\nCode\nchat$chat(\"Tell me three jokes about statisticians\")\n\n\n\n\nrun on console\n\n\nCode\nlive_console(chat)\n\n\n\n\n\ncheck token usage\n\n\nCode\ntoken_usage()"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-1-install-package",
    "href": "posts/run_ai_online/index.html#step-1-install-package",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "Step 1 Install package",
    "text": "Step 1 Install package\n\n\nCode\n#remotes::install_github(\"mlverse/chattr\")\n\n\n\n\nCode\nlibrary(chattr)"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-2-set-key",
    "href": "posts/run_ai_online/index.html#step-2-set-key",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "Step 2 set key",
    "text": "Step 2 set key\n\nLogin at https://platform.openai.com/\nGoto Settings (gear icon on top right)\nFind API Keys from menu on left\nFollow the process to Create new secret key\nCopy your secret key (it will only show once so make sure you copy it)\n\n\n\nCode\nSys.setenv(OpenAI_API_KEY=\"sk-xxxxxxxx\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-3-run-chatgpt-as-background-job",
    "href": "posts/run_ai_online/index.html#step-3-run-chatgpt-as-background-job",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "Step 3 run ChatGPT as background job",
    "text": "Step 3 run ChatGPT as background job\n\nselect model\n\n\nCode\n#copilot do not need OpenAI_API_KEY\nchattr_use(\"copilot\")\n\n\n\n\nadd prompt\n\n\nCode\nchattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n\n\n\n\nrun ChatGPT as background jobs\nDo not use Copilot (GitHub) model for chattr(). Github will block this behavior.\n\n\nCode\n# run \nchattr_app(as_job = TRUE)\n\n\nDone!"
  },
  {
    "objectID": "posts/run_ai_online/index.html#or-setup-auto-open-chat-gpt-when-rstudio-start",
    "href": "posts/run_ai_online/index.html#or-setup-auto-open-chat-gpt-when-rstudio-start",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "Or setup auto open Chat GPT when Rstudio start",
    "text": "Or setup auto open Chat GPT when Rstudio start\n\nStep 1 find Rprofile file\n\n\nCode\n#install.packages(\"usethis\")  # Install if not already installed\nusethis::edit_r_profile()\n\n\n\n\nStep 2 edit Rprofile file as below\n\n\n\nCode\n\n.RProfile\n\n#|eval: false\n# Load chattr app after RStudio is fully loaded\nsetHook(\"rstudio.sessionInit\", function(newSession) {\n  if (newSession) {\n    Sys.sleep(2)  # Wait 2 seconds before starting chattr to ensure RStudio is ready\n    tryCatch({\n      library(chattr)\n      chattr_use(\"copilot\")\n      #Sys.setenv(\"OPENAI_API_KEY\" = \"your-api-key-here\")\n      chattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n\n      chattr_app(as_job = TRUE)\n    }, error = function(e)\n      message(\"Error starting chattr: \", e$message))\n  }\n}, action = \"append\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#gemini-model",
    "href": "posts/run_ai_online/index.html#gemini-model",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "gemini model",
    "text": "gemini model\n\n\nCode\nfrom chatlas import ChatGoogle\n\nchat_google_model = ChatGoogle(\n  model = \"gemini-2.0-flash\",\n  api_key=keyring.get_password(\"system\", \"google_ai_api_key\"),\n  system_prompt = \"You are a whisky expert\",\n)\n\nchat_google_model\n\n\n\n\nCode\nchat_google_model.chat(\"translate following whisky tasting note to English:ÂæÆÈÖ∏ÔºåËÑèÈ∫¶ËäΩ„ÄÇËè≤ÁâπËÇØËøòÊòØË¶ÅÊâæ1988\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#local-ollama-model",
    "href": "posts/run_ai_online/index.html#local-ollama-model",
    "title": "Ë∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã",
    "section": "local Ollama model",
    "text": "local Ollama model\n\n\nCode\nfrom chatlas import ChatOllama\n\nchat_llama_model = ChatOllama(\n  model=\"llama3.2\",\n  #api_key=keyring.get_password(\"system\", \"google_ai_api_key\"),\n  system_prompt = \"You are a whisky expert\",\n)\n\nchat_llama_model\n\n\n\n\nCode\nchat_llama_model.chat(\"translate following whisky tasting note to English:ÂæÆÈÖ∏ÔºåËÑèÈ∫¶ËäΩ„ÄÇËè≤ÁâπËÇØËøòÊòØË¶ÅÊâæ1988\")\n\n\n\n\nCode\ntoken_usage()"
  },
  {
    "objectID": "posts/versioncontrol/index.html",
    "href": "posts/versioncontrol/index.html",
    "title": "Version control with renv",
    "section": "",
    "text": "A guide to using the renv package in R for creating reproducible environments and managing package versions. This document covers initialization, package installation, lock file management, and Python integration.\nThis document provides a comprehensive guide to using the renv package in R for creating reproducible environments and managing package versions. It covers the entire workflow, from initializing renv in a project to installing and updating packages, managing the lock file, and even integrating renv with Python. This guide is also part of the R handbook, making it a valuable resource for anyone looking to improve the reproducibility of their R projects.\nExplains how to use the renv package in R for reproducible environments and package version management. Covers renv initialization, package installation/updates, lock file management, and Python integration.\nThe renv package helps you create reproducible environments for your R projects\nIt section also update into R handbook\n# renv for R"
  },
  {
    "objectID": "posts/versioncontrol/index.html#inital-renv-and-create-renv.lock-with-current-loaded-pacakge",
    "href": "posts/versioncontrol/index.html#inital-renv-and-create-renv.lock-with-current-loaded-pacakge",
    "title": "Version control with renv",
    "section": "inital renv and create renv.lock with current loaded pacakge",
    "text": "inital renv and create renv.lock with current loaded pacakge\n\n\nCode\nrenv::init()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#show-all-installed-pacakge",
    "href": "posts/versioncontrol/index.html#show-all-installed-pacakge",
    "title": "Version control with renv",
    "section": "show all installed pacakge",
    "text": "show all installed pacakge\n\n\nCode\ninstalled_pacakge = as.data.frame(installed.packages()[,c(1,3:4)])\ninstalled_pacakge = installed_pacakge[is.na(installed_pacakge$Priority),1:2,drop=FALSE]\ninstalled_pacakge"
  },
  {
    "objectID": "posts/versioncontrol/index.html#show-all-installed-pacakge-and-uploaded-pacakge",
    "href": "posts/versioncontrol/index.html#show-all-installed-pacakge-and-uploaded-pacakge",
    "title": "Version control with renv",
    "section": "show all installed pacakge and uploaded pacakge",
    "text": "show all installed pacakge and uploaded pacakge\n\n\nCode\nlibrary(dplyr)\ninstalled_pacakge = as.data.frame(installed.packages()[,c(1,3:4)])\ninstalled_pacakge = installed_pacakge[is.na(installed_pacakge$Priority),1:2,drop=FALSE]\ninstalled_pacakge |&gt; filter(Package %in% (.packages()))"
  },
  {
    "objectID": "posts/versioncontrol/index.html#when-using-renv-and-install-new-pakcage",
    "href": "posts/versioncontrol/index.html#when-using-renv-and-install-new-pakcage",
    "title": "Version control with renv",
    "section": "when using renv and install new pakcage",
    "text": "when using renv and install new pakcage\n\n\nCode\n# it will not work\n# library(lubridate)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#need-to-install-new-package-with-renvinstall",
    "href": "posts/versioncontrol/index.html#need-to-install-new-package-with-renvinstall",
    "title": "Version control with renv",
    "section": "need to install new package with renv::install",
    "text": "need to install new package with renv::install\n\n\nCode\nrenv::install('lubridate')\n\n\n\n\nCode\nlibrary(lubridate)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-current-package-and-renv-package",
    "href": "posts/versioncontrol/index.html#check-current-package-and-renv-package",
    "title": "Version control with renv",
    "section": "check current package and renv package",
    "text": "check current package and renv package\n\n\nCode\nrenv::status()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file",
    "href": "posts/versioncontrol/index.html#update-lock-file",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-status-again",
    "href": "posts/versioncontrol/index.html#check-status-again",
    "title": "Version control with renv",
    "section": "check status again",
    "text": "check status again\n\n\nCode\nrenv::status()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list",
    "href": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list",
    "title": "Version control with renv",
    "section": "make all current pakcage version back to renv list",
    "text": "make all current pakcage version back to renv list\n\n\nCode\nrenv::restore()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-all-pakcage-in-renv.-recommand-do-it-once-a-year-to-keep-package-updated.",
    "href": "posts/versioncontrol/index.html#update-all-pakcage-in-renv.-recommand-do-it-once-a-year-to-keep-package-updated.",
    "title": "Version control with renv",
    "section": "update all pakcage in renv. recommand do it once a year to keep package updated.",
    "text": "update all pakcage in renv. recommand do it once a year to keep package updated.\n\n\nCode\nrenv::update()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-renv-itself-only",
    "href": "posts/versioncontrol/index.html#update-renv-itself-only",
    "title": "Version control with renv",
    "section": "update renv itself only",
    "text": "update renv itself only\n\n\nCode\nrenv::upgrade()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#close-renv-in-a-project",
    "href": "posts/versioncontrol/index.html#close-renv-in-a-project",
    "title": "Version control with renv",
    "section": "close renv in a project",
    "text": "close renv in a project\n\n\nCode\nrenv::deactivate()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#re-enable-renv-in-a-project",
    "href": "posts/versioncontrol/index.html#re-enable-renv-in-a-project",
    "title": "Version control with renv",
    "section": "re enable renv in a project",
    "text": "re enable renv in a project\n\n\nCode\nrenv::activate()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#set-python-version",
    "href": "posts/versioncontrol/index.html#set-python-version",
    "title": "Version control with renv",
    "section": "set python version",
    "text": "set python version\n\n\nCode\nrenv::use_python()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-python-version-in-renv",
    "href": "posts/versioncontrol/index.html#check-python-version-in-renv",
    "title": "Version control with renv",
    "section": "check python version in renv",
    "text": "check python version in renv\n\n\nCode\nfrom sys import version as python_formatted_version\nprint(python_formatted_version)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#list-all-installed-pacakge-in-python",
    "href": "posts/versioncontrol/index.html#list-all-installed-pacakge-in-python",
    "title": "Version control with renv",
    "section": "list all installed pacakge in python",
    "text": "list all installed pacakge in python\n\n\nCode\nimport os\nprint(os.system('pip freeze'))"
  },
  {
    "objectID": "posts/versioncontrol/index.html#install-package",
    "href": "posts/versioncontrol/index.html#install-package",
    "title": "Version control with renv",
    "section": "install package",
    "text": "install package\n\n\nCode\nimport os\nos.system('python3.10 -m pip install siuba')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file-1",
    "href": "posts/versioncontrol/index.html#update-lock-file-1",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#uninstall-package",
    "href": "posts/versioncontrol/index.html#uninstall-package",
    "title": "Version control with renv",
    "section": "uninstall package",
    "text": "uninstall package\n\n\nCode\nimport os\nos.system('yes | python3.10 -m pip uninstall siuba')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list-1",
    "href": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list-1",
    "title": "Version control with renv",
    "section": "make all current pakcage version back to renv list",
    "text": "make all current pakcage version back to renv list\n\n\nCode\nrenv::restore()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#install-package-1",
    "href": "posts/versioncontrol/index.html#install-package-1",
    "title": "Version control with renv",
    "section": "install package",
    "text": "install package\n\n\nCode\nimport os\nos.system('python3.10 -m pip install requests')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file-2",
    "href": "posts/versioncontrol/index.html#update-lock-file-2",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/TidyTuesday/index.html",
    "href": "posts/TidyTuesday/index.html",
    "title": "Êï∞ÊçÆÊòüÊúü‰∫å",
    "section": "",
    "text": "A guide to the TidyTuesday data project, demonstrating how to access data and create interactive Shiny apps in both R and Python for data exploration and visualization.\nThis document provides a comprehensive guide to the TidyTuesday data project, demonstrating how to access and work with the data in both R and Python. It also includes detailed instructions on how to create interactive Shiny apps for data exploration and visualization. The guide covers everything from downloading the data to building a complete Shiny app with various plots and user inputs. This is a valuable resource for anyone looking to participate in the TidyTuesday project and improve their data science skills.\nExplores the TidyTuesday data project, demonstrating data access and interactive Shiny app creation in R and Python.\nTidyTuesday data project\ndata from github\n\ngetting the data\n\nRPython\n\n\n\n\nCode\n#pak::pak('tidytuesdayR')\n\n\n\n\nCode\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n\n\ndownload the data\nall available data\n\n\nCode\n#tt_available() \n\n\n\n\nCode\ntuesdata &lt;- tidytuesdayR::tt_load('2025-04-01')\n\n\n\n\nCode\ntuesdata\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport pydytuesday\n\n\n\n\nCode\npydytuesday.get_date('2025-04-15')\n\n\n\n\n\n\n\nmake a shiny\n\nRPython\n\n\n\nread data\n\n\nCode\ndata=tuesdata$pokemon_df\n#glimpse(data)\n\n\nor read directly from the url\n\n\nCode\ndata&lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv')\n\n\n\n\nusing shinyapps assistant to create shinyapp\nhttps://gallery.shinyapps.io/assistant\ngo to project folder and install quarto-ext/shinylive\n\n\nCode\nquarto add quarto-ext/shinylive\n\n\n\n\nPrompt:\ncreate a shinyapp with this data from github:https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv. left side: selector type_1 number of pokemon right side: histogram of height, color by type_2 histogram of weight, color by type_2 histogram of attack, color by type_2 histogram of defense color by type_2 barplot of color_1\nthere is no weight_kg,height_m.please use correct name.\n\n\nShiny R in quarto\nif adding shiny in quarto then adding this to yaml header\n---\n\nfilters:\n  - shinylive\n---\n\n\nCode\nlibrary(shiny)\nlibrary(bslib)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Load the Pokemon data\npokemon_data &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv\")\n\nui &lt;- page_sidebar(\n  title = \"Pokemon Data Explorer\",\n  sidebar = sidebar(\n    selectInput(\"type1\", \"Select Type 1:\", \n                choices = sort(unique(pokemon_data$type_1)),\n                selected = \"water\"),\n    hr(),\n    textOutput(\"pokemon_count\")\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Height Distribution by Type 2\"),\n      plotOutput(\"height_hist\")\n    ),\n    card(\n      card_header(\"Weight Distribution by Type 2\"),\n      plotOutput(\"weight_hist\")\n    )\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Attack Distribution by Type 2\"),\n      plotOutput(\"attack_hist\")\n    ),\n    card(\n      card_header(\"Defense Distribution by Type 2\"),\n      plotOutput(\"defense_hist\")\n    )\n  ),\n  \n  card(\n    card_header(\"Pokemon Color Distribution\"),\n    plotOutput(\"color_barplot\")\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # Filtered data based on the selected type_1\n  filtered_data &lt;- reactive({\n    pokemon_data %&gt;%\n      filter(type_1 == input$type1)\n  })\n  \n  # Display number of Pokemon\n  output$pokemon_count &lt;- renderText({\n    count &lt;- nrow(filtered_data())\n    paste(\"Number of Pokemon with Type 1 '\", input$type1, \"': \", count)\n  })\n  \n  # Height histogram colored by type_2\n  output$height_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = height, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Height\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Weight histogram colored by type_2\n  output$weight_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = weight, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Weight\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Attack histogram colored by type_2\n  output$attack_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = attack, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Attack\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Defense histogram colored by type_2\n  output$defense_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = defense, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Defense\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Barplot of color_1\n  output$color_barplot &lt;- renderPlot({\n    color_counts &lt;- filtered_data() %&gt;%\n      count(color_1) %&gt;%\n      arrange(desc(n))\n    \n    ggplot(color_counts, aes(x = reorder(color_1, n), y = n, fill = color_1)) +\n      geom_col() +\n      coord_flip() +\n      scale_fill_brewer(palette = \"Set3\") +\n      theme_minimal() +\n      labs(x = \"Color\", y = \"Count\", fill = \"Color\") +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui, server)\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 800\nlibrary(shiny)\nlibrary(bslib)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Load the Pokemon data\npokemon_data &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv\")\n\nui &lt;- page_sidebar(\n  title = \"Pokemon Data Explorer\",\n  sidebar = sidebar(\n    selectInput(\"type1\", \"Select Type 1:\", \n                choices = sort(unique(pokemon_data$type_1)),\n                selected = \"water\"),\n    hr(),\n    textOutput(\"pokemon_count\")\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Height Distribution by Type 2\"),\n      plotOutput(\"height_hist\")\n    ),\n    card(\n      card_header(\"Weight Distribution by Type 2\"),\n      plotOutput(\"weight_hist\")\n    )\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Attack Distribution by Type 2\"),\n      plotOutput(\"attack_hist\")\n    ),\n    card(\n      card_header(\"Defense Distribution by Type 2\"),\n      plotOutput(\"defense_hist\")\n    )\n  ),\n  \n  card(\n    card_header(\"Pokemon Color Distribution\"),\n    plotOutput(\"color_barplot\")\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # Filtered data based on the selected type_1\n  filtered_data &lt;- reactive({\n    pokemon_data %&gt;%\n      filter(type_1 == input$type1)\n  })\n  \n  # Display number of Pokemon\n  output$pokemon_count &lt;- renderText({\n    count &lt;- nrow(filtered_data())\n    paste(\"Number of Pokemon with Type 1 '\", input$type1, \"': \", count)\n  })\n  \n  # Height histogram colored by type_2\n  output$height_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = height, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Height\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Weight histogram colored by type_2\n  output$weight_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = weight, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Weight\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Attack histogram colored by type_2\n  output$attack_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = attack, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Attack\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Defense histogram colored by type_2\n  output$defense_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = defense, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Defense\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Barplot of color_1\n  output$color_barplot &lt;- renderPlot({\n    color_counts &lt;- filtered_data() %&gt;%\n      count(color_1) %&gt;%\n      arrange(desc(n))\n    \n    ggplot(color_counts, aes(x = reorder(color_1, n), y = n, fill = color_1)) +\n      geom_col() +\n      coord_flip() +\n      scale_fill_brewer(palette = \"Set3\") +\n      theme_minimal() +\n      labs(x = \"Color\", y = \"Count\", fill = \"Color\") +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui, server)\n\n\n\n\n\ninstall shiny in python\nNeed to down grade shinylive Python version to 0.7.1 in order to match shinylive R version\n\n\nCode\nimport os\nos.system(\"pip install 'shinylive==0.7.1'\")\n\n\n\n\nread data\n\n\nCode\npenguins = pd.read_csv('penguins.csv')\npenguins_raw = pd.read_csv('penguins_raw.csv')\n\n\n\n\nCode\n# Option 2: Read directly from GitHub and assign to an object\n#penguins = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n#penguins_raw = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv')\n\n\n\n\nusing shinyapps assistant to create shinyapp\nhttps://gallery.shinyapps.io/assistant\ninstall shinylive\n\n\nCode\npip install shinylive\n\n\n\n\nPrompt:\ncreate a shinyapp with this data from github:https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv.\nspecies choices is not correct,please use correct choices.\n\n\nShiny Python in quarto\nif adding shiny in quarto then adding this to yaml header\n---\n\nfilters:\n  - shinylive\n---\n\n\nCode\nfrom shiny import App, reactive, render, ui\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport urllib3\n\napp_ui = ui.page_sidebar(\n    ui.sidebar(\n        ui.h3(\"Penguin Data Explorer\"),\n        ui.input_select(\n            \"species\",\n            \"Select Penguin Species\",\n            choices=[\"All Species\", \"Adelie Penguin (Pygoscelis adeliae)\", \n                     \"Gentoo penguin (Pygoscelis papua)\", \n                     \"Chinstrap penguin (Pygoscelis antarctica)\"]\n        ),\n        ui.input_select(\n            \"plot_type\",\n            \"Select Plot Type\",\n            choices=[\n                \"Body Mass vs Flipper Length\",\n                \"Culmen Length vs Depth\",\n                \"Histogram of Body Mass\"\n            ]\n        ),\n        ui.input_checkbox_group(\n            \"islands\",\n            \"Select Islands\",\n            choices=[\"Torgersen\", \"Biscoe\", \"Dream\"],\n            selected=[\"Torgersen\", \"Biscoe\", \"Dream\"]\n        ),\n        ui.hr(),\n        ui.p(\"Data from Palmer Penguins dataset via TidyTuesday.\"),\n    ),\n    ui.card(\n        ui.card_header(\"Penguin Data Visualization\"),\n        ui.output_plot(\"penguin_plot\")\n    ),\n    ui.card(\n        ui.card_header(\"Data Summary\"),\n        ui.output_table(\"summary_table\")\n    )\n)\n\ndef server(input, output, session):\n    # Load data\n    @reactive.calc\n    def load_data():\n        http = urllib3.PoolManager()\n        url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv\"\n        \n        try:\n            response = http.request('GET', url)\n            if response.status != 200:\n                # If file not found, use fallback URL\n                fallback_url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins_raw.csv\"\n                response = http.request('GET', fallback_url)\n                \n            data = pd.read_csv(pd.io.common.StringIO(response.data.decode('utf-8')))\n            return data\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            # Return empty dataframe if there are issues\n            return pd.DataFrame()\n\n    @reactive.calc\n    def filtered_data():\n        data = load_data()\n        if data.empty:\n            return pd.DataFrame()\n        \n        # Clean column names\n        data.columns = [col.strip() for col in data.columns]\n        \n        # Filter data based on inputs\n        filtered = data.copy()\n        \n        # Filter by species\n        if input.species() != \"All Species\":\n            filtered = filtered[filtered['Species'] == input.species()]\n        \n        # Filter by islands\n        filtered = filtered[filtered['Island'].isin(input.islands())]\n        \n        return filtered\n\n    @output\n    @render.plot\n    def penguin_plot():\n        data = filtered_data()\n        if data.empty:\n            fig, ax = plt.subplots()\n            ax.text(0.5, 0.5, \"No data available or error loading data\", \n                    ha='center', va='center')\n            ax.set_xlim(0, 1)\n            ax.set_ylim(0, 1)\n            ax.axis('off')\n            return fig\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        plot_type = input.plot_type()\n        \n        if plot_type == \"Body Mass vs Flipper Length\":\n            sns.scatterplot(\n                data=data, \n                x='Flipper Length (mm)', \n                y='Body Mass (g)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Body Mass vs Flipper Length\")\n            \n        elif plot_type == \"Culmen Length vs Depth\":\n            sns.scatterplot(\n                data=data, \n                x='Culmen Length (mm)', \n                y='Culmen Depth (mm)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Culmen Length vs Depth\")\n            \n        elif plot_type == \"Histogram of Body Mass\":\n            sns.histplot(\n                data=data,\n                x='Body Mass (g)',\n                hue='Species',\n                kde=True,\n                ax=ax\n            )\n            ax.set_title(\"Distribution of Body Mass\")\n            \n        plt.tight_layout()\n        return fig\n\n    @output\n    @render.table\n    def summary_table():\n        data = filtered_data()\n        if data.empty:\n            return pd.DataFrame({'Message': ['No data available or error loading data']})\n        \n        # Create a summary table with counts by species and island\n        summary = data.groupby(['Species', 'Island', 'Sex']).size().reset_index(name='Count')\n        \n        # Add some descriptive statistics\n        stats = data.groupby(['Species']).agg({\n            'Body Mass (g)': ['mean', 'std'],\n            'Flipper Length (mm)': ['mean', 'std'],\n            'Culmen Length (mm)': ['mean', 'std'],\n            'Culmen Depth (mm)': ['mean', 'std']\n        }).round(2)\n        \n        stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n        stats = stats.reset_index()\n        \n        return summary\n\napp = App(app_ui, server)\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 800\nfrom shiny import App, reactive, render, ui\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport urllib3\n\napp_ui = ui.page_sidebar(\n    ui.sidebar(\n        ui.h3(\"Penguin Data Explorer\"),\n        ui.input_select(\n            \"species\",\n            \"Select Penguin Species\",\n            choices=[\"All Species\", \"Adelie Penguin (Pygoscelis adeliae)\", \n                     \"Gentoo penguin (Pygoscelis papua)\", \n                     \"Chinstrap penguin (Pygoscelis antarctica)\"]\n        ),\n        ui.input_select(\n            \"plot_type\",\n            \"Select Plot Type\",\n            choices=[\n                \"Body Mass vs Flipper Length\",\n                \"Culmen Length vs Depth\",\n                \"Histogram of Body Mass\"\n            ]\n        ),\n        ui.input_checkbox_group(\n            \"islands\",\n            \"Select Islands\",\n            choices=[\"Torgersen\", \"Biscoe\", \"Dream\"],\n            selected=[\"Torgersen\", \"Biscoe\", \"Dream\"]\n        ),\n        ui.hr(),\n        ui.p(\"Data from Palmer Penguins dataset via TidyTuesday.\"),\n    ),\n    ui.card(\n        ui.card_header(\"Penguin Data Visualization\"),\n        ui.output_plot(\"penguin_plot\")\n    ),\n    ui.card(\n        ui.card_header(\"Data Summary\"),\n        ui.output_table(\"summary_table\")\n    )\n)\n\ndef server(input, output, session):\n    # Load data\n    @reactive.calc\n    def load_data():\n        http = urllib3.PoolManager()\n        url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv\"\n        \n        try:\n            response = http.request('GET', url)\n            if response.status != 200:\n                # If file not found, use fallback URL\n                fallback_url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins_raw.csv\"\n                response = http.request('GET', fallback_url)\n                \n            data = pd.read_csv(pd.io.common.StringIO(response.data.decode('utf-8')))\n            return data\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            # Return empty dataframe if there are issues\n            return pd.DataFrame()\n\n    @reactive.calc\n    def filtered_data():\n        data = load_data()\n        if data.empty:\n            return pd.DataFrame()\n        \n        # Clean column names\n        data.columns = [col.strip() for col in data.columns]\n        \n        # Filter data based on inputs\n        filtered = data.copy()\n        \n        # Filter by species\n        if input.species() != \"All Species\":\n            filtered = filtered[filtered['Species'] == input.species()]\n        \n        # Filter by islands\n        filtered = filtered[filtered['Island'].isin(input.islands())]\n        \n        return filtered\n\n    @output\n    @render.plot\n    def penguin_plot():\n        data = filtered_data()\n        if data.empty:\n            fig, ax = plt.subplots()\n            ax.text(0.5, 0.5, \"No data available or error loading data\", \n                    ha='center', va='center')\n            ax.set_xlim(0, 1)\n            ax.set_ylim(0, 1)\n            ax.axis('off')\n            return fig\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        plot_type = input.plot_type()\n        \n        if plot_type == \"Body Mass vs Flipper Length\":\n            sns.scatterplot(\n                data=data, \n                x='Flipper Length (mm)', \n                y='Body Mass (g)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Body Mass vs Flipper Length\")\n            \n        elif plot_type == \"Culmen Length vs Depth\":\n            sns.scatterplot(\n                data=data, \n                x='Culmen Length (mm)', \n                y='Culmen Depth (mm)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Culmen Length vs Depth\")\n            \n        elif plot_type == \"Histogram of Body Mass\":\n            sns.histplot(\n                data=data,\n                x='Body Mass (g)',\n                hue='Species',\n                kde=True,\n                ax=ax\n            )\n            ax.set_title(\"Distribution of Body Mass\")\n            \n        plt.tight_layout()\n        return fig\n\n    @output\n    @render.table\n    def summary_table():\n        data = filtered_data()\n        if data.empty:\n            return pd.DataFrame({'Message': ['No data available or error loading data']})\n        \n        # Create a summary table with counts by species and island\n        summary = data.groupby(['Species', 'Island', 'Sex']).size().reset_index(name='Count')\n        \n        # Add some descriptive statistics\n        stats = data.groupby(['Species']).agg({\n            'Body Mass (g)': ['mean', 'std'],\n            'Flipper Length (mm)': ['mean', 'std'],\n            'Culmen Length (mm)': ['mean', 'std'],\n            'Culmen Depth (mm)': ['mean', 'std']\n        }).round(2)\n        \n        stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n        stats = stats.reset_index()\n        \n        return summary\n\napp = App(app_ui, server)\n\n\n\n\n\n\n\n\nReference\nhttps://github.com/rfordatascience/tidytuesday\nhttps://github.com/posit-dev/python-tidytuesday"
  },
  {
    "objectID": "posts/makeQRcode/index.html",
    "href": "posts/makeQRcode/index.html",
    "title": "Make QR code",
    "section": "",
    "text": "A guide to generating QR codes in R and Python.\nThis document demonstrates how to generate QR codes using both R and Python. It provides code examples for creating QR codes from a given string, saving them as SVG or PNG files, and displaying them. The R section uses the qrcode package, while the Python section uses the qrcode and scikit-image libraries.\n\nR\n\n\nCode\npak::pkg_install('qrcode')\n\n\n\n\nCode\nlibrary(reticulate)\nuse_python(\"/Library/Frameworks/Python.framework/Versions/3.13/bin/python3.13\")\npy_require(c('qrcode','Pillow','numpy','scikit-image'))\n\n\n\n\nCode\nlibrary(qrcode)\ncode=qr_code(\"https://rfor.us/posit2024slides\") \n\n\nSave the QR code as a SVG file\n\n\nCode\ngenerate_svg(code, filename = \"qr.svg\")\n\n\n\n\nCode\nplot(code)\n\n\n\n\n\n\n\n\n\n\n\nPython\n\n\nCode\n!pip install qrcode scikit-image\n\n\n\n\nCode\nimport platform\nprint(platform.python_version())\n\n\n3.13.2\n\n\n\n\nCode\nimport qrcode\nimg = qrcode.make(\"https://rfor.us/posit2024slides\")\ntype(img)  # qrcode.image.pil.PilImage\n\n\n&lt;class 'qrcode.image.pil.PilImage'&gt;\n\n\nsave the QR code as a PNG file\n\n\nCode\nimg.save(\"some_file.png\")\n\n\n\n\nCode\nfrom skimage import io\nimg = io.imread(\"some_file.png\")\nio.imshow(img)"
  },
  {
    "objectID": "posts/python_code_optimization/index.html",
    "href": "posts/python_code_optimization/index.html",
    "title": "Python code optimization with ruff",
    "section": "",
    "text": "A guide to using ruff for Python code linting and formatting, including installation, usage, and integration with Positron.\nThis document provides a comprehensive guide to using ruff, a fast and efficient Python linter and formatter. It covers the essential steps for getting started with ruff, including installation, checking your code for issues, and automatically fixing them. The guide also demonstrates how to format your code with ruff and how to integrate it as an extension in the Positron IDE. Additionally, it outlines a practical workflow for using ruff on .qmd files by first converting them to .py format."
  },
  {
    "objectID": "posts/python_code_optimization/index.html#convert-.qmd-to-.py",
    "href": "posts/python_code_optimization/index.html#convert-.qmd-to-.py",
    "title": "Python code optimization with ruff",
    "section": "convert .qmd to .py",
    "text": "convert .qmd to .py\n\n\n\nCode\n\nTerminal\n\nquarto convert index.qmd    # ‚Üí index.ipynb\n\n\n\n\n\n\nCode\n\nTerminal\n\n!jupyter nbconvert --to python index.ipynb    # ‚Üí index.py"
  },
  {
    "objectID": "posts/python_code_optimization/index.html#check-.py-with-ruff",
    "href": "posts/python_code_optimization/index.html#check-.py-with-ruff",
    "title": "Python code optimization with ruff",
    "section": "check .py with ruff",
    "text": "check .py with ruff\n\n\n\nCode\n\nTerminal\n\n!ruff check index.py"
  },
  {
    "objectID": "posts/linux_command/index.html",
    "href": "posts/linux_command/index.html",
    "title": "LinuxÁ≥ªÁªüÊìç‰Ωú‰ª£Á†Å",
    "section": "",
    "text": "A quick reference guide for common Linux commands, covering basic file operations, system information, and process management.\nThis document serves as a quick reference guide for a wide range of common Linux commands. It covers fundamental operations such as printing text, viewing manual pages, and navigating the file system. The guide also includes commands for file and folder management, such as listing, creating, and deleting files and folders, as well as downloading files from the internet and changing file permissions. Additionally, it provides commands for system information and process management, including checking folder sizes, installing software, editing files, viewing file content, and managing running processes.\nTop useful Linux command"
  },
  {
    "objectID": "posts/linux_command/index.html#create-txt-file",
    "href": "posts/linux_command/index.html#create-txt-file",
    "title": "LinuxÁ≥ªÁªüÊìç‰Ωú‰ª£Á†Å",
    "section": "create txt file",
    "text": "create txt file\nnano"
  },
  {
    "objectID": "posts/linux_command/index.html#edit-current-txt-file",
    "href": "posts/linux_command/index.html#edit-current-txt-file",
    "title": "LinuxÁ≥ªÁªüÊìç‰Ωú‰ª£Á†Å",
    "section": "edit current txt file",
    "text": "edit current txt file\nnano test.txt"
  },
  {
    "objectID": "posts/AI_subtitles/index.html",
    "href": "posts/AI_subtitles/index.html",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "",
    "text": "A workflow for generating and embedding bilingual subtitles for videos, covering video/audio downloading, transcription with mlx_whisper, translation with Gemini 2.0 Flash, and embedding with FFmpeg.\nThis document outlines a complete workflow for automatically generating and embedding bilingual (Chinese and English) subtitles for videos. It covers every step of the process, from downloading the video and audio from YouTube using yt-dlp to transcribing the audio to text with the mlx_whisper model. The guide also demonstrates how to use the Gemini 2.0 Flash model to correct and translate the transcribed text, and finally, how to embed the generated subtitles into the video using FFmpeg. This is a comprehensive resource for anyone looking to make their video content more accessible to a wider audience.\nUse mlx_whisper for transcribing audio to text, and use gemini-2.0-flash for correction\nLoad R packages\nCode\n#pak::pkg_install('tuneR')\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#check-mp3-duration",
    "href": "posts/AI_subtitles/index.html#check-mp3-duration",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "check mp3 duration",
    "text": "check mp3 duration\n\n\nCode\n# Load the MP3 file\n# Load the MP3 file\nmp3_file &lt;- readMP3(mp3_title)\n\n# Get the duration in seconds\nduration_mins &lt;- (length(mp3_file@left) / mp3_file@samp.rate)/60\nduration_mins"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#trim-mp3-if-needed",
    "href": "posts/AI_subtitles/index.html#trim-mp3-if-needed",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "trim mp3 if needed",
    "text": "trim mp3 if needed\n\n\nCode\n# library(lares)\n# trim_mp3(\n#   mp3_title,\n#   start_time = 1,\n#   end_time = 9999999,\n#   overwrite = FALSE,\n#   ext = \"mp3\",\n#   quiet = FALSE\n# )\n\n\n# output file:\n#paste0(mp3_title |&gt; str_replace('.mp3,',''),\"_trim.mp3\")"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#define-model",
    "href": "posts/AI_subtitles/index.html#define-model",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"‰Ω†ÊòØ‰∏Ä‰∏™‰∏≠ÊñáÂíåËã±ÊñáÁöÑËØ≠Ë®ÄÂ≠¶ÂÆ∂\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model\n\n\n\n\nCode\n#testing model connection\nchat_result=chat_gemini_model$chat(\"hello\")\nchat_result"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#run-model",
    "href": "posts/AI_subtitles/index.html#run-model",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt0=read_srt('text.srt')\nsrt_txt2=srt_txt0$subtitle|&gt; as.character()\n\n\n\n\nCode\nlength(srt_txt2)\n\n\n\n\nCode\nprompt_text=paste0('Êää‰ª•‰∏ãÊñáÂ≠óÊòØÈÄöËøáËØ≠Ë®ÄËØÜÂà´Âá∫Êù•ÁöÑÊñáÂ≠ó„ÄÇÂ¶ÇÊûúÊúâÈîôÂà´Â≠óËØ∑Êõ¥Ê≠£Âπ∂ËæìÂá∫‰∏≠Êñá„ÄÇ‰øùÊåÅÊõ¥Ê≠£ÂêéÁöÑÊñáÂ≠ó‰∏éÂéüÊñáÁöÑÊñáÂ≠óÈïøÂ∫¶‰∏ÄÊ†∑„ÄÇ‰πü‰øùÊåÅÂè•Â≠êÊÄªÈïøÂ∫¶‰∏éÊõ¥Ê≠£ÂêéÁöÑÂè•Â≠êÊÄªÈïøÂ∫¶‰∏ÄËá¥„ÄÇÊØîÂ¶ÇhovahËØ∑Êõ¥Ê≠£‰∏∫Á¶èÂª∫‰∫∫„ÄÇÊ≤°ÊúâÈîôÂàô‰∏çÂèò„ÄÇÊúâÊõ¥Ê≠£ÁöÑÂè•Â≠êÂêéÈù¢Âä†‰∏ä!!!!„ÄÇ‰∏çË¶ÅÂ§ö‰ΩôÁöÑÂèçÈ¶à„ÄÇËæìÂá∫Ê†ºÂºè‰∏∫:Êõ¥Ê≠£ÂâçÁöÑÂè•Â≠ê„Ää---„ÄãÊõ¥Ê≠£ÂêéÁöÑÂè•Â≠ê ',srt_txt2)\nchat_result1=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\nall_result2=unlist(strsplit(chat_result1, \"\\n\"))\nlength(all_result2)\n#all_result2= c(all_result2,\"\")"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#add-to-data",
    "href": "posts/AI_subtitles/index.html#add-to-data",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "add to data",
    "text": "add to data\n\n\nCode\nsrt_txt=srt_txt0 |&gt; mutate(correct_txt=all_result2 |&gt; str_replace('!!!!','')|&gt; str_extract( \"(?&lt;=„Ää---„Äã).*\")\n                           ,all_correct_txt=all_result2\n                           \n                           )"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#define-model-1",
    "href": "posts/AI_subtitles/index.html#define-model-1",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "define model",
    "text": "define model\n‰∏≠ÁøªËã± using google LLM model gemini-2.0-flash\n\n\nCode\nchat_gemini_model_translate&lt;- chat_gemini(\n  system_prompt = \"‰Ω†ÊòØ‰∏Ä‰∏™‰∏≠ÊñáÂíåËã±ÊñáÁöÑÁøªËØë‰∏ìÂÆ∂\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model_translate"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#run-model-1",
    "href": "posts/AI_subtitles/index.html#run-model-1",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "run model",
    "text": "run model\n\n\nCode\ncorrect_txt=srt_txt$correct_txt|&gt; as.character()\n\n\n\n\nCode\nprompt_text=paste0('ËØ∑ËÅîÁ≥ª‰∏ä‰∏ãÊñáÊää‰ª•‰∏ãÊñáÂ≠óÁøªËØëÊàêËã±Êñá„ÄÇÊÄªÂè•Â≠êÊï∞Èáè‰∏çÂèò„ÄÇ‰∏çË¶ÅÂ§ö‰ΩôÁöÑÂèçÈ¶à„ÄÇËæìÂá∫Ê†ºÂºè‰∏∫:ÂéüÊù•ÁöÑÊñáÂ≠ó„Ää---„ÄãÁøªËØëÊàêËã±Êñá',correct_txt)\nchat_result1=chat_gemini_model_translate$chat(prompt_text)\n\n\n\n\nCode\nall_result2=unlist(strsplit(chat_result1, \"\\n\"))\nlength(all_result2)\n#all_result2=all_result2[1:422]"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#add-to-data-1",
    "href": "posts/AI_subtitles/index.html#add-to-data-1",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "add to data",
    "text": "add to data\n\n\nCode\nsrt_txt=srt_txt |&gt; mutate(correct_english_txt=all_result2 |&gt; str_extract( \"(?&lt;=„Ää---„Äã).*\"))"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#output-srt_txt",
    "href": "posts/AI_subtitles/index.html#output-srt_txt",
    "title": "‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï",
    "section": "output srt_txt",
    "text": "output srt_txt\n\n\nCode\nwrite.xlsx(srt_txt,'srt_data.xlsx')"
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html",
    "href": "posts/web_scraping_in_R_with_rvest/index.html",
    "title": "Web scraping in R with rvest",
    "section": "",
    "text": "A guide to web scraping in R using the rvest package, with examples of how to extract text, links, and tables from web pages.\nThis document provides a comprehensive guide to web scraping in R using the rvest package. It covers the entire workflow, from reading HTML content from a URL to extracting specific elements like text, links, and tables. The guide also introduces advanced techniques with read_html_live() for dynamic web pages that require interaction, such as scrolling, to load content. This document is also part of the R handbook."
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html#get-3rd-table",
    "href": "posts/web_scraping_in_R_with_rvest/index.html#get-3rd-table",
    "title": "Web scraping in R with rvest",
    "section": "get 3rd table",
    "text": "get 3rd table\nfind table xpath\n\n\nCode\ntable=page %&gt;%html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[3]') |&gt; html_table()\ntable |&gt; head()\n\n\n# A tibble: 6 √ó 11\n  `Driver name`     Nationality    `Seasons competed` `Drivers' Championships`\n  &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;              &lt;chr&gt;                   \n1 Carlo Abate       Italy          1962‚Äì1963          0                       \n2 George Abecassis  United Kingdom 1951‚Äì1952          0                       \n3 Kenny Acheson     United Kingdom 1983, 1985         0                       \n4 Andrea de Adamich Italy          1968, 1970‚Äì1973    0                       \n5 Philippe Adams    Belgium        1994               0                       \n6 Walt Ader         United States  1950               0                       \n# ‚Ñπ 7 more variables: `Race entries` &lt;chr&gt;, `Race starts` &lt;chr&gt;,\n#   `Pole positions` &lt;chr&gt;, `Race wins` &lt;chr&gt;, Podiums &lt;chr&gt;,\n#   `Fastest laps` &lt;chr&gt;, `Points[a]` &lt;chr&gt;"
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html#get-4th-table",
    "href": "posts/web_scraping_in_R_with_rvest/index.html#get-4th-table",
    "title": "Web scraping in R with rvest",
    "section": "get 4th table",
    "text": "get 4th table\nfind table xpath\n\n\nCode\ntable=page %&gt;%html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[4]') |&gt; html_table()\ntable |&gt; head()\n\n\n# A tibble: 6 √ó 7\n  Country     Totaldrivers Champions Championships `Race wins` `First driver(s)`\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;            \n1 Argentinad‚Ä¶ 26           1(Fangio‚Ä¶ 5(1951, 1954‚Ä¶ \"38\\n(Fang‚Ä¶ Juan Manuel Fang‚Ä¶\n2 Australiad‚Ä¶ 18           2(Brabha‚Ä¶ 4(1959, 1960‚Ä¶ \"50\\n(Brab‚Ä¶ Tony Gaze(1952 B‚Ä¶\n3 Austriadet‚Ä¶ 16           2(Rindt,‚Ä¶ 4(1970, 1975‚Ä¶ \"41\\n(Rind‚Ä¶ Jochen Rindt(196‚Ä¶\n4 Belgiumdet‚Ä¶ 24           0         0             \"11\\n(Ickx‚Ä¶ Johnny Claes(195‚Ä¶\n5 Brazildeta‚Ä¶ 33           3(Fittip‚Ä¶ 8(1972, 1974‚Ä¶ \"101\\n(Fit‚Ä¶ Chico Landi(1951‚Ä¶\n6 Canadadeta‚Ä¶ 15           1(J. Vil‚Ä¶ 1(1997)       \"17\\n(G. V‚Ä¶ Peter Ryan(1961 ‚Ä¶\n# ‚Ñπ 1 more variable: `Most recent driver(s)/Current driver(s)` &lt;chr&gt;"
  },
  {
    "objectID": "posts/r_code_optimization/index.html",
    "href": "posts/r_code_optimization/index.html",
    "title": "R code optimization with lintr and styler",
    "section": "",
    "text": "An introduction to lintr and styler for R code optimization, with examples of how to use them for static code analysis and formatting.\nThis document introduces two essential R packages for code optimization: lintr and styler. It explains how lintr performs static code analysis to help you identify and fix style inconsistencies, syntax errors, and other potential issues in your R code. The document also demonstrates how styler can automatically format your code to adhere to the tidyverse style guide, ensuring consistency and readability. You‚Äôll find practical examples of how to use both packages to improve the quality of your R code.\npacakge for R code optimization"
  },
  {
    "objectID": "posts/r_code_optimization/index.html#before",
    "href": "posts/r_code_optimization/index.html#before",
    "title": "R code optimization with lintr and styler",
    "section": "Before",
    "text": "Before\n\n\nCode\nlibrary(\"dplyr\")\n\n   Good &lt;- 1\napplePie &lt;- Good + 1\n    Peter &lt;- d + 1"
  },
  {
    "objectID": "posts/r_code_optimization/index.html#auto-formating",
    "href": "posts/r_code_optimization/index.html#auto-formating",
    "title": "R code optimization with lintr and styler",
    "section": "Auto formating",
    "text": "Auto formating\n\n\n\nCode\n\ntest.R\n\nstyle_file(\"test.R\")\n\n\n\nStyling  1  files:\n test.R ‚úî \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nStatus  Count   Legend \n‚úî   1   File unchanged.\n‚Ñπ   0   File changed.\n‚úñ   0   Styling threw an error.\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\nAfter\n\n\nCode\nlibrary(\"dplyr\")\n\nGood &lt;- 1\napplePie &lt;- Good + 1\nPeter &lt;- d + 1"
  },
  {
    "objectID": "posts/display_table/index.html",
    "href": "posts/display_table/index.html",
    "title": "Ë°®Ê†ºÂ±ïÁ§∫",
    "section": "",
    "text": "A guide to creating visually appealing tables in R and Python using the gt and great_tables packages, with examples of styling, image embedding, and nanoplots.\nThis document provides a comprehensive guide to creating visually appealing and informative tables in both R and Python. It focuses on the gt package in R and the great_tables package in Python, demonstrating how to style tables, embed images, handle missing data, and even incorporate nanoplots (bar charts) directly into table cells. The guide also includes a practical example of translating great_tables code from Python to R, making it a valuable resource for users of both languages.\nWith the gt package, anyone can make wonderful-looking tables using the R/Python programming language.\n\nGT package\n\n\n\nRPython\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr) # Using dplyr for mutate, optional but convenient\nlibrary(gtExtras) # For image embedding\n\n\n\n\nCode\nlibrary(reticulate)\npy_require(c(\"polars\",\"great-tables\",\"pandas\",\"pyarrow\"))\n\n\n\n\nCode\nexibble |&gt; gt() |&gt; opt_stylize(style=3,color = \"green\") |&gt; fmt_auto()\n\n\n\n\n\n\n\n\nnum\nchar\nfctr\ndate\ntime\ndatetime\ncurrency\nrow\ngroup\n\n\n\n\n0.111\napricot\none\n2015-01-15\n13:35\n2018-01-01 02:22\n‚Äá‚Äá‚Äá‚Äá49.95‚Äá\nrow_1\ngrp_a\n\n\n2.222\nbanana\ntwo\n2015-02-15\n14:40\n2018-02-02 14:33\n‚Äá‚Äá‚Äá‚Äá17.95‚Äá\nrow_2\ngrp_a\n\n\n33.33\ncoconut\nthree\n2015-03-15\n15:45\n2018-03-03 03:44\n‚Äá‚Äá‚Äá‚Äá‚Äá1.39‚Äá\nrow_3\ngrp_a\n\n\n444.4\ndurian\nfour\n2015-04-15\n16:50\n2018-04-04 15:55\n65,100 ‚Äá‚Äá‚Äá\nrow_4\ngrp_a\n\n\n5,550\nNA\nfive\n2015-05-15\n17:55\n2018-05-05 04:00\n‚Äá1,325.81‚Äá\nrow_5\ngrp_b\n\n\nNA\nfig\nsix\n2015-06-15\nNA\n2018-06-06 16:11\n‚Äá‚Äá‚Äá‚Äá13.255\nrow_6\ngrp_b\n\n\n777,000\ngrapefruit\nseven\nNA\n19:10\n2018-07-07 05:22\nNA\nrow_7\ngrp_b\n\n\n8.880¬†√ó¬†106\nhoneydew\neight\n2015-08-15\n20:20\nNA\n‚Äá‚Äá‚Äá‚Äá‚Äá0.44‚Äá\nrow_8\ngrp_b\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport polars.selectors as cs\nfrom great_tables import GT, md,exibble\nfrom great_tables.data import reactions\n\n\n\n\nCode\n#exibble\n\n\n\n\nCode\nGT(exibble).opt_stylize(style=3,color = \"green\")\n\n\n\n\n\n\n\n\nnum\nchar\nfctr\ndate\ntime\ndatetime\ncurrency\nrow\ngroup\n\n\n\n\n0.1111\napricot\none\n2015-01-15\n13:35\n2018-01-01 02:22\n49.95\nrow_1\ngrp_a\n\n\n2.222\nbanana\ntwo\n2015-02-15\n14:40\n2018-02-02 14:33\n17.95\nrow_2\ngrp_a\n\n\n33.33\ncoconut\nthree\n2015-03-15\n15:45\n2018-03-03 03:44\n1.39\nrow_3\ngrp_a\n\n\n444.4\ndurian\nfour\n2015-04-15\n16:50\n2018-04-04 15:55\n65100.0\nrow_4\ngrp_a\n\n\n5550.0\n\nfive\n2015-05-15\n17:55\n2018-05-05 04:00\n1325.81\nrow_5\ngrp_b\n\n\n\nfig\nsix\n2015-06-15\n\n2018-06-06 16:11\n13.255\nrow_6\ngrp_b\n\n\n777000.0\ngrapefruit\nseven\n\n19:10\n2018-07-07 05:22\n\nrow_7\ngrp_b\n\n\n8880000.0\nhoneydew\neight\n2015-08-15\n20:20\n\n0.44\nrow_8\ngrp_b\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\nTable 1\nOriginal table:\n\n\nRPython\n\n\n\n\nCode\n# Load the necessary library\nlibrary(gt)\nlibrary(dplyr) # Using dplyr for mutate, optional but convenient\nlibrary(gtExtras) # For image embedding\n\n\n\n\nCode\n# 1. Create the data frame\n# Note: Storing percentages as numbers (0-100) for easier formatting\nhoosiers_data &lt;- data.frame(\n  TEAM = c(\"Wake Forest\", \"Indiana\", \"North Carolina\", \"Coppin St.\", \"Vermont\", \"New Mexico St.\"),\n  logo_url = c(\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/154.png\",      # Wake Forest\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/84.png\",       # Indiana\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/153.png\",      # North Carolina\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/2154.png\",     # Coppin St.\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/261.png\",     # Vermont\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/166.png\"       # New Mexico St.\n  ),\n  `3FG_Text` = c(\"17-61\", \"19-79\", \"20-60\", \"21-60\", \"22-89\", \"22-72\"), # Keep original text for display\n  `3FG%` = c(27.87, 24.05, 33.33, 35.00, 24.72, 30.56),\n  PER_GAME = c(2.83, 3.17, 3.33, 3.50, 3.67, 3.67),\n  SEED = c(4, NA, 6, 16, 16, 13),\n  ROUND = c(\"R64\", NA, \"R32\", \"R68\", \"R64\", \"R64\"),\n  YEAR = c(2009, 2024, 2014, 2008, 2010, 2014),\n  stringsAsFactors = FALSE # Good practice\n)\n\n\n\n\nCode\n# 2. Create the gt table\ngt_table &lt;- hoosiers_data %&gt;%\n  gt() %&gt;%\n  # --- Add Logos ---\n  gt_img_rows(columns = logo_url, height = 25) %&gt;% # Use URL column, set image height\n  # --- Move logo column ---\n  cols_move_to_start(columns = logo_url) %&gt;% # Place logo column first\n  # Add title and subtitle\n  tab_header(\n    title = \"History does not bode well for the Hoosiers\",\n    subtitle = \"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n  ) %&gt;%\n  # Create the spanner header over the shooting columns\n  tab_spanner(\n    label = \"Shooting\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME)\n  ) %&gt;%\n  # Format column labels\n  cols_label(\n    logo_url = \"\", # No header text for the logo column\n    TEAM = \"TEAM\",\n    `X3FG_Text` = \"3FG\", # Use the text column for display\n    `X3FG.` = \"3FG%\",\n    PER_GAME = \"PER GAME\",\n    SEED = \"SEED\",\n    ROUND = \"ROUND\",\n    YEAR = \"YEAR\"\n  ) %&gt;%\n  # Format the percentage column\n  fmt_percent(\n    columns = `X3FG.`,\n    decimals = 2,\n    scale_values = FALSE # Values are already 0-100\n  ) %&gt;%\n  # Format the 'PER GAME' column to two decimal places\n  fmt_number(\n    columns = PER_GAME,\n    decimals = 2\n  ) %&gt;%\n  # Replace NA values with \"???\"\n  sub_missing(\n    columns = c(SEED, ROUND),\n    missing_text = \"???\"\n  ) %&gt;%\n   # Align columns (optional, but often improves appearance)\n  cols_align(\n    align = \"center\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME, SEED, ROUND, YEAR)\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = TEAM\n  ) %&gt;%\n  # Highlight the Indiana row (using a light blue background as an example)\n  tab_style(\n    style = cell_fill(color = \"#ADD8E6\"), # AliceBlue, adjust as needed\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n  tab_style(\n    style = cell_borders(\n      sides = c(\"top\", 'bottom',\"left\", \"right\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(2)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`)\n  ) %&gt;%\n  # Add the source note\n  tab_source_note(\n    source_note = \"Viz. + Analysis by @andreweatherman\"\n  )%&gt;%\n  # Adjust width of the logo column if needed (optional)\n  cols_width(\n      logo_url ~ px(40) # Set logo column width to 40 pixels\n  )\ngt_table\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\n\nShooting\n\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n\n\nthe row Team Indiana background color is not correct,and also letter is not bold,So adjust it.\n\n\nCode\nlibrary(magick)\n\n# Read the image\nimg &lt;- image_read(\"images/my screenshots.png\")\n\n# Display the image to inspect it (optional, opens in a viewer)\n#image_browse(img)\n\n\n\n\nCode\n# Get image dimensions\nimg_info &lt;- image_info(img)\nprint(img_info)\n\n\n# A tibble: 1 √ó 7\n  format width height colorspace matte filesize density\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n1 PNG     1066    872 sRGB       TRUE    983185 57x57  \n\n\n\n\nCode\n# Crop a 50x50 pixel section from the Indiana row background\n# Adjust coordinates based on your image dimensions\nimg_cropped &lt;- image_crop(img, \"50x50+200+400\")\n\n# Display the cropped section to confirm (optional)\n#image_browse(img_cropped)\n\n\n\n\nCode\n# Convert the cropped image to a raster\nimg_raster &lt;- as.raster(img_cropped)\n\n# Convert the raster to a matrix of colors\nimg_matrix &lt;- as.matrix(img_raster)\n\n# Extract RGB values from the matrix\n# col2rgb expects a vector of colors, so we flatten the matrix\nrgb_values &lt;- col2rgb(img_matrix)\n\n# Calculate the average RGB values (to approximate the dominant background color)\navg_rgb &lt;- rowMeans(rgb_values, na.rm = TRUE)\n\n# Convert the average RGB to Hex\n# col2rgb returns values in the range 0-255, so we can use them directly\nhex_code &lt;- rgb(avg_rgb[1], avg_rgb[2], avg_rgb[3], maxColorValue = 255)\n\n# Print the Hex code\nprint(hex_code)\n\n\n[1] \"#70AACA\"\n\n\n\n\nCode\n# 2. Create the gt table\ngt_table &lt;- hoosiers_data %&gt;%\n  gt() %&gt;%\n  # --- Add Logos ---\n  gt_img_rows(columns = logo_url, height = 25) %&gt;% # Use URL column, set image height\n  # --- Move logo column ---\n  cols_move_to_start(columns = logo_url) %&gt;% # Place logo column first\n  # Add title and subtitle\n  tab_header(\n    title = \"History does not bode well for the Hoosiers\",\n    subtitle = \"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n  ) %&gt;%\n  # Create the spanner header over the shooting columns\n  tab_spanner(\n    label = \"Shooting\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME)\n  ) %&gt;%\n  # Format column labels\n  cols_label(\n    logo_url = \"\", # No header text for the logo column\n    TEAM = \"TEAM\",\n    `X3FG_Text` = \"3FG\", # Use the text column for display\n    `X3FG.` = \"3FG%\",\n    PER_GAME = \"PER GAME\",\n    SEED = \"SEED\",\n    ROUND = \"ROUND\",\n    YEAR = \"YEAR\"\n  ) %&gt;%\n  # Format the percentage column\n  fmt_percent(\n    columns = `X3FG.`,\n    decimals = 2,\n    scale_values = FALSE # Values are already 0-100\n  ) %&gt;%\n  # Format the 'PER GAME' column to two decimal places\n  fmt_number(\n    columns = PER_GAME,\n    decimals = 2\n  ) %&gt;%\n  # Replace NA values with \"???\"\n  sub_missing(\n    columns = c(SEED, ROUND),\n    missing_text = \"???\"\n  ) %&gt;%\n   # Align columns (optional, but often improves appearance)\n  cols_align(\n    align = \"center\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME, SEED, ROUND, YEAR)\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = TEAM\n  ) %&gt;%\n  # Highlight the Indiana row (using a light blue background as an example)\n  tab_style(\n    \n    style = cell_fill(color = \"#70AACA\"), # AliceBlue, adjust as needed\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n   tab_style(\n     style = cell_text(weight = \"bold\"),\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n  ### dotted line\n  tab_style(\n    style = cell_borders(\n      sides = c(\"top\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`,rows = TEAM == \"Wake Forest\") # Apply to Indiana row)\n  ) %&gt;%\n    ### dotted line\n    tab_style(\n    style = cell_borders(\n      sides = c(\"bottom\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`,rows = TEAM == \"New Mexico St.\")\n  ) %&gt;%\n  ### dotted line\n    tab_style(\n    style = cell_borders(\n      sides = c(\"left\",\"right\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`)\n  ) %&gt;%\n  # Add the source note\n  tab_source_note(\n    source_note = \"Viz. + Analysis by @andreweatherman\"\n  )%&gt;%\n  # Adjust width of the logo column if needed (optional)\n  cols_width(\n      logo_url ~ px(40) # Set logo column width to 40 pixels\n  )\ngt_table\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\n\nShooting\n\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nfrom great_tables import GT, md, html, loc, style, px# Import necessary components\n\n\n\n\nCode\n# 1. Create the Pandas DataFrame\n# Using a dictionary preserves column names with special characters/spaces\nhoosiers_data = pd.DataFrame({\n    \"TEAM\": [\"Wake Forest\", \"Indiana\", \"North Carolina\", \"Coppin St.\", \"Vermont\", \"New Mexico St.\"],\n    \"logo_url\": [\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/154.png\",      # Wake Forest\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/84.png\",       # Indiana\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/153.png\",      # North Carolina\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/2154.png\",     # Coppin St.\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/261.png\",      # Vermont\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/166.png\"       # New Mexico St.\n    ],\n    \"3FG_Text\": [\"17-61\", \"19-79\", \"20-60\", \"21-60\", \"22-89\", \"22-72\"], # Keep original text\n    \"3FG%\": [27.87, 24.05, 33.33, 35.00, 24.72, 30.56],\n    \"PER_GAME\": [2.83, 3.17, 3.33, 3.50, 3.67, 3.67],\n    \"SEED\": [4, np.nan, 6, 16, 16, 13], # Use numpy.nan for missing values\n    \"ROUND\": [\"R64\", np.nan, \"R32\", \"R68\", \"R64\", \"R64\"],\n    \"YEAR\": [2009, 2024, 2014, 2008, 2010, 2014],\n})\n\nhoosiers_data_pl=pl.from_pandas(hoosiers_data)\n\n\n\n\nCode\n# 2. Create the great_tables table (Using lambda for older versions)\n# NOTE: This assumes fmt_image and loc.body exist in your version.\n# If you get errors on those, your version might be very old.\ngt_table = (\n    GT(data=hoosiers_data_pl)\n    .fmt_image(columns=\"logo_url\", height=25)\n    .cols_move_to_start(columns=[\"logo_url\"])\n    .tab_header(\n        title=\"History does not bode well for the Hoosiers\",\n        subtitle=\"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n    )\n    .tab_spanner(\n        label=\"Shooting\",\n        columns=[\"3FG_Text\", \"3FG%\", \"PER_GAME\"]\n    )\n    .cols_label(\n        logo_url = \"\",\n        TEAM = \"TEAM\",\n        **{\"3FG_Text\": \"3FG\"},\n        **{\"3FG%\": \"3FG%\"},\n        PER_GAME = \"PER GAME\",\n        SEED = \"SEED\",\n        ROUND = \"ROUND\",\n        YEAR = \"YEAR\"\n    )\n    .fmt_percent(\n        columns=\"3FG%\",\n        decimals=2,\n        scale_values=False\n    )\n    .fmt_number(\n        columns=\"PER_GAME\",\n        decimals=2\n    )\n    .sub_missing(\n        columns=[\"SEED\", \"ROUND\"],\n        missing_text=\"???\"\n    )\n    .cols_align(\n        align=\"center\",\n        columns=[\"3FG_Text\", \"3FG%\", \"PER_GAME\", \"SEED\", \"ROUND\", \"YEAR\"]\n    )\n    .cols_align(\n        align=\"left\",\n        columns=\"TEAM\"\n    )\n    # Highlight the Indiana row (Using lambda function)\n    .tab_style(\n        style=style.fill(color=\"#70AACA\"),\n        # pandas way   Use a lambda function to define the row condition\n      # locations=[loc.body(rows=lambda x: x[\"TEAM\"] == \"Indiana\")]\n        locations=[loc.body(rows=pl.col(\"TEAM\")  == \"Indiana\")]\n    )\n    # Make letter bold the Indiana row (Using lambda function)\n    .tab_style(\n        style=style.text(weight = \"bold\"),\n        # pandas way   Use a lambda function to define the row condition\n      # locations=[loc.body(rows=lambda x: x[\"TEAM\"] == \"Indiana\")]\n        locations=[loc.body(rows=pl.col(\"TEAM\")  == \"Indiana\")]\n    )\n\n    # Add the source note\n    .tab_source_note(\n        source_note=md(\"Viz. + Analysis by @andreweatherman\")\n    )\n     # Adjust width of the logo column\n     .cols_width(\n        logo_url = px(40)\n     )\n)\n\n\n\n\nCode\n# save:\n# gt_table.save(\"hoosiers_table.html\")\n\n# To display(In Jupyter):\ngt_table # In Jupyter\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\nShooting\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4.0\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6.0\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16.0\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16.0\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13.0\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\nTable 2\nOriginal table:\n\n\nRPython\n\n\n\n\nCode\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(dplyr)\nlibrary(jsonlite)\nlibrary(scales)\nlibrary(lubridate)\n\n\n\n\nCode\n# URL for the data\ndata_url &lt;- \"https://github.com/machow/coffee-sales-data/raw/main/data/coffee-sales.ndjson\"\ncoffee_data_raw =stream_in(url(data_url), simplifyDataFrame = TRUE)\n\n\n\n Found 14 records...\n Imported 14 records. Simplifying...\n\n\n\nPrompt gemini 2.5\nusing R GT package to recreate this table.data source from https://github.com/machow/coffee-sales-data/blob/main/data/coffee-sales.ndjson\nStep 1 load package and read in data from github library(gt) library(gtExtras) library(dplyr) library(jsonlite) library(scales) library(lubridate) data_url &lt;- ‚Äúhttps://github.com/machow/coffee-sales-data/raw/main/data/coffee-sales.ndjson‚Äù coffee_data_raw =stream_in(url(data_url), simplifyDataFrame = TRUE)\nno need to no need to Aggregate data for the table.all number are given\nStep 2 create GT table,using cols_nanoplot() to add the bar plot for column Monthly Sales\nno need to create the icon at left side\nSince gt v0.3.0, columns = vars(...) has been deprecated. ‚Ä¢ Please use columns = c(...) instead.\n\n\nCode\n# Step 1: Load necessary packages\n# ----------------------------------------------------\n# Ensure gt and gtExtras are installed and loaded\n# install.packages(\"gt\")\n# install.packages(\"gtExtras\")\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(dplyr) # Still useful for data frame creation/manipulation\nlibrary(tibble) # Good for defining data frames\n\n# Step 2: Define the data frame manually based on the image\n# ----------------------------------------------------\n# Note:\n# - Amounts are entered as numbers (e.g., 904000 for $904K, 2.05e6 for $2.05M)\n#   so fmt_currency(scale_suffixing = TRUE) works correctly.\n# - Percentages are entered as proportions (e.g., 0.03 for 3%) for fmt_percent.\n# - Monthly Sales data needs to be a list of numeric vectors. Since we don't\n#   have the exact monthly data, we create approximate data representative\n#   of the bar patterns shown in the image. The length (14) is arbitrary.\n\n# coffee_table_data &lt;- tibble(\n#   Product = c(\"Grinder\", \"Moka pot\", \"Cold brew\", \"Filter\", \"Drip machine\",\n#               \"AeroPress\", \"Pour over\", \"French press\", \"Cezve\", \"Chemex\",\n#               \"Scale\", \"Kettle\", \"Espresso Machine\"),\n#   Revenue_Amount = c(904000, 2050000, 289000, 404000, 2630000,\n#                      2600000, 846000, 1110000, 2510000, 3140000,\n#                      3800000, 756000, 8410000),\n#   Revenue_Percent = c(0.03, 0.07, 0.01, 0.01, 0.09,\n#                       0.09, 0.03, 0.04, 0.09, 0.11,\n#                       0.13, 0.03, 0.29),\n#   Profit_Amount = c(568000, 181000, 242000, 70000, 1370000,\n#                     1290000, 365000, 748000, 1970000, 818000,\n#                     2910000, 618000, 3640000),\n#   Profit_Percent = c(0.04, 0.01, 0.02, 0.00, 0.09,\n#                      0.09, 0.02, 0.05, 0.13, 0.06,\n#                      0.20, 0.04, 0.25),\n#   # --- Estimated Monthly Sales Data (List Column) ---\n#   # Create lists of numbers that approximate the bar patterns\n#   Monthly_Sales = list(\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Grinder (Consistent high)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # Moka pot (Consistent medium-high)\n#     c(2,3,4,5,6,7,8,7,6,5,4,3,2,1),         # Cold brew (Peak in middle)\n#     c(6,7,6,7,6,7,6,7,6,7,6,7,6,7),         # Filter (Consistent medium)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Drip machine (Consistent high)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # AeroPress (Consistent high)\n#     c(5,6,7,6,5,6,7,6,5,6,7,6,5,6),         # Pour over (Slight variation medium)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # French press (Consistent medium-high)\n#     c(6,7,8,7,6,7,8,7,6,7,8,7,6,7),         # Cezve (Slight variation medium-high)\n#     c(7,8,9,8,7,8,9,8,7,8,9,8,7,8),         # Chemex (Slight variation high)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Scale (Consistent high)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # Kettle (Consistent medium-high)\n#     c(1,2,3,4,5,6,7,7,6,6,5,5,4,4)          # Espresso Machine (Ramp up, plateau/dip)\n#   )\n# )\n\ncoffee_table_data=coffee_data_raw |&gt; rename(\n  Product=product,\n  Revenue_Amount=revenue_dollars,\n  Revenue_Percent=revenue_pct,\n  Profit_Amount=profit_dollars,\n  Profit_Percent=profit_pct,\n  Monthly_Sales=monthly_sales\n)\n\n# Step 3: Create the GT table\n# --------------------------------------------------\n\ncoffee_gt_table_manual &lt;- coffee_table_data %&gt;%\n  # Initialize gt table, using 'Product' column as row labels (stub)\n  gt(rowname_col = \"icon\") %&gt;%\n\n  # --- Add Column Spanners ---\n  tab_spanner(\n    label = \"Revenue\",\n    columns = c(Revenue_Amount, Revenue_Percent)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Profit\",\n    columns = c(Profit_Amount, Profit_Percent)\n  ) %&gt;%\n\n  # --- Format Columns ---\n  # Format Amounts using short scale (K, M)\n  fmt_currency(\n      columns = c(Revenue_Amount, Profit_Amount),\n      currency = \"USD\", # Assuming USD\n      decimals = 1,     # One decimal place shown in image for totals, apply consistently\n      suffixing = TRUE # Key for K, M suffixes\n  ) %&gt;%\n  # Format percentage columns\n  fmt_percent(\n      columns = c(Revenue_Percent, Profit_Percent),\n      decimals = 0 # Zero decimal places\n  ) %&gt;%\n\n  # --- Add Nanoplot (Bar Chart) ---\n  cols_nanoplot(\n     columns = Monthly_Sales,\n     plot_type = \"bar\",\n     options = nanoplot_options(\n         data_bar_fill_color = \"steelblue\",\n         data_bar_stroke_color = \"steelblue\"\n     )\n  ) %&gt;%\n\n  # --- Add Grand Summary Row ---\n  # Calculate sums directly from the numeric columns we created\n  # Verify these match the totals in the image ($29.4M, 100%, $14.8M, 100%)\n  # grand_summary_rows(\n  #   columns = c(Revenue_Amount, Profit_Amount),\n  #   fns = list(\n  #     Total = ~sum(., na.rm = TRUE)\n  #   ),\n  #   formatter = fmt_currency,\n  #    #currency = \"USD\",\n  #    decimals = 1,\n  #    suffixing = TRUE\n  # ) %&gt;%\n  #  grand_summary_rows(\n  #   columns = c(Revenue_Percent, Profit_Percent),\n  #   fns = list(\n  #       Total = ~sum(., na.rm = TRUE)\n  #   ),\n  #   formatter = fmt_percent,\n  #   decimals = 0\n  #  ) %&gt;%\n\n  # --- Add Title and Labels ---\n  tab_header(\n    title = \"Sales of Coffee Equipment\"\n  ) %&gt;%\n  cols_label(\n    Revenue_Amount = \"Amount\",\n    Revenue_Percent = \"Percent\",\n    Profit_Amount = \"Amount\",\n    Profit_Percent = \"Percent\",\n    Monthly_Sales = \"Monthly Sales\"\n  ) %&gt;%\n\n  # --- Styling ---\n   cols_width(\n      c(Product) ~ px(150),\n      contains(\"Amount\") ~ px(100),\n      contains(\"Percent\") ~ px(80),\n      Monthly_Sales ~ px(150)\n   ) %&gt;%\n   tab_style(\n      style = cell_text(align = \"center\", weight = \"bold\"),\n      locations = list(\n          cells_column_spanners(),\n          cells_column_labels()\n          )\n   ) %&gt;%\n   cols_align(\n      align = \"right\",\n      columns = c(Revenue_Amount, Profit_Amount, Revenue_Percent, Profit_Percent)\n   ) %&gt;%\n    cols_align( # Center align product names (stub) and monthly sales plot\n      align = \"center\",\n      columns = c(Product, Monthly_Sales)\n   ) %&gt;%\n   cols_align( # Left align product names (stub)\n      align = \"left\",\n      columns = Product\n   ) %&gt;%\n   tab_options(\n       column_labels.padding = px(5),\n       data_row.padding = px(5),\n       summary_row.padding = px(5), # Controls grand summary padding too\n       grand_summary_row.padding = px(5)\n   )\n\n\n\n\nCode\n# --- Display the table ---\ncoffee_gt_table_manual |&gt; tab_style(\n        style= list(cell_fill(color =\"aliceblue\")),\n        locations=cells_body(columns = c(Revenue_Amount, Revenue_Percent))\n        )|&gt; tab_style(\n        style= list(cell_fill(color =\"papayawhip\")),\n        locations=cells_body(columns = c(Profit_Amount, Profit_Percent))\n    )|&gt; tab_style(\n        style= list(cell_text(weight=\"bold\")),\n        locations=cells_body(rows = Revenue_Amount == max(Revenue_Amount))\n    ) |&gt; fmt_image(\"icon\", path=\"assets\") |&gt; sub_missing(missing_text=\"\")\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\n\nRevenue\n\n\nProfit\n\nnanoplots\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904.5K\n3%\n$568.0K\n4%\n\n\n     \n\n               765 0   521   494   596   613   667   748   765   686   607   594   568   751\n\n\n\n\n\nMoka pot\n$2.0M\n7%\n$181.1K\n1%\n\n\n     \n\n               6.87K 0   4.73K   4.74K   4.79K   5.51K   6.16K   6.62K   6.87K   6.03K   5.30K   4.88K   4.65K   6.28K\n\n\n\n\n\nCold brew\n$288.8K\n1%\n$241.8K\n2%\n\n\n     \n\n               2.70K 0   244   249   438   981   1.77K   2.70K   2.61K   2.35K   1.74K   896   499   244\n\n\n\n\n\nFilter\n$404.2K\n1%\n$70.0K\n0%\n\n\n     \n\n               2.74K 0   2.07K   1.81K   1.84K   2.12K   2.25K   2.63K   2.56K   2.37K   2.16K   2.19K   2.07K   2.74K\n\n\n\n\n\nDrip machine\n$2.6M\n9%\n$1.4M\n9%\n\n\n     \n\n               2.58K 0   2.14K   1.62K   1.97K   2.10K   2.58K   2.46K   2.34K   2.32K   2.05K   1.97K   1.84K   2.33K\n\n\n\n\n\nAeroPress\n$2.6M\n9%\n$1.3M\n9%\n\n\n     \n\n               9.27K 0   6.33K   5.20K   6.37K   7.02K   7.91K   8.70K   8.69K   7.80K   6.83K   6.96K   6.88K   9.27K\n\n\n\n\n\nPour over\n$846.0K\n3%\n$364.5K\n2%\n\n\n     \n\n               2.18K 0   1.56K   1.29K   1.51K   1.69K   1.94K   2.18K   2.14K   1.86K   1.72K   1.81K   1.60K   2.16K\n\n\n\n\n\nFrench press\n$1.1M\n4%\n$748.1K\n5%\n\n\n     \n\n               4.82K 0   3.51K   2.88K   3.35K   3.79K   3.90K   4.10K   4.18K   4.43K   3.28K   3.42K   3.30K   4.82K\n\n\n\n\n\nCezve\n$2.5M\n9%\n$2.0M\n13%\n\n\n     \n\n               17.1K 0   12.2K   11.5K   11.8K   13.6K   15.4K   16.5K   17.1K   14.4K   13.0K   12.9K   11.6K   15.9K\n\n\n\n\n\nChemex\n$3.1M\n11%\n$817.7K\n6%\n\n\n     \n\n               7.22K 0   4.94K   4.17K   5.24K   6.00K   6.36K   6.77K   7.11K   6.25K   5.60K   6.08K   4.98K   7.22K\n\n\n\n\n\nScale\n$3.8M\n13%\n$2.9M\n20%\n\n\n     \n\n               3.18K 0   1.54K   1.57K   1.68K   2.03K   2.43K   2.55K   2.57K   2.23K   2.04K   2.09K   1.69K   3.18K\n\n\n\n\n\nKettle\n$756.2K\n3%\n$617.5K\n4%\n\n\n     \n\n               1.53K 0   1.14K   1.02K   1.09K   1.13K   1.41K   1.48K   1.46K   1.30K   1.14K   1.23K   1.19K   1.53K\n\n\n\n\n\nEspresso Machine\n$8.4M\n29%\n$3.6M\n25%\n\n\n     \n\n               2.58K 0   686   840   618   598   2.15K   533   797   996   1.00K   668   858   2.58K\n\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport polars.selectors as cs\nfrom great_tables import GT, loc, style\n\ncoffee_sales = pl.read_ndjson(\"coffee-sales.ndjson\")\nsel_rev = cs.starts_with(\"revenue\")\nsel_prof = cs.starts_with(\"profit\")\n\n\ncoffee_table = (\n    GT(coffee_sales)\n    .tab_header(\"Sales of Coffee Equipment\")\n    .tab_spanner(label=\"Revenue\", columns=sel_rev)\n    .tab_spanner(label=\"Profit\", columns=sel_prof)\n    .cols_label(\n        revenue_dollars=\"Amount\",\n        profit_dollars=\"Amount\",\n        revenue_pct=\"Percent\",\n        profit_pct=\"Percent\",\n        monthly_sales=\"Monthly Sales\",\n        icon=\"\",\n        product=\"Product\",\n    )\n    # formatting ----\n    .fmt_number(\n        columns=cs.ends_with(\"dollars\"),\n        compact=True,\n        pattern=\"${x}\",\n        n_sigfig=3,\n    )\n    .fmt_percent(columns=cs.ends_with(\"pct\"), decimals=0)\n    # style ----\n    .tab_style(\n        style=style.fill(color=\"aliceblue\"),\n        locations=loc.body(columns=sel_rev),\n    )\n    .tab_style(\n        style=style.fill(color=\"papayawhip\"),\n        locations=loc.body(columns=sel_prof),\n    )\n    .tab_style(\n        style=style.text(weight=\"bold\"),\n        locations=loc.body(rows=pl.col(\"product\") == \"Total\"),\n    )\n    .fmt_nanoplot(\"monthly_sales\", plot_type=\"bar\")\n    .fmt_image(\"icon\", path=\"assets\")\n    .sub_missing(missing_text=\"\")\n)\n\ncoffee_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\nRevenue\nProfit\nMonthly Sales\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904K\n3%\n$568K\n4%\n\n\n\n\n7650521494596613667748765686607594568751\n\n\n\n\n\nMoka pot\n$2.05M\n7%\n$181K\n1%\n\n\n\n\n6.87K04.73K4.74K4.79K5.51K6.16K6.62K6.87K6.03K5.30K4.88K4.65K6.28K\n\n\n\n\n\nCold brew\n$289K\n1%\n$242K\n2%\n\n\n\n\n2.70K02442494389811.77K2.70K2.61K2.35K1.74K896499244\n\n\n\n\n\nFilter\n$404K\n1%\n$70.0K\n0%\n\n\n\n\n2.74K02.07K1.81K1.84K2.12K2.25K2.63K2.56K2.37K2.16K2.19K2.07K2.74K\n\n\n\n\n\nDrip machine\n$2.63M\n9%\n$1.37M\n9%\n\n\n\n\n2.58K02.14K1.62K1.97K2.10K2.58K2.46K2.34K2.32K2.05K1.97K1.84K2.33K\n\n\n\n\n\nAeroPress\n$2.60M\n9%\n$1.29M\n9%\n\n\n\n\n9.27K06.33K5.20K6.37K7.02K7.91K8.70K8.69K7.80K6.83K6.96K6.88K9.27K\n\n\n\n\n\nPour over\n$846K\n3%\n$365K\n2%\n\n\n\n\n2.18K01.56K1.29K1.51K1.69K1.94K2.18K2.14K1.86K1.72K1.81K1.60K2.16K\n\n\n\n\n\nFrench press\n$1.11M\n4%\n$748K\n5%\n\n\n\n\n4.82K03.51K2.88K3.35K3.79K3.90K4.10K4.18K4.43K3.28K3.42K3.30K4.82K\n\n\n\n\n\nCezve\n$2.51M\n9%\n$1.97M\n13%\n\n\n\n\n17.1K012.2K11.5K11.8K13.6K15.4K16.5K17.1K14.4K13.0K12.9K11.6K15.9K\n\n\n\n\n\nChemex\n$3.14M\n11%\n$818K\n6%\n\n\n\n\n7.22K04.94K4.17K5.24K6.00K6.36K6.77K7.11K6.25K5.60K6.08K4.98K7.22K\n\n\n\n\n\nScale\n$3.80M\n13%\n$2.91M\n20%\n\n\n\n\n3.18K01.54K1.57K1.68K2.03K2.42K2.55K2.57K2.23K2.04K2.09K1.69K3.18K\n\n\n\n\n\nKettle\n$756K\n3%\n$618K\n4%\n\n\n\n\n1.53K01.14K1.02K1.09K1.13K1.41K1.48K1.46K1.30K1.14K1.23K1.19K1.53K\n\n\n\n\n\nEspresso Machine\n$8.41M\n29%\n$3.64M\n25%\n\n\n\n\n2.58K06868406185982.15K5337979961.00K6688582.58K\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n        \n\n\nCode\n#coffee_table.save(\"data/coffee-table.png\",  scale=2)\n\n\n\npython to R with gemini 2.5\ntranslate following python code to R code,using cols_nanoplot in R to replace fmt_nanoplot()\nError in fmt_currency(., columns = ends_with(‚Äúdollars‚Äù), currency = ‚ÄúUSD‚Äù, : unused arguments (use_sigfig = TRUE, sigfig = 3)\n\n\nCode\n# --- Load necessary libraries ---\nlibrary(gt)\nlibrary(dplyr)\nlibrary(jsonlite)\nlibrary(gtExtras)\n\n# --- Data Loading ---\n# (Assuming coffee_sales is loaded as before)\ncon &lt;- file(\"coffee-sales.ndjson\", \"r\")\ncoffee_sales &lt;- stream_in(con, simplifyDataFrame = TRUE) %&gt;%\n  as_tibble()\n\n\n\n Found 14 records...\n Imported 14 records. Simplifying...\n\n\nCode\nclose(con)\n\n# --- Table Creation and Styling with gt ---\ncoffee_table &lt;-\n  gt(coffee_sales) %&gt;%\n\n  # --- Headers and Spanners ---\n  tab_header(title = \"Sales of Coffee Equipment\") %&gt;%\n  tab_spanner(label = \"Revenue\", columns = starts_with(\"revenue\")) %&gt;%\n  tab_spanner(label = \"Profit\", columns = starts_with(\"profit\")) %&gt;%\n\n  # --- Column Labels ---\n  cols_label(\n    revenue_dollars = \"Amount\",\n    profit_dollars = \"Amount\",\n    revenue_pct = \"Percent\",\n    profit_pct = \"Percent\",\n    monthly_sales = \"Monthly Sales\",\n    icon = \"\",\n    product = \"Product\"\n  ) %&gt;%\n\n  # --- Formatting ---\n  # *** CORRECTED SECTION ***\n  # Format numeric columns using significant figures and add '$' prefix with pattern\n  fmt_number(\n      columns = ends_with(\"dollars\"),\n      pattern = \"${x}\",  # Use pattern to add the dollar sign\n      n_sigfig = 3 ,      # Specify 3 significant figures\n      # If you also wanted the compact K/M notation like in Python's compact=True:\n      suffixing = TRUE\n  ) %&gt;%\n  # Format percentage columns\n  fmt_percent(columns = ends_with(\"pct\"), decimals = 0) %&gt;%\n\n  # --- Styling ---\n  tab_style(\n    style = cell_fill(color = \"aliceblue\"),\n    locations = cells_body(columns = starts_with(\"revenue\"))\n  ) %&gt;%\n  tab_style(\n    style = cell_fill(color = \"papayawhip\"),\n    locations = cells_body(columns = starts_with(\"profit\"))\n  ) %&gt;%\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body(columns = everything(), rows = product == \"Total\")\n  ) %&gt;%\n\n  # --- Special Formatting ---\n  #gt_plt_bar(column = monthly_sales, color=\"grey\", background = \"lightgrey\") %&gt;%\n  # text_transform(\n  #   locations = cells_body(columns = icon),\n  #   fn = function(x) {\n  #       image_path &lt;- file.path(\"assets\", x)\n  #        if (!file.exists(image_path)) {\n  #           warning(\"Image file not found: \", image_path)\n  #           return(\"\")\n  #         }\n  #       local_image(filename = image_path, height = px(25))\n  #   }\n  # ) %&gt;%\n  sub_missing(missing_text = \"\")\n\n\n\n# --- Save the table (optional) ---\n# gtsave(coffee_table, filename = \"data/coffee-table.png\", zoom = 2)\n\n\n\n\nCode\n# --- Display the table ---\ncoffee_table|&gt; fmt_image(\"icon\", path=\"assets\") |&gt;  \n  # --- Add Nanoplot (Bar Chart) ---\n  cols_nanoplot(\n     columns = monthly_sales,\n     plot_type = \"bar\",\n     options = nanoplot_options(\n         data_bar_fill_color = \"steelblue\",\n         data_bar_stroke_color = \"steelblue\"\n     )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\n\nRevenue\n\n\nProfit\n\nnanoplots\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904K\n3%\n$568K\n4%\n\n\n     \n\n               765 0   521   494   596   613   667   748   765   686   607   594   568   751\n\n\n\n\n\nMoka pot\n$2.05M\n7%\n$181K\n1%\n\n\n     \n\n               6.87K 0   4.73K   4.74K   4.79K   5.51K   6.16K   6.62K   6.87K   6.03K   5.30K   4.88K   4.65K   6.28K\n\n\n\n\n\nCold brew\n$289K\n1%\n$242K\n2%\n\n\n     \n\n               2.70K 0   244   249   438   981   1.77K   2.70K   2.61K   2.35K   1.74K   896   499   244\n\n\n\n\n\nFilter\n$404K\n1%\n$70.0K\n0%\n\n\n     \n\n               2.74K 0   2.07K   1.81K   1.84K   2.12K   2.25K   2.63K   2.56K   2.37K   2.16K   2.19K   2.07K   2.74K\n\n\n\n\n\nDrip machine\n$2.63M\n9%\n$1.37M\n9%\n\n\n     \n\n               2.58K 0   2.14K   1.62K   1.97K   2.10K   2.58K   2.46K   2.34K   2.32K   2.05K   1.97K   1.84K   2.33K\n\n\n\n\n\nAeroPress\n$2.60M\n9%\n$1.29M\n9%\n\n\n     \n\n               9.27K 0   6.33K   5.20K   6.37K   7.02K   7.91K   8.70K   8.69K   7.80K   6.83K   6.96K   6.88K   9.27K\n\n\n\n\n\nPour over\n$846K\n3%\n$365K\n2%\n\n\n     \n\n               2.18K 0   1.56K   1.29K   1.51K   1.69K   1.94K   2.18K   2.14K   1.86K   1.72K   1.81K   1.60K   2.16K\n\n\n\n\n\nFrench press\n$1.11M\n4%\n$748K\n5%\n\n\n     \n\n               4.82K 0   3.51K   2.88K   3.35K   3.79K   3.90K   4.10K   4.18K   4.43K   3.28K   3.42K   3.30K   4.82K\n\n\n\n\n\nCezve\n$2.51M\n9%\n$1.97M\n13%\n\n\n     \n\n               17.1K 0   12.2K   11.5K   11.8K   13.6K   15.4K   16.5K   17.1K   14.4K   13.0K   12.9K   11.6K   15.9K\n\n\n\n\n\nChemex\n$3.14M\n11%\n$818K\n6%\n\n\n     \n\n               7.22K 0   4.94K   4.17K   5.24K   6.00K   6.36K   6.77K   7.11K   6.25K   5.60K   6.08K   4.98K   7.22K\n\n\n\n\n\nScale\n$3.80M\n13%\n$2.91M\n20%\n\n\n     \n\n               3.18K 0   1.54K   1.57K   1.68K   2.03K   2.43K   2.55K   2.57K   2.23K   2.04K   2.09K   1.69K   3.18K\n\n\n\n\n\nKettle\n$756K\n3%\n$618K\n4%\n\n\n     \n\n               1.53K 0   1.14K   1.02K   1.09K   1.13K   1.41K   1.48K   1.46K   1.30K   1.14K   1.23K   1.19K   1.53K\n\n\n\n\n\nEspresso Machine\n$8.41M\n29%\n$3.64M\n25%\n\n\n     \n\n               2.58K 0   686   840   618   598   2.15K   533   797   996   1.00K   668   858   2.58K\n\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3\nOriginal table:\n\n\nRPython\n\n\n\nPrompt\nwrite R code using GT package to recreate this table\n1.opt_align change to cols_align 2.cols_labels change to cols_label\n\n\ninput data\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\n# Create the data frame (replace with your actual data loading if needed)\ndata &lt;-read.csv(\"power-generation.csv\")\n\n\n\n\nmake GT table\n\n\nCode\n# Create the gt table\ngt_table &lt;- data %&gt;%\n  gt() %&gt;%\n  # Title and subtitle\n  tab_header(\n    title = md(\"2023 Mean **Carbon Intensity** (gCO2eq/kWh) and **Power Consumption** Breakdown (%)\")\n  ) %&gt;%\n  # Column labels\n  cols_label(\n    CO2.Intensity = \"CO2 Intensity\",\n    Hydro.Discharge = \"Hydro Discharge\",\n    Battery.Discharge = \"Battery Discharge\"\n  ) %&gt;%\n  # Format the numeric columns to have one decimal place\n  fmt_number(\n    columns = -Zone, # Apply to all columns except Zone\n    decimals = 1\n  ) %&gt;%\n  # Add a spanning header for the power consumption breakdown\n  # tab_spanner(\n  #   label = \"Power Consumption Breakdown (%)\",\n  #   columns = c(Hydro, Nuclear, Wind, Solar, Geothermal, Biomass, Gas, Coal, Oil, Unknown, Hydro.Discharge, Battery.Discharge)\n  # ) %&gt;%\n  # Add source note\n  tab_source_note(md(\"Source: [Your Data Source Information Here]\")) %&gt;%\n  # Add a footnote about the methodology\n  tab_footnote(\n    md(\"Some emissions factors are based on IPCC 2014 defaults, while some are based on more accurate regional factors.\")\n  ) %&gt;%\n  # Style the table (optional, customize as needed)\n   cols_align(align = \"center\") %&gt;%\n  opt_row_striping()\n\n# Display the table\ngt_table\n\n\n\n\n\n  \n    \n      2023 Mean Carbon Intensity (gCO2eq/kWh) and Power Consumption Breakdown (%)\n    \n    \n    \n      Zone\n      CO2 Intensity\n      Hydro\n      Nuclear\n      Wind\n      Solar\n      Geothermal\n      Biomass\n      Gas\n      Coal\n      Oil\n      Unknown\n      Hydro Discharge\n      Battery Discharge\n    \n  \n  \n    Sweden\n23.5\n0.4\n0.3\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    Iceland\n27.6\n0.7\n0.0\n0.0\n0.0\n0.3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    Quebec\n30.6\n0.9\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    France\n52.7\n0.1\n0.6\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Ontario\n72.6\n0.3\n0.5\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Finland\n87.2\n0.2\n0.4\n0.2\n0.0\n0.0\n0.1\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    Tasmania\n92.2\n0.7\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    New Zealand\n94.5\n0.6\n0.0\n0.1\n0.0\n0.2\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Belgium\n139.6\n0.0\n0.4\n0.2\n0.1\n0.0\n0.0\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n    West Denmark\n143.1\n0.2\n0.0\n0.5\n0.1\n0.0\n0.1\n0.1\n0.1\n0.0\n0.0\n0.0\n0.0\n    East Denmark\n147.6\n0.1\n0.1\n0.4\n0.1\n0.0\n0.1\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    Spain\n154.0\n0.1\n0.2\n0.2\n0.2\n0.0\n0.0\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n    South Australia\n185.8\n0.0\n0.0\n0.4\n0.2\n0.0\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.0\n    Great Britain\n199.8\n0.0\n0.2\n0.3\n0.1\n0.0\n0.1\n0.3\n0.0\n0.0\n0.0\n0.0\n0.0\n    California\n257.7\n0.1\n0.1\n0.1\n0.2\n0.0\n0.0\n0.4\n0.0\n0.0\n0.0\n0.0\n0.0\n    Netherlands\n272.8\n0.0\n0.0\n0.3\n0.2\n0.0\n0.1\n0.3\n0.1\n0.0\n0.0\n0.0\n0.0\n    New York ISO\n280.0\n0.2\n0.2\n0.0\n0.0\n0.0\n0.0\n0.5\n0.0\n0.0\n0.0\n0.0\n0.0\n    Italy (North)\n307.3\n0.2\n0.1\n0.0\n0.1\n0.0\n0.0\n0.4\n0.0\n0.0\n0.1\n0.0\n0.0\n    Texas\n383.2\n0.0\n0.1\n0.3\n0.1\n0.0\n0.0\n0.4\n0.1\n0.0\n0.0\n0.0\n0.0\n    Germany\n396.8\n0.1\n0.0\n0.3\n0.1\n0.0\n0.1\n0.1\n0.2\n0.0\n0.0\n0.0\n0.0\n    Western Australia\n433.3\n0.0\n0.0\n0.2\n0.2\n0.0\n0.0\n0.4\n0.3\n0.0\n0.0\n0.0\n0.0\n    Alberta\n438.9\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.7\n0.1\n0.0\n0.0\n0.0\n0.0\n    Victoria\n506.4\n0.1\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    New South Wales\n556.3\n0.0\n0.0\n0.1\n0.2\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    India (North)\n558.2\n0.2\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    Queensland\n607.0\n0.0\n0.0\n0.0\n0.2\n0.0\n0.0\n0.1\n0.7\n0.0\n0.0\n0.0\n0.0\n    South Africa\n701.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.8\n0.0\n0.0\n0.0\n0.0\n  \n  \n    \n      Source: [Your Data Source Information Here]\n    \n  \n  \n    \n       Some emissions factors are based on IPCC 2014 defaults, while some are based on more accurate regional factors.\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nReference:\nhttps://github.com/rich-iannone/great-tables-mini-workshop?tab=readme-ov-file"
  },
  {
    "objectID": "posts/docker/index.html",
    "href": "posts/docker/index.html",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "",
    "text": "A comprehensive introduction to Docker, covering essential commands, Dockerfiles, and an example of building and managing an RStudio Docker image.\nThis document provides a comprehensive introduction to Docker, a platform for developing, shipping, and running applications in containers. It covers the essential Docker commands for managing images and containers, from pulling and running images to stopping and deleting containers. The guide also explains the role of Dockerfiles in building custom images and provides a practical example of creating an RStudio image with Tidyverse pre-installed. This document is designed to be a helpful resource for anyone getting started with Docker."
  },
  {
    "objectID": "posts/docker/index.html#create-docker-file",
    "href": "posts/docker/index.html#create-docker-file",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "create Docker file",
    "text": "create Docker file\n\n\n\nCode\n\ntidyverse_4.3.3.Dockerfile\n\nFROM docker.io/library/ubuntu:jammy\n\nENV R_VERSION=\"4.3.3\"\nENV R_HOME=\"/usr/local/lib/R\"\nENV TZ=\"Etc/UTC\"\n\nCOPY scripts/install_R_source.sh /rocker_scripts/install_R_source.sh\nRUN /rocker_scripts/install_R_source.sh\n\nENV CRAN=\"https://p3m.dev/cran/__linux__/jammy/2024-04-23\"\nENV LANG=en_US.UTF-8\n\nCOPY scripts/bin/ /rocker_scripts/bin/\nCOPY scripts/setup_R.sh /rocker_scripts/setup_R.sh\nRUN /rocker_scripts/setup_R.sh\n\nCOPY scripts/install_tidyverse.sh /rocker_scripts/install_tidyverse.sh\nRUN /rocker_scripts/install_tidyverse.sh\n\nENV S6_VERSION=\"v2.1.0.2\"\nENV RSTUDIO_VERSION=\"2023.12.1+402\"\nENV DEFAULT_USER=\"rstudio\"\n\nCOPY scripts/install_rstudio.sh /rocker_scripts/install_rstudio.sh\nCOPY scripts/install_s6init.sh /rocker_scripts/install_s6init.sh\nCOPY scripts/default_user.sh /rocker_scripts/default_user.sh\nCOPY scripts/init_set_env.sh /rocker_scripts/init_set_env.sh\nCOPY scripts/init_userconf.sh /rocker_scripts/init_userconf.sh\nCOPY scripts/pam-helper.sh /rocker_scripts/pam-helper.sh\nRUN /rocker_scripts/install_rstudio.sh\n\nEXPOSE 8787\nCMD [\"/init\"]\n\nCOPY scripts/install_pandoc.sh /rocker_scripts/install_pandoc.sh\nRUN /rocker_scripts/install_pandoc.sh\n\nCOPY scripts/install_quarto.sh /rocker_scripts/install_quarto.sh\nRUN /rocker_scripts/install_quarto.sh\n\nCOPY scripts /rocker_scripts"
  },
  {
    "objectID": "posts/docker/index.html#bulid-docker-image-from-dockerfile",
    "href": "posts/docker/index.html#bulid-docker-image-from-dockerfile",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "bulid Docker image from dockerfile",
    "text": "bulid Docker image from dockerfile\n\n\nCode\ndocker build -f tidyverse_4.3.3.Dockerfile -t proj:myapp ."
  },
  {
    "objectID": "posts/docker/index.html#run-docker-image",
    "href": "posts/docker/index.html#run-docker-image",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "run Docker image",
    "text": "run Docker image\n\n\nCode\ndocker run -p 8787:8787 proj:myapp\n\n\nrun at backend\n\n\nCode\ndocker run -d proj:myapp\n\n\nRstuido server is open at: http://localhost:8787/\nuser name is rstudio\npassword is show on terminal"
  },
  {
    "objectID": "posts/docker/index.html#go-inside-docker-containers-with-containers-id",
    "href": "posts/docker/index.html#go-inside-docker-containers-with-containers-id",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "go inside docker containers with containers id",
    "text": "go inside docker containers with containers id\n\n\nCode\ndocker exec -it b28a1b8eeeb6 sh\n\n\nexit docker linux\n\n\nCode\nexit"
  },
  {
    "objectID": "posts/docker/index.html#stop-container-with-container-id",
    "href": "posts/docker/index.html#stop-container-with-container-id",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "stop container with container id",
    "text": "stop container with container id\n\n\nCode\ndocker stop b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#restart-container-with-container-id",
    "href": "posts/docker/index.html#restart-container-with-container-id",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "restart container with container id",
    "text": "restart container with container id\n\n\nCode\ndocker start b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#delete-a-stop-container",
    "href": "posts/docker/index.html#delete-a-stop-container",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "delete a stop container",
    "text": "delete a stop container\n\n\nCode\ndocker rm -f b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#delete-image-with-image-id",
    "href": "posts/docker/index.html#delete-image-with-image-id",
    "title": "Docker‰ΩøÁî®‰ªãÁªç",
    "section": "delete image with image id",
    "text": "delete image with image id\n\n\nCode\ndocker rmi -f 7e1a4e2d11e2"
  },
  {
    "objectID": "posts/AI_podcast/index.html",
    "href": "posts/AI_podcast/index.html",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "",
    "text": "A guide on transcribing podcast audio and generating summaries using AI, covering downloading MP3s, using mlx_whisper for transcription, and leveraging the Gemini 2.0 Flash model for summarization.\nThis document provides a comprehensive guide to transcribing podcast audio and generating summaries using a combination of AI tools. It outlines a multi-step process that includes downloading MP3 files from various podcast platforms, using the mlx_whisper model for accurate audio-to-text transcription, and then leveraging the Gemini 2.0 Flash model for summarization and correction of the transcribed text. The guide includes R code snippets for each step, making it a practical resource for anyone looking to automate the process of podcast transcription and summarization.\nArticle abstract for podcast like firstory/poddtoppen/Â∞èÂÆáÂÆôFM using mlx_whisper for transcription and Gemini 2.0 Flash for summarization\nCode\n#pak::pkg_install('tuneR')\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(av)"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model",
    "href": "posts/AI_podcast/index.html#define-model",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"‰Ω†ÊòØ‰∏Ä‰∏™‰∏≠ÊñáÔºåËã±ÊñáÔºåÂ®ÅÂ£´Âøå‰∏ìÂÆ∂\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model\n\n\n\n\nCode\n#testing model connection\nchat_result=chat_gemini_model$chat(\"hello\")\nchat_result\n\n\n\n\nCode\nchat_gemini_model$get_turns(include_system_prompt = TRUE)"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model",
    "href": "posts/AI_podcast/index.html#run-model",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt0=read_srt('text.srt')\nsrt_txt2=srt_txt0$subtitle|&gt; as.character()\n\n\n\n\nCode\nlength(srt_txt2)\n\n\n\n\nCode\nprompt_text=paste0('ËØ∑Áªô‰ª•‰∏ãÊñáÂ≠ó‰Ωú500Â≠óÂÜÖÊëòË¶ÅÔºö',srt_txt2)\nsummary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\nsummary_text |&gt; tibble() |&gt; write_delim('summary.txt')"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model-1",
    "href": "posts/AI_podcast/index.html#define-model-1",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"‰Ω†ÊòØ‰∏Ä‰∏™‰∏≠ÊñáÂíåËã±ÊñáÁöÑÂ®ÅÂ£´Âøå‰∏ìÂÆ∂\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model-1",
    "href": "posts/AI_podcast/index.html#run-model-1",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nprompt_text=paste0('ËØ∑Êõ¥Ê≠£‰ª•‰∏ãÊñáÂ≠óÁöÑÈîôÂà´Â≠óÔºåÂπ∂‰∏îÊîπÊ≠£ËÉ°‰∫ë‰∏∫Â£∂‰∫ëÔºåÂ∏åÊ∏∏ËÆ∞‰∏∫Â¨âÊ∏∏Âøå,Wish Jokey‰∏∫WhisJockey,‰∏çË¶ÅÁ©∫ÁôΩË°å',summary_text)\ncorrect_summary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\ncorrect_summary_text |&gt; str_replace_all('\\n\\n','\\n')|&gt; tibble() |&gt; write_delim('correct_summary2.txt')"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model-2",
    "href": "posts/AI_podcast/index.html#define-model-2",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"‰Ω†ÊòØ‰∏Ä‰∏™‰∏≠ÊñáÂíåËã±ÊñáÁöÑÂ®ÅÂ£´Âøå‰∏ìÂÆ∂\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #model = \"gemini-2.5-pro-exp-03-25\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model-2",
    "href": "posts/AI_podcast/index.html#run-model-2",
    "title": "‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt_format=read.delim('text.srt')\n\n\n\n\nCode\nprompt_text=paste0('‰∏ãÈù¢ÁöÑÂÜÖÂÆπÊòØsrtÊñáÊ°£„ÄÇËØ∑ÊåâÊØè5ÂàÜÈíüÂÅö‰∏Ä‰∏™ÊëòË¶ÅÔºåÂÜçÊõ¥Ê≠£‰ª•‰∏ãÊñáÂ≠óÔºåËÉ°‰∫ë‰∏∫Â£∂‰∫ëÔºåÂ∏åÊ∏∏ËÆ∞‰∏∫Â¨âÊ∏∏Âøå,Wish Jokey‰∏∫WhisJockey',srt_txt_format)\ncorrect_summary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\ncorrect_summary_text|&gt; tibble() |&gt; write_delim('correct_srt_summary.txt')"
  },
  {
    "objectID": "posts/GDP/index.html",
    "href": "posts/GDP/index.html",
    "title": "‰∏ñÁïåGDP",
    "section": "",
    "text": "This document demonstrates how to download and analyze global GDP data using R, utilizing the wbstats and WDI packages to retrieve and visualize various indicators from the World Bank.\nThis document provides a guide to downloading and analyzing global GDP data using R. It demonstrates how to use the wbstats and WDI packages to retrieve a variety of economic indicators from the World Bank, including GDP, GDP per capita, and the sectoral contributions of agriculture, industry, and services to GDP. The document includes R code for data acquisition, cleaning, and creating visualizations to compare the economic performance of different countries over time. The Python section is a placeholder for future content."
  },
  {
    "objectID": "posts/GDP/index.html#wbstats-package",
    "href": "posts/GDP/index.html#wbstats-package",
    "title": "‰∏ñÁïåGDP",
    "section": "wbstats package",
    "text": "wbstats package\n\n\nCode\n#install.packages(\"wbstats\")\nlibrary(wbstats)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\ndata from World Bank:https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n\n\nCode\nindustry_search_results &lt;- wbsearch(pattern = \"% of GDP\")\nprint(industry_search_results)\n\n\n\n\nCode\n# Define the indicators you want to download\n# \"NY.GDP.MKTP.CD\" for GDP (current US$)\n# \"NY.GDP.PCAP.CD\" for GDP per capita (current US$)\n\n#NV.AGR.TOTL.ZS Agriculture, forestry, and fishing, value added (% of GDP)\n#NV.IND.TOTL.ZS Industry (including construction), value added (% of GDP)\n#NV.SRV.TOTL.ZS Services, value added (% of GDP)\ngdp_indicators &lt;- c(\"NY.GDP.MKTP.CD\", \"NY.GDP.PCAP.CD\",\n                    \"NV.AGR.TOTL.ZS\",\"NV.IND.TOTL.ZS\",\"NV.SRV.TOTL.ZS\" )\n\n\n# Download the data\nworld_gdp_data &lt;- wb_data(\n  indicator = gdp_indicators,\n  start_date = 2000, # You can change the start and end years as needed\n  end_date = 2023\n)\n\n# Print the first few rows of the data to see the structure\nhead(world_gdp_data)\n\n# You can also use summary() to get a quick overview of the data\nsummary(world_gdp_data)\n\n# To get the data with country names, you can merge with wb_countries()\n#world_gdp_data_with_names &lt;- merge(world_gdp_data, wb_countries(), by = \"country_code\", all.x = TRUE)\n\n# Print the first few rows of the merged data\n#head(world_gdp_data_with_names)\n\n# Clean up the column names\nworld_gdp_data_with_names &lt;- world_gdp_data %&gt;%\n  rename(\n    GDP = NY.GDP.MKTP.CD,\n    GDP_per_capita = NY.GDP.PCAP.CD,\n    \n    Agriculture_of_GDP=NV.AGR.TOTL.ZS,\n    Industry_of_GDP=NV.IND.TOTL.ZS,\n    Services_of_GDP=NV.SRV.TOTL.ZS,\n    Year = date,\n    Country_Name = country\n  )\n\n# Select only the columns you need\nfinal_gdp_data &lt;- world_gdp_data_with_names %&gt;%mutate(total=Agriculture_of_GDP+Industry_of_GDP+Services_of_GDP)\n  \n\n# Print the first few rows of the final data\nhead(final_gdp_data)\n\n\n\n\nCode\n# Create the line chart\n\nchina_thailand_data=final_gdp_data |&gt; filter(Country_Name %in% c(\"China\", \"Thailand\",\"United States\",\"Japan\",\"Korea, Rep.\")) |&gt; mutate(Year=as.numeric(Year))\n\ngdp_per_capita_plot &lt;- ggplot(data = china_thailand_data, aes(x = Year, y = Services_of_GDP, color = Country_Name)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Services_of_GDP: China vs Thailand vs US\",\n    #subtitle = \"Services_of_GDP\",\n    x = \"Year\",\n    y = \"Services_of_GDP\",\n    color = \"Country_Name\"\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\ngdp_per_capita_plot\n\n\n\n\nCode\ngdp_per_capita_plot &lt;- ggplot(data = china_thailand_data, aes(x = Year, y = GDP_per_capita, color = Country_Name)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"GDP Per Capita: China vs Thailand\",\n    subtitle = \"Comparison of GDP per Capita (current US$)\",\n    x = \"Year\",\n    y = \"GDP Per Capita (USD)\",\n    color = \"Country_Name\"\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\ngdp_per_capita_plot"
  },
  {
    "objectID": "posts/GDP/index.html#wdi-package",
    "href": "posts/GDP/index.html#wdi-package",
    "title": "‰∏ñÁïåGDP",
    "section": "WDI package",
    "text": "WDI package\n\n\nCode\nlibrary(WDI)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n\n\nCode\n# Download GDP data from World Bank\ngdp_data &lt;- WDI(\n  country = \"all\",\n  indicator = c(\n    gdp = \"NY.GDP.MKTP.CD\",               # GDP (current US$)\n    gdp_per_capita = \"NY.GDP.PCAP.CD\",    # GDP per capita (current US$)\n    agriculture = \"NV.AGR.TOTL.ZS\",       # Agriculture value added (% of GDP)\n    industry = \"NV.IND.TOTL.ZS\",          # Industry value added (% of GDP)\n    services = \"NV.SRV.TOTL.ZS\"           # Services value added (% of GDP)\n  ),\n  start = 2000,\n  end = 2023,\n  extra = TRUE\n)"
  },
  {
    "objectID": "posts/GDP/index.html#imf",
    "href": "posts/GDP/index.html#imf",
    "title": "‰∏ñÁïåGDP",
    "section": "IMF",
    "text": "IMF"
  },
  {
    "objectID": "posts/password_management/index.html",
    "href": "posts/password_management/index.html",
    "title": "ÂØÜÁ†ÅÁÆ°ÁêÜ",
    "section": "",
    "text": "A guide to securely managing passwords in R and Python using various methods like local files, environment variables, and the keyring package.\nThis document explores various methods for securely managing passwords and other sensitive credentials in R and Python. For R, it presents three main options: sourcing a local R file, using environment variables, and leveraging the keyring package for more secure storage. For Python, it suggests a similar approach of importing credentials from a separate Python file. These techniques help you avoid hardcoding sensitive information directly in your scripts, improving the security and portability of your code.\nPassword management in R and Python"
  },
  {
    "objectID": "posts/password_management/index.html#option-1-using-source",
    "href": "posts/password_management/index.html#option-1-using-source",
    "title": "ÂØÜÁ†ÅÁÆ°ÁêÜ",
    "section": "Option 1 using source",
    "text": "Option 1 using source\n\ncreate pass.r and keep it yourself\n\n\n\nCode\n\npass.r\n\npass1='123'\n\n\n\n\n\nsource the pass.r in the main code\n\n\nCode\nsource('pass.r')\npass1\n\n\n[1] \"123\""
  },
  {
    "objectID": "posts/password_management/index.html#option-2-use-environment-variables",
    "href": "posts/password_management/index.html#option-2-use-environment-variables",
    "title": "ÂØÜÁ†ÅÁÆ°ÁêÜ",
    "section": "Option 2 Use Environment variables",
    "text": "Option 2 Use Environment variables\n\nopen /home/.Renviron\n\n\nCode\nusethis::edit_r_environ()\n\n\n\n\nsave following password in .Renviron\n\n\nCode\nfake_userid = \"username\"\nfake_pwd = \"password\"   \n\n\n\n\nget it back\n\n\nCode\nSys.getenv(\"fake_userid\")\n\n\n[1] \"username\"\n\n\nCode\nSys.getenv(\"fake_pwd\")\n\n\n[1] \"password\""
  },
  {
    "objectID": "posts/password_management/index.html#option-3-using-keyringr-package",
    "href": "posts/password_management/index.html#option-3-using-keyringr-package",
    "title": "ÂØÜÁ†ÅÁÆ°ÁêÜ",
    "section": "Option 3 using keyringr package",
    "text": "Option 3 using keyringr package\n\n\nCode\npak::pak(\"keyring\")\n\n\n\n\nCode\nlibrary(keyring)\n\n\n\n\nCode\n# Interactively save a secret. This avoids typing the value of the secret\n# into the console as this could be recorded in your `.Rhistory`\nkey_set(\"account_fake_001\")\n\n\n\n\nCode\n# Later retrieve that secret\nkey_get(\"account_fake_001\")"
  },
  {
    "objectID": "posts/password_management/index.html#option-1-using-import",
    "href": "posts/password_management/index.html#option-1-using-import",
    "title": "ÂØÜÁ†ÅÁÆ°ÁêÜ",
    "section": "Option 1 using import",
    "text": "Option 1 using import\n\ncreate pass_file.py and keep it yourself\n\n\n\nCode\n\npass_file.py\n\npass1='123'\n\n\n\n\n\ncall pass_file.py with import\n\n\nCode\nfrom pass_file import *\n#from pass_file import acct\npass_w\n\n\n'123'\n\n\nCode\nacct_w\n\n\n'222'"
  },
  {
    "objectID": "posts/AI_OCR/index.html",
    "href": "posts/AI_OCR/index.html",
    "title": "AIÂõæÁâáËØÜÂà´ÊñáÂ≠ó",
    "section": "",
    "text": "A demonstration of how to perform OCR using both online (Gemini 2.5) and offline (InternVL3 1B) AI models, with Python code examples for text extraction from images in both English and Chinese.\nThis document demonstrates how to perform Optical Character Recognition (OCR) using both online and offline AI models. It provides Python code examples for extracting text from images in both English and Chinese using the Gemini 2.5 API. Additionally, it includes instructions and code for setting up and using the InternVL3 1B model locally, including functions for image preprocessing and model splitting. This guide is a valuable resource for anyone looking to implement OCR in their projects.\nwith Gemini 2.5 online/InternVL3 offline"
  },
  {
    "objectID": "posts/AI_OCR/index.html#english-extract",
    "href": "posts/AI_OCR/index.html#english-extract",
    "title": "AIÂõæÁâáËØÜÂà´ÊñáÂ≠ó",
    "section": "English Extract",
    "text": "English Extract\n\n\n\nCode\nimage = Image.open(\"images/english.jpg\")\n\nresponse_gemini_en = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[image, \"Extract text from image\"])\n\n\n\n\nCode\nprint(response_gemini_en.text)\n\n\nWrite slowly and take the time\nto make sure each letter\nis the perfect shape"
  },
  {
    "objectID": "posts/AI_OCR/index.html#chinese-extract",
    "href": "posts/AI_OCR/index.html#chinese-extract",
    "title": "AIÂõæÁâáËØÜÂà´ÊñáÂ≠ó",
    "section": "Chinese Extract",
    "text": "Chinese Extract\n\n\n\nCode\nimage = Image.open(\"images/chinese.png\")\n\nresponse_gemini = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[image, \"ÊèêÂèñÂõæ‰∏äÁöÑÊñáÂ≠ó\"])\n\n\n\n\nCode\nprint(response_gemini.text)\n\n\nÊîæÂÖª\n\nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç\nÊîæÂÖªÂú®ÂèØÂèØË•øÈáåÁöÑËçâÂéü‰∏äÔºå\nËóèÈõ™ÁãêÊ¥ªÊ≥ºÊ≤°‰∫∫Áà±‰∫∫\nÊàë‰∏éÂÆÉÊçâËø∑Ëóè\n\nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠ÇÔºå\nÊîæÂÖªÂú®ÊííÂìàÊãâÊ≤ôÊº†‰∏äÔºå\nÁúãÁîüÂëΩÂú®Ë¥´Áò†ÁöÑÂúüÂú∞‰∏äÔºå\n‰æùÁÑ∂Ê¨£Ê¨£ÂêëËç£Âú∞ÁîüÈïø\n\nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç\nÊîæÂÖªÂú®ÊòèÈªÑÈÅóËøπÁöÑÂ∞èÂ≤õ\nÂùê‰∏äÊòüÊúü‰∫îÁöÑÊú®Á≠è\nÂãáÊï¢Âú∞‰πòÈ£éÁ†¥Êµ™\n\nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç\nÊîæÂÖªÂú®Â§©Ê∂ØÊµ∑Ëßí\nÂ∞±ËÆ©ÊàëËá™Áî±Âú∞ÂéªÊµÅÊµ™„ÄÇ"
  },
  {
    "objectID": "posts/AI_OCR/index.html#single-image-single-round-conversation-ÂçïÂõæÂçïËΩÆÂØπËØù",
    "href": "posts/AI_OCR/index.html#single-image-single-round-conversation-ÂçïÂõæÂçïËΩÆÂØπËØù",
    "title": "AIÂõæÁâáËØÜÂà´ÊñáÂ≠ó",
    "section": "single-image single-round conversation (ÂçïÂõæÂçïËΩÆÂØπËØù)",
    "text": "single-image single-round conversation (ÂçïÂõæÂçïËΩÆÂØπËØù)\n\n\nCode\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.225)\n\ndef build_transform(input_size):\n    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n        T.ToTensor(),\n        T.Normalize(mean=MEAN, std=STD)\n    ])\n    return transform\n\ndef find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n    best_ratio_diff = float('inf')\n    best_ratio = (1, 1)\n    area = width * height\n    for ratio in target_ratios:\n        target_aspect_ratio = ratio[0] / ratio[1]\n        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n        if ratio_diff &lt; best_ratio_diff:\n            best_ratio_diff = ratio_diff\n            best_ratio = ratio\n        elif ratio_diff == best_ratio_diff:\n            if area &gt; 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n                best_ratio = ratio\n    return best_ratio\n\ndef dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n    orig_width, orig_height = image.size\n    aspect_ratio = orig_width / orig_height\n\n    # calculate the existing image aspect ratio\n    target_ratios = set(\n        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n        i * j &lt;= max_num and i * j &gt;= min_num)\n    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n\n    # find the closest aspect ratio to the target\n    target_aspect_ratio = find_closest_aspect_ratio(\n        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n\n    # calculate the target width and height\n    target_width = image_size * target_aspect_ratio[0]\n    target_height = image_size * target_aspect_ratio[1]\n    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n\n    # resize the image\n    resized_img = image.resize((target_width, target_height))\n    processed_images = []\n    for i in range(blocks):\n        box = (\n            (i % (target_width // image_size)) * image_size,\n            (i // (target_width // image_size)) * image_size,\n            ((i % (target_width // image_size)) + 1) * image_size,\n            ((i // (target_width // image_size)) + 1) * image_size\n        )\n        # split the image\n        split_img = resized_img.crop(box)\n        processed_images.append(split_img)\n    assert len(processed_images) == blocks\n    if use_thumbnail and len(processed_images) != 1:\n        thumbnail_img = image.resize((image_size, image_size))\n        processed_images.append(thumbnail_img)\n    return processed_images\n\ndef load_image(image_file, input_size=448, max_num=12):\n    image = Image.open(image_file).convert('RGB')\n    transform = build_transform(input_size=input_size)\n    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n    pixel_values = [transform(image) for image in images]\n    pixel_values = torch.stack(pixel_values)\n    return pixel_values\n\ndef split_model(model_name):\n    device_map = {}\n    world_size = torch.cuda.device_count()\n    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n    num_layers = config.llm_config.num_hidden_layers\n    # Since the first GPU will be used for ViT, treat it as half a GPU.\n    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n    layer_cnt = 0\n    for i, num_layer in enumerate(num_layers_per_gpu):\n        for j in range(num_layer):\n            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n            layer_cnt += 1\n    device_map['vision_model'] = 0\n    device_map['mlp1'] = 0\n    device_map['language_model.model.tok_embeddings'] = 0\n    device_map['language_model.model.embed_tokens'] = 0\n    device_map['language_model.output'] = 0\n    device_map['language_model.model.norm'] = 0\n    device_map['language_model.model.rotary_emb'] = 0\n    device_map['language_model.lm_head'] = 0\n    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n\n    return device_map\n\n\n\nEnglish Extract\n\n\n\nCode\npixel_values = load_image('images/english.jpg').to(torch.bfloat16)\nquestion = '&lt;image&gt;\\nPlease Extract text from image'\nresponse_en = model.chat(tokenizer, pixel_values, question, generation_config)\n\n\n\n\nCode\nprint(response_en)\n\n\nWrite slowly and take the time to make sure each letter is the perfect shape\n\n\n\n\nChinese Extract\n\n\n\nCode\npixel_values = load_image('images/chinese.png').to(torch.bfloat16)\n\nquestion = '&lt;image&gt;\\nÊèêÂèñÂõæ‰∏äÁöÑÊñáÂ≠ó'\nresponse = model.chat(tokenizer, pixel_values, question, generation_config)\n\n\n\n\nCode\nprint(response)\n\n\nÊîæÂÖª  \nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç  \nÊîæÂú®‰∫ÜÈÑÇË•øË•øÈáåÁöÑËçâÂéü‰∏äÔºå  \nËóèÈõ™ÁãêÊ¥ªÂèëÁà±‰∫∫  \nÊàë‰∏éÂÆÉÊçâËø∑Ëóè  \nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç  \nÊîæÂú®ÊííÂìàÊãâÊ≤ôÊº†‰∏äÔºå  \nÁúãÁîüÂëΩÂú®Ë¥´Áò†ÁöÑÂúüÂú∞‰∏äÔºå  \n‰æùÁÑ∂Ê¨£Ê¨£Ê¨£Ëç£Âú∞ÁîüÈïø  \nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç  \nÊîæÂú®È≤ÅÊª®ÈÄäÁöÑÂ∞èÂ≤õ‰∏ä  \nÂùê‰∏äÊòüÊúü‰∫îÁöÑÊú®Á≠è  \nÂãáÊï¢Âú∞‰πòÈ£éÁ†¥Êµ™  \n\nÊääÊàë‰∏çÁæÅÁöÑÁÅµÈ≠Ç  \nÊîæÂÖªÂú®Â§©Ê∂ØÊµ∑Ëßí  \nËÆ©ÊàëËá™Áî±Âú∞ÂéªÊµÅÊµ™„ÄÇ"
  },
  {
    "objectID": "posts/CPUGPU/index.html",
    "href": "posts/CPUGPU/index.html",
    "title": "CPU and GPU",
    "section": "",
    "text": "Provides resources for checking CPU and GPU performance, including local and global benchmarks.\nThis document serves as a resource hub for checking CPU and GPU performance. It provides information and tools for evaluating the performance of both your local machine and comparing it with global benchmarks. The document includes embedded HTML iframes to display local CPU, GPU OpenCL, and GPU Metal performance, as well as links to Geekbench benchmarks for worldwide comparisons. This is a valuable resource for anyone interested in understanding and comparing the performance of their hardware.\nCPU & GPU Performance\n\nlocal computer CPU and GPU info\n\nCPUGPU OpenCL PerformanceGPU Metal Performance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld computer CPU and GPU info\n\nCPUGPU OpenCL PerformanceGPU Metal Performance\n\n\nhttps://browser.geekbench.com/v6/cpu/multicore\n\n\n\nhttps://browser.geekbench.com/opencl-benchmarks\n\n\n\nhttps://browser.geekbench.com/metal-benchmarks\n\n\n\n\n\n\nReference\nhttps://www.geekbench.com/\nhttps://github.com/ProjectPhysX/OpenCL-Benchmark"
  },
  {
    "objectID": "posts/Classification Metrics/index.html",
    "href": "posts/Classification Metrics/index.html",
    "title": "Classification Metrics",
    "section": "",
    "text": "A comprehensive guide to classification metrics in Python, covering concepts like sensitivity, precision, AUROC, and F1-score with practical code examples.\nThis document provides a comprehensive guide to understanding and implementing various classification metrics in Python. It covers key concepts such as sensitivity, precision, AUROC, accuracy, F1-score, and specificity. The guide includes practical code examples that walk you through the entire process, from installing the necessary packages and loading data from Kaggle to training a logistic regression model and visualizing the results with a confusion matrix and ROC/PR curves. This is an essential resource for anyone looking to evaluate the performance of their classification models.\nClassification Metrics Explained | Sensitivity, Precision, AUROC, & More\n\ninstall package\n\n\nCode\npip install -U scikit-learn\npip install -U kaggle\npip install -U kagglehub\n\n\n\n\nload package\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\n\n#from kaggle.api.kaggle_api_extended import KaggleApi\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    precision_score, recall_score, roc_curve,\n    accuracy_score, f1_score, roc_auc_score,\n    average_precision_score, confusion_matrix,\n    precision_recall_curve\n)\n\n\n\n\ndownload data from kaggle\n\n\nCode\nimport kagglehub\n# Download latest version\nkagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\npath = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\nprint(\"Path to dataset files:\", path)\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.12).\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/jinchaoduan/.cache/kagglehub/datasets/uciml/pima-indians-diabetes-database/versions/1\n\n\nshow data file under download folder\n\n\nCode\nimport os\nos.listdir(path)\n\n\n['diabetes.csv']\n\n\n\n\nread data\n\n\nCode\ndf = pd.read_csv(path+'/'+os.listdir(path)[0])\ndf.head()\n\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\n\nCode\ndf.Outcome.value_counts()\n\n\nOutcome\n0    500\n1    268\nName: count, dtype: int64\n\n\n\n\nCode\n# separate features from response\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\n\n\n\n\nCode\n# split data into test and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n\n\nCode\n# initialize and train logistic regression model\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n\nLogisticRegression(max_iter=1000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(max_iter=1000) \n\n\n\n\nCode\n# predict on the test set and get the probas\ny_pred = model.predict(X_test)\ny_pred_proba = model.predict_proba(X_test)[:, 1] \n\n\n\n\nCode\n# quickly look at the distribution of the probas\npercentiles = np.percentile(y_pred_proba, [5, 25, 50, 75, 95])\npercentiles\n\n\narray([0.03455652, 0.11989883, 0.29954411, 0.64776581, 0.87083353])\n\n\n\n\nconfusion matrix\n\n\nCode\n# generate confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.xticks([0.5, 1.5], ['No Diabetes', 'Diabetes'])\nplt.yticks([0.5, 1.5], ['No Diabetes', 'Diabetes'], va='center')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# recall / sensitivity\nrecall = recall_score(y_test, y_pred)\nrecall\n\n\n0.6727272727272727\n\n\n\n\nCode\n# precision / positive predictive value\nprecision = precision_score(y_test, y_pred)\nprecision\n\n\n0.6379310344827587\n\n\n\n\nCode\n# specificity\ntn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\nspecificity = tn / (tn + fp)\nspecificity\n\n\nnp.float64(0.7878787878787878)\n\n\n\n\nCode\n# accuracy\naccuracy = accuracy_score(y_test, y_pred)\naccuracy\n\n\n0.7467532467532467\n\n\n\n\nCode\n# f1\nf1 = f1_score(y_test, y_pred)\nf1\n\n\n0.6548672566371682\n\n\n\n\nCode\n# get ROC curve values\nfpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n\n# get PR curve values\nprecision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n\n# get areas under the curves\nauroc = roc_auc_score(y_test, y_pred_proba)\npr_auc = average_precision_score(y_test, y_pred_proba)\n\n\n\n\nCode\n# plot both curves\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\nax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auroc:.2f}')\nax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate')\nax1.set_title('Receiver Operating Characteristic (ROC) Curve')\nax1.legend(loc=\"lower right\")\n\n# Plot Precision-Recall Curve\nax2.plot(recall, precision, color='purple', lw=2, label=f'PR-AUC = {pr_auc:.2f}')\nax2.set_xlabel('Recall')\nax2.set_ylabel('Precision')\nax2.set_title('Precision-Recall Curve')\nax2.legend(loc=\"lower left\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_test.value_counts()\n\n\nOutcome\n0    99\n1    55\nName: count, dtype: int64\n\n\n\n\nReference\nhttps://www.youtube.com/watch?v=KdUrfY1yM0w\nhttps://github.com/RichardOnData/YouTube/blob/main/Python%20Notebooks/classification_metrics.ipynb"
  },
  {
    "objectID": "posts/multi language blog/index.html",
    "href": "posts/multi language blog/index.html",
    "title": "Â§öËØ≠Ë®Ä quarto blog",
    "section": "",
    "text": "A guide to creating a multi-language Quarto blog using the babelquarto R package.\nThis document provides a step-by-step guide to creating a multi-language blog using Quarto and the babelquarto R package. It covers the entire process, from installing and loading the necessary packages to setting up the main and additional languages. The guide also explains how to modify the _quarto.yml file for language-specific configurations, create new language versions of your .qmd files, and render the final website. It also suggests using LLMs for translation to streamline the content creation process."
  },
  {
    "objectID": "posts/multi language blog/index.html#add-site-url-to-system-environment-before-render",
    "href": "posts/multi language blog/index.html#add-site-url-to-system-environment-before-render",
    "title": "Â§öËØ≠Ë®Ä quarto blog",
    "section": "7.1 add site url to system environment before render",
    "text": "7.1 add site url to system environment before render\n\n\nCode\nSys.setenv(BABELQUARTO_CI_URL=\"https://jcfly3000.github.io/into_AI/\")\n\n\n\n\nCode\nSys.getenv(\"BABELQUARTO_CI_URL\")"
  },
  {
    "objectID": "posts/multi language blog/index.html#we-use-babelquartorender_website.",
    "href": "posts/multi language blog/index.html#we-use-babelquartorender_website.",
    "title": "Â§öËØ≠Ë®Ä quarto blog",
    "section": "7.2 we use babelquarto::render_website().",
    "text": "7.2 we use babelquarto::render_website().\nwe need to render the .qmd files to HTML. If you are used to using Quarto, you may expect to do this with quarto render or quarto preview, but those do not work with babelquarto.\n\n\nCode\nbabelquarto::render_website()"
  },
  {
    "objectID": "posts/path_managment/index.html",
    "href": "posts/path_managment/index.html",
    "title": "Ë∑ØÂæÑÁÆ°ÁêÜ",
    "section": "",
    "text": "A guide to managing file paths in R and Python, with a focus on the fs and here packages in R.\nThis document addresses the common challenge of managing file paths across different operating systems, such as Windows and Mac. It provides a guide to using dedicated packages in R and Python to handle file paths in a robust and reproducible way. The R section focuses on the fs package for a wide range of file system operations and the here package for creating project-relative paths that work seamlessly across different environments. The Python section is a placeholder for future content.\nSince windows and mac have different file path, we use package to manage the file path."
  },
  {
    "objectID": "posts/path_managment/index.html#fs-pacakge",
    "href": "posts/path_managment/index.html#fs-pacakge",
    "title": "Ë∑ØÂæÑÁÆ°ÁêÜ",
    "section": "fs pacakge",
    "text": "fs pacakge\n\n\nCode\n#pak::pkg_install('here')\n#pak::pkg_install('fs')\nlibrary(fs)\n\n\n\n\nCode\ngetwd()\n\n\n\nlist file in the current directory\n\n\nCode\ndir_ls()\n\n\n\n\nshow the current directory file info\n\n\nCode\ndir_info()\n\n\n\n\nshow the current directory file tree\n\n\nCode\ndir_tree()\n\n\n\n\ncreate a new temp directory\n\n\nCode\n# create a new directory\ntmp &lt;- dir_create(file_temp())\ntmp\n\n\n\n\ncreate new files in that directory\n\n\nCode\n# create new files in that directory\nfile_create(path(tmp, \"my-file.txt\"))\ndir_ls(tmp)\n\n\n\n\nremove files from the directory\n\n\nCode\n# remove files from the directory\nfile_delete(path(tmp, \"my-file.txt\"))\ndir_ls(tmp)\n\n\n\n\nremove the directory\n\n\nCode\n# remove the directory\ndir_delete(tmp)"
  },
  {
    "objectID": "posts/path_managment/index.html#here-package",
    "href": "posts/path_managment/index.html#here-package",
    "title": "Ë∑ØÂæÑÁÆ°ÁêÜ",
    "section": "here package",
    "text": "here package\n\n\nCode\nlibrary(here)\n\n\n\nshow project directory\n\n\nCode\nhere()\n\n\n\n\nshow all file in the project directory\n\n\nCode\nlist.files(here())\n\n\n\n\nshow one file path\nhere.png in images folder\n\n\nCode\nimage_path=here('posts/path_managment/images','here.png')\nimage_path"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html",
    "href": "posts/download yotube on iphone or ipad/index.html",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "",
    "text": "Instructions on how to download YouTube videos on iOS devices using the a-Shell mini app and the SW-DLT shortcut.\nThis document provides a step-by-step guide on how to download YouTube videos on iOS devices. It outlines two primary methods: using the a-Shell mini app to install and run youtube-dl, and using the SW-DLT shortcut for a more automated experience. The guide includes instructions for installing the necessary tools and running the download commands.\nÈ¶ñÂÖàÈúÄË¶ÅÁ°ÆËÆ§‰Ω†ÁöÑiphoneÊàñipadÊòØÂèØ‰ª•ËøûÊé•youtubeÁöÑ„ÄÇ"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#Áî®iphoneÊàñipad‰∏ãËΩΩ-a-shell-mini-app",
    "href": "posts/download yotube on iphone or ipad/index.html#Áî®iphoneÊàñipad‰∏ãËΩΩ-a-shell-mini-app",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "1. Áî®iphoneÊàñipad‰∏ãËΩΩ a-Shell mini app",
    "text": "1. Áî®iphoneÊàñipad‰∏ãËΩΩ a-Shell mini app\n\nhttps://apps.apple.com/us/app/a-shell-mini/id1543537943"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#ÊâìÂºÄa-shell-miniËøêË°å‰ª•‰∏ã‰ª£Á†ÅÂÆâË£Öyoutube-dl",
    "href": "posts/download yotube on iphone or ipad/index.html#ÊâìÂºÄa-shell-miniËøêË°å‰ª•‰∏ã‰ª£Á†ÅÂÆâË£Öyoutube-dl",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "2. ÊâìÂºÄa-shell miniËøêË°å‰ª•‰∏ã‰ª£Á†ÅÂÆâË£Öyoutube-dl",
    "text": "2. ÊâìÂºÄa-shell miniËøêË°å‰ª•‰∏ã‰ª£Á†ÅÂÆâË£Öyoutube-dl\n\n\nCode\npip install youtube-dl\n\n\nÂ¶ÇÊûúÊÉ≥Ë¶Å‰∏ãËΩΩÈ´òÊ∏ÖËßÜÈ¢ëÂÜçËøêË°å‰ª•‰∏ã‰ª£Á†ÅÔºàÂèØÈÄâÔºâÔºö\n\n\nCode\npip install gallery-dl\nmkdir bin\ncd bin\ncurl -L https://github.com/holzschu/a-Shell-commands/releases/download/0.1/ffmpeg.wasm -o ffmpeg.wasm"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#Âú®a-shell-mini‰∏≠Áî®youtube-dl‰∏ãËΩΩyoutubeËßÜÈ¢ë",
    "href": "posts/download yotube on iphone or ipad/index.html#Âú®a-shell-mini‰∏≠Áî®youtube-dl‰∏ãËΩΩyoutubeËßÜÈ¢ë",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "3. Âú®a-shell mini‰∏≠Áî®youtube-dl‰∏ãËΩΩyoutubeËßÜÈ¢ë",
    "text": "3. Âú®a-shell mini‰∏≠Áî®youtube-dl‰∏ãËΩΩyoutubeËßÜÈ¢ë\nÊâæÂà∞‰Ω†ÊÉ≥Ë¶Å‰∏ãËΩΩÁöÑyoutubeËßÜÈ¢ëÁΩëÁ´ôÂú∞ÂùÄÔºåÂú®a-shell miniÈáåËøêË°å‰ª•‰∏ã‰ª£Á†Å\n\n\nCode\nyoutube-dl https://www.youtube.com/watch?v=FT3ODSg1GFE"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#‰ΩøÁî®shortcut-appÈáåÁöÑsw-dltËá™Âä®‰∏ãËΩΩÂèØÈÄâ",
    "href": "posts/download yotube on iphone or ipad/index.html#‰ΩøÁî®shortcut-appÈáåÁöÑsw-dltËá™Âä®‰∏ãËΩΩÂèØÈÄâ",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "4. ‰ΩøÁî®shortcut appÈáåÁöÑSW-DLTËá™Âä®‰∏ãËΩΩ(ÂèØÈÄâ)",
    "text": "4. ‰ΩøÁî®shortcut appÈáåÁöÑSW-DLTËá™Âä®‰∏ãËΩΩ(ÂèØÈÄâ)\nÂ¶ÇÊûú‰Ω†ËßâÂæóÊØèÊ¨°ÈÉΩË¶ÅÂú®a-shell miniÈáåÊâìÈÇ£‰πàÈïøÁöÑ‰ª£Á†Å„ÄÇ‰πüÂèØ‰ª•‰ΩøÁî®shortcut app„ÄÇ\nÁî®iphoneÊàñipadÊâ´Êèè‰∏ãÈù¢‰∫åÁª¥Á†Å‰∏ãËΩΩSW-DLT\n\n‰ΩøÁî®ÊñπÊ≥ïÔºö\n1.Â§çÂà∂Ë¶Å‰∏ãËΩΩÁöÑyoutubeËßÜÈ¢ëËøûÊé•\n2.ÊâìÂºÄshrotcut appÁÇπÂáªSW-DLTÂ∞±‰ºöÂºÄÂßãËá™Âä®‰∏ãËΩΩ‰∫Ü\nÊâìÂºÄshrotcut appÔºö\n\nÁÇπÂáªSW-DLTÔºö"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#reference",
    "href": "posts/download yotube on iphone or ipad/index.html#reference",
    "title": "‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube",
    "section": "Reference",
    "text": "Reference\n3 Ways to Run youtube-dl on iOS :https://chrunos.com/youtube-dl-ios/\nSW-DLT:https://routinehub.co/shortcut/7284/"
  },
  {
    "objectID": "posts/copilot/index.html",
    "href": "posts/copilot/index.html",
    "title": "AI Code assistant",
    "section": "",
    "text": "An introduction to AI code assistants, focusing on setting up and using GitHub Copilot in RStudio.\nThis document provides an introduction to AI-powered code assistants, with a specific focus on setting up and using GitHub Copilot within the RStudio IDE. It walks through the necessary steps to enable and configure Copilot, and also mentions other relevant tools like Codeium Copilot for Positron and the chores and gander R packages. This guide is a great starting point for anyone looking to leverage AI to enhance their coding workflow.\nAI tool for writing code"
  },
  {
    "objectID": "posts/copilot/index.html#step-1-enable-on-rstudio",
    "href": "posts/copilot/index.html#step-1-enable-on-rstudio",
    "title": "AI Code assistant",
    "section": "Step 1 Enable on RStudio",
    "text": "Step 1 Enable on RStudio"
  },
  {
    "objectID": "posts/copilot/index.html#step-2-configure-on-github",
    "href": "posts/copilot/index.html#step-2-configure-on-github",
    "title": "AI Code assistant",
    "section": "Step 2 configure on github",
    "text": "Step 2 configure on github\nfree account is limited per month"
  },
  {
    "objectID": "posts/regular_expression/index.html",
    "href": "posts/regular_expression/index.html",
    "title": "Ê≠£ÂàôË°®ËææÂºè‰ª£Á†Å",
    "section": "",
    "text": "A guide to using regular expressions in R and Python for pattern matching and extraction.\nThis document serves as a practical guide to using regular expressions (regex) in both R and Python. It provides a series of examples demonstrating how to perform common tasks such as extracting numbers, capturing text between specific delimiters, and matching complex patterns, including those with special characters. The R section utilizes the stringr package for its intuitive functions, while the Python section is a placeholder for future content."
  },
  {
    "objectID": "posts/regular_expression/index.html#view",
    "href": "posts/regular_expression/index.html#view",
    "title": "Ê≠£ÂàôË°®ËææÂºè‰ª£Á†Å",
    "section": "view",
    "text": "view\n\n\nCode\nlibrary(stringr)\n\n\n\n\nCode\nlibrary(stringr)\npattern='cat'\nstr_view_all(\"The cat sat on the mat with another cat.\", pattern)"
  },
  {
    "objectID": "posts/regular_expression/index.html#extract-all-numbers-from-a-string",
    "href": "posts/regular_expression/index.html#extract-all-numbers-from-a-string",
    "title": "Ê≠£ÂàôË°®ËææÂºè‰ª£Á†Å",
    "section": "Extract all numbers from a string:",
    "text": "Extract all numbers from a string:\n\n\nCode\npattern=\"\\\\d+\"\nstr_view(\"I bought 3 apples, 12 bananas, and 5 oranges.\",pattern)\n\n\n\n\nCode\nstr_extract_all(\"I bought 3 apples, 12 bananas, and 5 oranges.\", pattern) |&gt; unlist()"
  },
  {
    "objectID": "posts/regular_expression/index.html#extract-string-between-two-string",
    "href": "posts/regular_expression/index.html#extract-string-between-two-string",
    "title": "Ê≠£ÂàôË°®ËææÂºè‰ª£Á†Å",
    "section": "Extract string between two string:",
    "text": "Extract string between two string:\n\n\nCode\na &lt;- \"STR1 11111 STR2 STR1 22222 STR2,\"\nres &lt;- str_extract_all(a, \"STR1\\\\s*(.*?)\\\\s*STR2\")\nres\n\na=res |&gt; unlist()\n\nprint(paste0(\"first match: \",a[1]))\n      \nprint(paste0(\"second match: \",a[2]))"
  },
  {
    "objectID": "posts/regular_expression/index.html#match-sperical",
    "href": "posts/regular_expression/index.html#match-sperical",
    "title": "Ê≠£ÂàôË°®ËææÂºè‰ª£Á†Å",
    "section": "match sperical",
    "text": "match sperical\nregular expression for getting string between ‚Äò/‚Äô and ‚Äô\\(' on \"The /1234cat\\) sat on the 1245ma with another 4444ee cat.‚Äù\n\n\nCode\npattern= \"/(.*?)\\\\$\"\nstr_view_all(\"The /1234cat$ sat on the 1245ma with another 4444ee cat.\", pattern)\n\n\n\n\nCode\npattern= \"/(.*?)\\\\$\"\nmatches &lt;- str_extract_all(\"The /1234cat$ sat on the 1245ma with another 4444ee cat.\",pattern)\nmatches"
  },
  {
    "objectID": "posts/usefullresource/index.html",
    "href": "posts/usefullresource/index.html",
    "title": "Useful resource",
    "section": "",
    "text": "A curated list of valuable resources, focusing on YouTube channels dedicated to R programming and data science.\nThis document provides a curated list of valuable resources for anyone interested in R programming and data science. It focuses on a selection of high-quality YouTube channels that offer tutorials, case studies, and expert insights into various aspects of the R ecosystem. This is a great starting point for both beginners and experienced users who are looking to expand their knowledge and skills.\nA curated list of helpful resources, specifically YouTube channels related to R programming and data science.\nSome useful resource\n\nYoutube\n\nRProgramming101\n\nPositPBC\n\nJuliaSilge\n\n\n\nthecoatlessprofessor\n\n\n\nEquitableEquations"
  },
  {
    "objectID": "posts/github trend/index.html",
    "href": "posts/github trend/index.html",
    "title": "Github trend",
    "section": "",
    "text": "github tending project since 2024.\n\n\nload package\n\n\nCode\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(tidyverse)\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter()  masks stats::filter()\n‚úñ purrr::flatten() masks jsonlite::flatten()\n‚úñ dplyr::lag()     masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(plotly)\n\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:httr':\n\n    config\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nlibrary(scales)\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n\nget data\n\n\nCode\n# Install if needed\n# install.packages(c(\"httr\", \"jsonlite\"))\n\n# Calculate the date one week ago\n#since &lt;- format(Sys.Date() - 30, \"%Y-%m-%d\")\n\nsince &lt;- \"2024-01-01\"\n\n# Query GitHub search API for repos created in the last week, ordered by stars\nres &lt;- GET(\n  url = \"https://api.github.com/search/repositories\",\n  query = list(\n    q = paste0(\"created:&gt;\", since),\n    sort = \"stars\",\n    order = \"desc\",\n    per_page = 20\n  ),\n  add_headers(Accept = \"application/vnd.github.v3+json\")\n)\n\nstop_for_status(res)\ndata &lt;- content(res, as = \"parsed\", simplifyVector = TRUE)\n\n# Extract details\ntop &lt;- data$items\ndf &lt;- data.frame(\n  name        = top$full_name,\n  stars       = top$stargazers_count,\n  forks       = top$forks_count,\n  watchers    = top$watchers_count,\n  created_at  = top$created_at,\n  summary     = top$description,\n  url         = top$html_url,\n  stringsAsFactors = FALSE\n)\n\nglimpse(df)\n\n\nRows: 20\nColumns: 7\n$ name       &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\", \"deepseek-ai/DeepSeek-R1\", \"Digi‚Ä¶\n$ stars      &lt;int&gt; 98160, 90473, 65966, 65775, 65124, 60190, 60125, 58762, 570‚Ä¶\n$ forks      &lt;int&gt; 15978, 11678, 1251, 19126, 7440, 7044, 3160, 6793, 5162, 83‚Ä¶\n$ watchers   &lt;int&gt; 98160, 90473, 65966, 65775, 65124, 60190, 60125, 58762, 570‚Ä¶\n$ created_at &lt;chr&gt; \"2024-12-26T09:52:40Z\", \"2025-01-20T11:57:28Z\", \"2024-05-30‚Ä¶\n$ summary    &lt;chr&gt; NA, NA, \"DigitalPlat FreeDomain: Free Domain For Everyone\",‚Ä¶\n$ url        &lt;chr&gt; \"https://github.com/deepseek-ai/DeepSeek-V3\", \"https://gith‚Ä¶\n\n\n\n\nclean data\n\n\nCode\ndf$name_label &lt;- paste0(df$name, \"\n\", format(as.Date(df$created_at), \"%Y-%m-%d\"))\n\n# Reshape data to long format for plotting\ndf_long &lt;- df %&gt;%\n  select(name,name_label, url, stars, forks, watchers) %&gt;%\n  pivot_longer(cols = c(\"stars\", \"forks\", \"watchers\"),\n               names_to = \"metric\", values_to = \"count\") |&gt; mutate(text =paste0(\"&lt;a href='\",url,\"' target='_blank'&gt;\",name_label)\n               ) |&gt; mutate(text = factor(text, levels = rev(unique(text[order(-count)]))))\n     \nglimpse(df_long)\n\n\nRows: 60\nColumns: 6\n$ name       &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\", \"deepseek-ai/DeepSeek-V3\", \"deep‚Ä¶\n$ name_label &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\\n2024-12-26\", \"deepseek-ai/DeepSee‚Ä¶\n$ url        &lt;chr&gt; \"https://github.com/deepseek-ai/DeepSeek-V3\", \"https://gith‚Ä¶\n$ metric     &lt;chr&gt; \"stars\", \"forks\", \"watchers\", \"stars\", \"forks\", \"watchers\",‚Ä¶\n$ count      &lt;int&gt; 98160, 15978, 98160, 90473, 11678, 90473, 65966, 1251, 6596‚Ä¶\n$ text       &lt;fct&gt; &lt;a href='https://github.com/deepseek-ai/DeepSeek-V3' target‚Ä¶\n\n\n\n\nggplot\n\n\nCode\n# Bar chart\ngg &lt;- ggplot(df_long, aes(x = reorder(name_label, count), y = count, fill = metric, customdata = url)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(aes(label = scales::label_number(accuracy = 0.1, scale_cut = scales::cut_short_scale())(count)), position = position_dodge(width = 0.9), hjust = -0.1, size = 3) +\n  labs(\n    title = \"Top 20 Fastest Growing GitHub Projects (since 2024)\",\n    x = \"Repository\",\n    y = \"Count\",\n    fill = \"Metric\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\ngg\n\n\n\n\n\n\n\n\n\n\n\nplotly\n\n\nCode\nfig &lt;- plot_ly(\n  data = df_long,\n  x = ~count,\n  y = ~text,\n  color = ~metric,\n  type = 'bar',\n  orientation = 'h',\n  customdata = ~url,\n  texttemplate = '%{x:.2s}',\n  textposition = 'outside',\n  hovertemplate = paste(\n    \"&lt;b&gt;Repository:&lt;/b&gt; %{y}&lt;br&gt;\",\n    \"&lt;b&gt;Count:&lt;/b&gt; %{x:.2s}&lt;br&gt;\",\n    \"&lt;b&gt;Metric:&lt;/b&gt; %{fullData.name}&lt;br&gt;\",\n    \"&lt;b&gt;URL:&lt;/b&gt; %{customdata}&lt;extra&gt;&lt;/extra&gt;\"\n  )\n\n) %&gt;%\n  layout(\n    title = \"Top 20 Fastest Growing GitHub Projects (since 2024)\",\n    xaxis = list(title = \"Count\", range = c(0, max(df_long$count) * 1.15)),\n    yaxis = list(title = \"Repository\", categoryorder = \"array\", categoryarray = levels(df_long$text)),\n    barmode = \"group\",\n    legend = list(title = list(text = \"Metric\")),\n    margin = list(b = 120)\n   ,height=900\n  )\n\n\nWarning: Specifying width/height in layout() is now deprecated.\nPlease specify in ggplotly() or plot_ly()\n\n\nCode\nfig"
  },
  {
    "objectID": "posts/subscribeYouTubeviaemail/index.html",
    "href": "posts/subscribeYouTubeviaemail/index.html",
    "title": "Subscribe to a YouTube channel via email",
    "section": "",
    "text": "A guide on how to subscribe to YouTube channels and receive updates via email using RSS feeds.\nIf you want to Subscribe to a YouTube channel but do not want to follow them.The trick is figuring out how to subscribe to a YouTube channel via email\n\nWhat is RSS?\nRSS (Really Simple Syndication) is a web feed that allows users and applications to access updates to online content in a standardized, computer-readable format. These feeds can, for example, allow a user to keep track of many different websites in a single news aggregator.\n\n\nStep 1: open youtube page of the channel want to subscribe\nfor example:https://www.youtube.com/@thecoatlessprofessor7674/videos\n\n\nStep 2: view page source\n\n\n\nStep 3: find ‚Äòvideos.xml‚Äô in page source\nfor example: https://www.youtube.com/feeds/videos.xml?channel_id=UColncDCZ8SmTAHYr92QFclQ\n\n\nStep 4: Use an RSS-to-Email Tool to Subscribe\nusing free RSS tool https://feedrabbit.com and enter your email address to subscribe. \n\n\nStep 5: open email and activate feedrabbit from a email from feedrabbit\nWhen there is a new video you will get a email.\nyou can also view all subscribe at https://feedrabbit.com/subscriptions\n\n\nReference\nhttps://greggblanchard.com/how-to-subscribe-to-a-youtube-channel-via-email/"
  },
  {
    "objectID": "posts/versioncontrolpython/index.html",
    "href": "posts/versioncontrolpython/index.html",
    "title": "Version control for Python with uv",
    "section": "",
    "text": "A comprehensive guide to using uv for Python project and package management. This document covers installation, project initialization, Python version management, and various package operations.\nThis document provides a comprehensive guide to using uv, a fast and efficient tool for Python project and package management. It covers the entire workflow, from installation and project initialization to managing Python versions and handling package operations. The guide also demonstrates how to use uv to synchronize dependencies and even run scripts with specific package requirements. This is a valuable resource for any Python developer looking to streamline their development process.\nIntroduces uv as a fast and comprehensive tool for Python project and package management. It covers uv‚Äôs installation, project initialization, Python version management, package operations, and dependency synchronization."
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#there-is-no-rich-package-in-python",
    "href": "posts/versioncontrolpython/index.html#there-is-no-rich-package-in-python",
    "title": "Version control for Python with uv",
    "section": "there is no rich package in python",
    "text": "there is no rich package in python\n\n\nCode\ntry:\n    import rich\n    print('pacakge installed')\nexcept ImportError as e:\n    print('pacakge not installed')\n    pass  # module doesn't exist, deal with it."
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#but-can-add-rich-package-in-script",
    "href": "posts/versioncontrolpython/index.html#but-can-add-rich-package-in-script",
    "title": "Version control for Python with uv",
    "section": "but can add rich package in script",
    "text": "but can add rich package in script\n#| eval: false\n\n# /// script\n# requires-python = \"&gt;=3.12\"\n# dependencies = [\n#   \"requests&lt;3\",\n#   \"rich\",\n# ]\n# ///\n\nimport requests\nimport rich\nfrom rich.pretty import pprint\n\n\nimport rich\nfrom importlib.metadata import version\n\nprint('test.py is running')\nprint('version is :')\nprint(version('rich'))"
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#run-.py-with-uv",
    "href": "posts/versioncontrolpython/index.html#run-.py-with-uv",
    "title": "Version control for Python with uv",
    "section": "run .py with uv",
    "text": "run .py with uv\n\n\nCode\n!uv run test.py\n\n\n‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0/0‚†ô Resolving dependencies...                                                     ‚†ã Resolving dependencies...                                                     ‚†ô Resolving dependencies...                                                     ‚†π Resolving dependencies...                                                     ‚†∏ Resolving dependencies...                                                     ‚†∏ requests==2.32.4                                                              ‚†∏ rich==14.0.0                                                                  ‚†º rich==14.0.0                                                                  ‚†¥ rich==14.0.0                                                                  ‚†¶ rich==14.0.0                                                                  ‚†¶ charset-normalizer==3.4.2                                                     ‚†¶ idna==3.10                                                                    ‚†¶ urllib3==2.5.0                                                                ‚†¶ certifi==2025.6.15                                                            ‚†¶ markdown-it-py==3.0.0                                                         ‚†¶ pygments==2.19.2                                                              ‚†¶ mdurl==0.1.2                                                                  ‚†¶                                                                               ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [0/0] Installing wheels...                                 ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [0/9] Installing wheels...                                 ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [0/9] certifi==2025.6.15                                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [1/9] certifi==2025.6.15                                   ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [1/9] rich==14.0.0                                         ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [2/9] rich==14.0.0                                         ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [2/9] idna==3.10                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [3/9] idna==3.10                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [3/9] requests==2.32.4                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [4/9] requests==2.32.4                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [4/9] urllib3==2.5.0                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [5/9] urllib3==2.5.0                                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [5/9] mdurl==0.1.2                                         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [6/9] mdurl==0.1.2                                         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë [6/9] markdown-it-py==3.0.0                                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë [7/9] markdown-it-py==3.0.0                                ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë [7/9] charset-normalizer==3.4.2                            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë [8/9] charset-normalizer==3.4.2                            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë [8/9] pygments==2.19.2                                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [9/9] pygments==2.19.2                                     Installed 9 packages in 21ms\ntest.py is running\nversion is :\n14.0.0"
  },
  {
    "objectID": "posts/norway_pension_fund/index.html",
    "href": "posts/norway_pension_fund/index.html",
    "title": "Êå™Â®ÅÂÖªËÄÅÂü∫Èáë",
    "section": "",
    "text": "An overview of Norway‚Äôs Government Pension Fund Global, including its purpose and links to resources.\nThis document provides an overview of the Government Pension Fund Global of Norway, one of the world‚Äôs largest sovereign wealth funds. It explains the fund‚Äôs purpose, which is to manage the financial reserves from Norway‚Äôs oil and gas resources for the benefit of current and future generations. The document also includes links to the fund‚Äôs official website, investment data, and a related podcast, offering a comprehensive resource for those interested in learning more about this significant financial institution.\nThe Government Pension Fund Global was established after Norway discovered oil in the North Sea.\nThe fund was set up to shield the economy from ups and downs in oil revenue. It also serves as a financial reserve and as a long-term savings plan so that both current and future generations of Norway get to benefit from our oil wealth.\nhttps://www.nbim.no/en\n\n\nCode\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(av)\n\n\n\npodcast\nhttps://shows.acast.com/in-good-company-with-nicolai-tangen\n\n\nCode\none_podcast='https://shows.acast.com/in-good-company-with-nicolai-tangen/episodes/highlights-debra-crew-ceo-of-diageo'\n\naudio_page &lt;- read_html(one_podcast)\n    \n# ÊèêÂèñÈü≥È¢ëÊ†áÈ¢òÔºåproperty=\"og:title\"ÁöÑmetaÂÖÉÁ¥†ÁöÑcontentÂÄº\ntitle &lt;- audio_page %&gt;%\nhtml_nodes('meta[property=\"og:title\"]') %&gt;%\nhtml_attr(\"content\")\n\ntitle  \n\n# ÊèêÂèñÈü≥È¢ë‰∏ãËΩΩÈìæÊé•Ôºåproperty=\"og:audio\"ÁöÑmetaÂÖÉÁ¥†ÁöÑcontentÂÄº\naudio_url &lt;- audio_page %&gt;%\n  html_nodes('meta[property=\"og:audio\"]') %&gt;%\n  html_attr(\"content\")\n\naudio_url\n\n\n\n\nCode\noutput_file_name=paste0(title,\".mp3\")\ndownload.file(url = audio_url, destfile = output_file_name)\n\n\n\n\ndata\nhttps://www.nbim.no/en/investments/all-investments/#/\n\n\nvideo\nhttps://www.youtube.com/watch?v=mT6mRJehJdw"
  },
  {
    "objectID": "posts/api_with_httr2/index.html",
    "href": "posts/api_with_httr2/index.html",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "",
    "text": "A guide to using the httr2 R package for interacting with web APIs, with examples for the US National Weather Service and OpenWeatherMap APIs.\nThis document provides a practical guide to using the httr2 package in R for interacting with web APIs. It includes two detailed examples: one that demonstrates how to call the US National Weather Service (NWS) API to retrieve hourly weather forecasts, and another that shows how to use the OpenWeatherMap API to get current weather data for a specific city. The guide covers the entire process, from constructing the API request to performing the request and extracting the relevant data from the JSON response.\nThe httr2 package provides a pipeable API for working with web APIs."
  },
  {
    "objectID": "posts/api_with_httr2/index.html#api-link",
    "href": "posts/api_with_httr2/index.html#api-link",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "API link",
    "text": "API link\n\n\nCode\nNWS_base_url &lt;- 'https://api.weather.gov'\n\nNWS_response_link &lt;- request(NWS_base_url) |&gt; \n  req_url_path_append(\n    'points',\n    '38.8894,-77.0352'\n  ) \n\nNWS_response_link"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#create-response-and-check-connection",
    "href": "posts/api_with_httr2/index.html#create-response-and-check-connection",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "create response and check connection",
    "text": "create response and check connection\n\n\nCode\nNWS_response=NWS_response_link|&gt; req_perform()\nNWS_response"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-forecast-hourly-url-from-response",
    "href": "posts/api_with_httr2/index.html#get-forecast-hourly-url-from-response",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "get forecast hourly url from response",
    "text": "get forecast hourly url from response\n\n\nCode\nNWS_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()\n\n\n\n\nCode\nforecast_url &lt;- NWS_response |&gt; \n  resp_body_json() |&gt; \n  pluck('properties', 'forecastHourly')\n\nforecast_url"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#make-forecast-hourly-response",
    "href": "posts/api_with_httr2/index.html#make-forecast-hourly-response",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "make forecast hourly response",
    "text": "make forecast hourly response\n\n\nCode\nforecast_response &lt;- request(forecast_url) |&gt; \n  req_perform()\n\nforecast_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-forecast-hourly-data",
    "href": "posts/api_with_httr2/index.html#get-forecast-hourly-data",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "get forecast hourly data",
    "text": "get forecast hourly data\n\n\nCode\nextracted_data &lt;- forecast_response |&gt; \n  resp_body_json() |&gt; \n  pluck('properties', 'periods') |&gt; \n  map_dfr( # iterates over each list and binds rows to a tibble\n    \\(x) {\n      tibble(\n        time = x |&gt; pluck('startTime'),\n        temp_F = x |&gt; pluck('temperature'),\n        rain_prob = x |&gt; pluck('probabilityOfPrecipitation', 'value'),\n        forecast = x |&gt; pluck('shortForecast')\n      )\n    }\n  )\n\nextracted_data"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#create-response",
    "href": "posts/api_with_httr2/index.html#create-response",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "create response",
    "text": "create response\n\n\nCode\nlibrary(keyring)\nopenweathermap_base_url &lt;- 'https://api.openweathermap.org/data/2.5'\n\nopenweathermap_api_key=key_get(\"openweathermap_api_key\")\n\ncity='Bangkok'\n\nopenweathermap_response_link &lt;- request(openweathermap_base_url) |&gt; \n  req_url_path_append(\n    paste0('weather?q=',city,'&appid=',openweathermap_api_key,'&units=metric')\n  ) \n\nopenweathermap_response_link\n\n\n\n\nCode\nopenweathermap_response=openweathermap_response_link|&gt; req_perform()\nopenweathermap_response"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-data-from-response",
    "href": "posts/api_with_httr2/index.html#get-data-from-response",
    "title": "‰ΩøÁî®R httr2 Ë∞ÉÁî®API",
    "section": "get data from response",
    "text": "get data from response\n\n\nCode\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()\n\n\n\n\nCode\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('main', 'temp') \n\na=openweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('weather') \n\n(a[[1]])$main\n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('name') \n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('coord', 'lon') \n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('coord', 'lat') \n\n\nLondon air_pollution:\nhttp://api.openweathermap.org/data/2.5/air_pollution?lat=51.5085&lon=-0.1257&appid=625ae405e4f11b5b957af484b77fbd62"
  },
  {
    "objectID": "posts/edit video/index.html",
    "href": "posts/edit video/index.html",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "",
    "text": "A guide to video and audio editing in R, covering tasks like checking and changing resolution, length, and size, as well as cropping and converting formats.\nvideo/audio editing include change resolution and length\nThis document provides a comprehensive guide to video and audio editing using R, with a focus on the av package. It covers a wide range of tasks, from basic checks like determining video resolution and length to more advanced operations like changing video resolution, trimming video length, cropping, and converting video to images or audio-only formats. The audio section demonstrates how to manipulate MP3 files, including changing their length and converting them to WAV format.\nOriginal video:"
  },
  {
    "objectID": "posts/edit video/index.html#check-video-resolution",
    "href": "posts/edit video/index.html#check-video-resolution",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "check video resolution",
    "text": "check video resolution\n\n\nCode\nget_video_resolution_ffmpeg &lt;- function(file_path) {\n  if (!file.exists(file_path)) {\n    stop(\"File does not exist.\")\n  }\n  # Run ffmpeg command and capture output\n  cmd &lt;- sprintf(\"ffmpeg -i %s 2&gt;&1\", shQuote(normalizePath(file_path)))\n  output &lt;- system(cmd, intern = TRUE, ignore.stderr = FALSE)\n  # Find the line containing video stream details\n  video_line &lt;- grep(\"Video:\", output, value = TRUE)\n  if (length(video_line) == 0) {\n    stop(\"No video stream found.\")\n  }\n  # Extract resolution using regex (e.g., 1920x1080)\n  resolution &lt;- regmatches(video_line, regexpr(\"\\\\d{3,}x\\\\d{3,}\", video_line))\n  if (length(resolution) == 0) {\n    stop(\"Resolution not detected.\")\n  }\n  dimensions &lt;- as.numeric(strsplit(resolution, \"x\")[[1]])\n  return(dimensions)\n}\n\n\n\n\nCode\nresolution &lt;- get_video_resolution_ffmpeg(\"demo.mp4\")\ncat(sprintf(\"Resolution: %dx%d\", resolution[1], resolution[2]))\n\n\nResolution: 960x720"
  },
  {
    "objectID": "posts/edit video/index.html#check-video-length-and-size",
    "href": "posts/edit video/index.html#check-video-length-and-size",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "check video length and size",
    "text": "check video length and size\n\n\nCode\nvideo_info &lt;- av::av_media_info(\"demo.mp4\")\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 30.02501\n\n\nCode\nvideo_size_mb &lt;- file.info(\"demo.mp4\")$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 1.029325"
  },
  {
    "objectID": "posts/edit video/index.html#change-video-resolution",
    "href": "posts/edit video/index.html#change-video-resolution",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "change video resolution",
    "text": "change video resolution\n\n\nCode\n# Input video file path\ninput_video &lt;- \"demo.mp4\"\n\n# Output video file path\noutput_video &lt;- \"demo_resolution.mp4\"\n\n# Desired width and height\nnew_width &lt;- 960/3*2\nnew_height &lt;- 720/3*2\n\n# Construct the FFmpeg command for resizing\nffmpeg_command &lt;- paste0(\n  \"ffmpeg -i '\", input_video, \"' -vf scale=\", new_width, \":\", new_height, \" '\", output_video, \"'\"\n)\n\n# Execute the FFmpeg command\nsystem(ffmpeg_command)\n\ncat(\"Video resized to\", new_width, \"x\", new_height, \"and saved to\", output_video, \"\\n\")\n\n\nVideo resized to 640 x 480 and saved to demo_resolution.mp4 \n\n\nVideo after change resolution:\n\n\n\nCode\nresolution &lt;- get_video_resolution_ffmpeg(output_video)\ncat(sprintf(\"Resolution: %dx%d\", resolution[1], resolution[2]))\n\n\nResolution: 640x480\n\n\n\n\nCode\nvideo_info &lt;- av::av_media_info(output_video)\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 30.02501\n\n\nCode\nvideo_size_mb &lt;- file.info(output_video)$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 0.72155"
  },
  {
    "objectID": "posts/edit video/index.html#change-length-of-video",
    "href": "posts/edit video/index.html#change-length-of-video",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "change length of video",
    "text": "change length of video\n\n\nCode\n# Define input/output files and timestamps\ninput_file &lt;- \"demo.mp4\"\n\n# Define input and output file paths\ninput_video &lt;- \"demo.mp4\"\noutput_video &lt;- \"demo_change_length.mp4\"\n\n# --- Example 1: Trimming from the beginning ---\nstart_time &lt;- \"00:00:05\" # Start at 5 seconds\nduration &lt;- \"00:00:10\"  # Keep for 10 seconds\n\ncommand_trim &lt;- sprintf(\"ffmpeg -i %s -ss %s -t %s  %s\",\n                        input_video, start_time, duration, output_video)\n\n#command_trim\nsystem(command_trim)\ncat(paste(\"Trimmed video saved to:\", output_video, \"\\n\"))\n\n\nTrimmed video saved to: demo_change_length.mp4 \n\n\nVideo after change length:\n\n\n\nCode\nvideo_info &lt;- av::av_media_info(\"demo_change_length.mp4\")\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 10\n\n\nCode\nvideo_size_mb &lt;- file.info(\"demo_change_length.mp4\")$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 0.275506"
  },
  {
    "objectID": "posts/edit video/index.html#video-crop",
    "href": "posts/edit video/index.html#video-crop",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "video Crop",
    "text": "video Crop\n\n\nCode\n# Define the path to the input video file\ninput_video_path &lt;- \"demo.mp4\"  # Replace with your video file path\n\n# Define the path to save the cropped video\noutput_video_path &lt;- \"demo_crop.mp4\"  # Replace with your desired output path\n\n# Define crop parameters\ncrop_width &lt;- 640   # Desired width of the cropped video\ncrop_height &lt;- 360  # Desired height of the cropped video\ncrop_x &lt;- 100       # X offset for cropping\ncrop_y &lt;- 50        # Y offset for cropping\n\n# Define the crop filter\ncrop_filter &lt;- sprintf(\"crop=%d:%d:%d:%d\", crop_width, crop_height, crop_x, crop_y)\n\n# Crop the video\nav::av_encode_video(\n  input = input_video_path,\n  output = output_video_path,\n  vfilter = crop_filter,\n  audio=input_video_path\n)\n\n\n[1] \"/Users/jinchaoduan/Documents/Project/Tech-blog/posts/edit video/demo_crop.mp4\"\n\n\nCode\ncat(\"Video cropped successfully and saved to:\", output_video_path, \"\\n\")\n\n\nVideo cropped successfully and saved to: demo_crop.mp4 \n\n\nVideo after crop:"
  },
  {
    "objectID": "posts/edit video/index.html#changing-length-of-mp3",
    "href": "posts/edit video/index.html#changing-length-of-mp3",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "Changing length of mp3",
    "text": "Changing length of mp3\n\n\nCode\nvideo_info=av::av_media_info(\"demo.mp3\" )\nvideo_info$duration\n\n\n[1] 30.04082\n\n\n\n\n\nCode\npcm_data &lt;- read_audio_bin(\"demo.mp3\" , channels = 1, end_time = 2.0)\nplot(pcm_data, type = 'l')\n\n\n\n\n\n\n\n\n\n\n\nCode\nstart_time &lt;- 2 # Start at 1 seconds\ntotal_time &lt;- 4  # Keep for 10 seconds\n\nav_audio_convert(audio=\"demo.mp3\",output=\"demo_cut.mp3\",start_time=start_time,total_time=total_time)\n\n\n[1] \"/Users/jinchaoduan/Documents/Project/Tech-blog/posts/edit video/demo_cut.mp3\"\n\n\n\n\nCode\nvideo_info=av::av_media_info(\"demo_cut.mp3\")\nvideo_info$duration\n\n\n[1] 4.101224"
  },
  {
    "objectID": "posts/edit video/index.html#convert-mp3-to-wav",
    "href": "posts/edit video/index.html#convert-mp3-to-wav",
    "title": "Ââ™ÂàáËßÜÈ¢ë/Èü≥È¢ë",
    "section": "convert mp3 to wav",
    "text": "convert mp3 to wav"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html",
    "href": "posts/data_transfer_with_pin/index.html",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "",
    "text": "A guide to using the pins package in R for data transfer and version control between local and online storage.\nThis document provides a comprehensive guide to using the pins package in R for efficient data transfer and version control. It demonstrates how to set up and use both local and online boards (with OneDrive as an example) to store and retrieve data and other files. The guide covers essential pins functions for uploading, downloading, listing, and managing different versions of your data, making it a valuable resource for creating reproducible and collaborative data science workflows.\nThe pins package is used for uploading and downloading data/models to online drives.\nCode\npak::pkg_install(\"pins\")\nCode\nlibrary(pins)\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#use-local-location-as-a-board",
    "href": "posts/data_transfer_with_pin/index.html#use-local-location-as-a-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "use local location as a board",
    "text": "use local location as a board\n\n\nCode\nboard=board_folder(getwd())\n\n\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-to-local-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-to-local-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "upload to local board",
    "text": "upload to local board\n\n\nCode\nboard %&gt;% pin_write(head(mtcars), \"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-from-local-board",
    "href": "posts/data_transfer_with_pin/index.html#download-from-local-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "download from local board",
    "text": "download from local board\n\n\nCode\na=board %&gt;% pin_read(\"mtcars\")\na"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-file-to-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-file-to-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "upload file to board",
    "text": "upload file to board\n\n\nCode\nboard %&gt;% pin_upload('thumbnail.jpg','new.thumbnail.jpg')"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#list-file-in-the-board",
    "href": "posts/data_transfer_with_pin/index.html#list-file-in-the-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "list file in the board",
    "text": "list file in the board\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-file-from-board",
    "href": "posts/data_transfer_with_pin/index.html#download-file-from-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "download file from board",
    "text": "download file from board\n\n\nCode\nboard %&gt;% pin_download('new.thumbnail.jpg')"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#one-drive-as-as-a-board",
    "href": "posts/data_transfer_with_pin/index.html#one-drive-as-as-a-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "one drive as as a board",
    "text": "one drive as as a board\n\n\nCode\nod &lt;- Microsoft365R::get_personal_onedrive()\nboard365 &lt;- board_ms365(od, \"myboard\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-to-one-drive-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-to-one-drive-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "upload to one drive board",
    "text": "upload to one drive board\n\n\nCode\nboard365 %&gt;% pin_write(tail(mtcars), \"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-from-one-drive-board",
    "href": "posts/data_transfer_with_pin/index.html#download-from-one-drive-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "download from one drive board",
    "text": "download from one drive board\n\n\nCode\nboard365 %&gt;% pin_read(\"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#list-file-in-the-board-1",
    "href": "posts/data_transfer_with_pin/index.html#list-file-in-the-board-1",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "list file in the board",
    "text": "list file in the board\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#there-will-be-two-version",
    "href": "posts/data_transfer_with_pin/index.html#there-will-be-two-version",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "there will be two version",
    "text": "there will be two version\n\n\nCode\nboard %&gt;% pin_versions(\"mtcars_version\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-version-file-from-board",
    "href": "posts/data_transfer_with_pin/index.html#download-version-file-from-board",
    "title": "‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì",
    "section": "download version file from board",
    "text": "download version file from board\n\n\nCode\n# board %&gt;% pin_read(\"mtcars_version\",version = '20230704T095208Z-8df40')\nboard %&gt;% pin_read(\"mtcars_version\",version = .Last.value$version[[1]])"
  },
  {
    "objectID": "posts/Rpackage/index.html",
    "href": "posts/Rpackage/index.html",
    "title": "R pacakge download and managment tool",
    "section": "",
    "text": "A guide to R package management using the pak and cranlogs packages, covering installation, version checking, and analyzing download statistics.\nThis document provides a comprehensive guide to R package management, focusing on the pak and cranlogs packages. It demonstrates how to use pak for installing, updating, and managing packages from various sources, including CRAN, GitHub, and local files. The guide also covers how to use cranlogs to analyze package download statistics and retrieve information about packages from GitHub. Additionally, it briefly mentions other useful tools for building R packages.\npak installs R packages from CRAN, Bioconductor, GitHub, URLs, git repositories, local files and directories. It is an alternative to install.packages() and devtools::install_github(). pak is fast, safe and convenient."
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pak",
    "href": "posts/Rpackage/index.html#install-pak",
    "title": "R pacakge download and managment tool",
    "section": "install pak",
    "text": "install pak\n\n\nCode\ninstall.packages(\"pak\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#load-pak",
    "href": "posts/Rpackage/index.html#load-pak",
    "title": "R pacakge download and managment tool",
    "section": "load pak",
    "text": "load pak\n\n\nCode\nlibrary(pak)"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-pak-version",
    "href": "posts/Rpackage/index.html#check-pak-version",
    "title": "R pacakge download and managment tool",
    "section": "check pak version",
    "text": "check pak version\n\n\nCode\npak_sitrep()"
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pacakge-from-cran",
    "href": "posts/Rpackage/index.html#install-pacakge-from-cran",
    "title": "R pacakge download and managment tool",
    "section": "install pacakge from cran",
    "text": "install pacakge from cran\n\n\nCode\npkg_install(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pacakge-file-tar.gz-from-website",
    "href": "posts/Rpackage/index.html#install-pacakge-file-tar.gz-from-website",
    "title": "R pacakge download and managment tool",
    "section": "install pacakge file tar.gz from website",
    "text": "install pacakge file tar.gz from website\n\n\nCode\npkg_install(\n  \"url::https://cran.r-project.org/src/contrib/Archive/tibble/tibble_3.1.7.tar.gz\"\n)"
  },
  {
    "objectID": "posts/Rpackage/index.html#uninstall-package",
    "href": "posts/Rpackage/index.html#uninstall-package",
    "title": "R pacakge download and managment tool",
    "section": "uninstall package",
    "text": "uninstall package\n\n\nCode\npkg_remove(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-package",
    "href": "posts/Rpackage/index.html#check-package",
    "title": "R pacakge download and managment tool",
    "section": "check package",
    "text": "check package\n\n\nCode\npkg_deps_tree(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#show-all-dependencies",
    "href": "posts/Rpackage/index.html#show-all-dependencies",
    "title": "R pacakge download and managment tool",
    "section": "show all Dependencies",
    "text": "show all Dependencies\n\n\nCode\npkg_deps(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#explain-dependencies",
    "href": "posts/Rpackage/index.html#explain-dependencies",
    "title": "R pacakge download and managment tool",
    "section": "Explain dependencies",
    "text": "Explain dependencies\n\n\nCode\npkg_deps_explain(\"tibble\", \"rlang\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-pacakge-history-on-cran",
    "href": "posts/Rpackage/index.html#check-pacakge-history-on-cran",
    "title": "R pacakge download and managment tool",
    "section": "check pacakge history on cran",
    "text": "check pacakge history on cran\n\n\nCode\npkg_history(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#update-package",
    "href": "posts/Rpackage/index.html#update-package",
    "title": "R pacakge download and managment tool",
    "section": "update package",
    "text": "update package\n\n\nCode\npkg_install(\"tibble\")\n\n\nUpdate all dependencies of a package\n\n\nCode\npkg_install(\"tibble\", upgrade = TRUE)"
  },
  {
    "objectID": "posts/Rpackage/index.html#total-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#total-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "total pacakge download from last week",
    "text": "total pacakge download from last week\n\n\nCode\nlibrary(cranlogs)\ncran_downloads(when = \"last-week\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#total-pacakge-download-from-2014",
    "href": "posts/Rpackage/index.html#total-pacakge-download-from-2014",
    "title": "R pacakge download and managment tool",
    "section": "total pacakge download from 2014",
    "text": "total pacakge download from 2014\n\n\nCode\ndata=cran_downloads(from = \"2014-01-01\", to = \"2024-12-31\")\nlibrary(plotly)\nplot_ly(data, x = ~date, y = ~count, mode = \"lines\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#top-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#top-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "top pacakge download from last week",
    "text": "top pacakge download from last week\n\n\nCode\ncran_top_downloads(\"last-week\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#one-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#one-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "one pacakge download from last week",
    "text": "one pacakge download from last week\n\n\nCode\npacakge_name=\"tibble\"\nlastweek=cran_downloads(when = \"last-week\", package = pacakge_name)\nlastweek\n\n\n\n\nCode\nprint(paste(pacakge_name,\"last week been downloaded\",sum(lastweek$count),\"times\"))"
  },
  {
    "objectID": "posts/git/index.html",
    "href": "posts/git/index.html",
    "title": "‰ΩøÁî®git‰ª£Á†ÅÁâàÊú¨ÁÆ°ÁêÜ",
    "section": "",
    "text": "A quick reference guide for essential Git commands, covering basic to advanced operations.\nThis document serves as a quick reference guide for essential Git commands, providing a comprehensive overview of basic to advanced operations. It covers everything from initializing a repository and managing branches to committing changes and interacting with remote repositories. This guide is designed to be a helpful resource for both beginners and experienced users who need a quick reminder of Git‚Äôs powerful features.\n\ndownload github desktop\nhttps://desktop.github.com/download/\n\n\nset up github account\nhttps://github.com/\n\n\nClone a repository into a new directory\ngit clone \n\n\nInitialize a new Git repository\ngit init\n\n\nAdd to the staging area\ngit add  git add .\n\n\nCommit changes to the repository\ngit commit -m ‚Äúcommit message‚Äù\n\n\nView the commit history\ngit log\n\n\nCheck the status of changes\ngit status\n\n\nShow the changes in the working directory\ngit diff\n\n\nCreate a new branch\ngit branch \n\n\nList all branches\ngit branch\n\n\nSwitch to a different branch\ngit checkout \n\n\nCreate and switch to a new branch\ngit checkout -b \n\n\nMerge a branch into the current branch\ngit merge \n\n\nchanges from a remote repository\ngit pull\n\n\nPush changes to a remote repository\ngit push\n\n\nDelete a branch\ngit branch -d  git push origin ‚Äìdelete \n\n\nStash changes\ngit stash\n\n\nApply stashed changes\ngit stash apply\n\n\nShow stashed changes\ngit stash list\n\n\nRemove a file from the staging area\ngit reset \n\n\nreset to the last commit with commit id but keep your actual file unchange\ngit reset ‚Äìsoft HEAD~1\n\n\nreset to the last commit with commit id\ngit reset ‚Äìhard e4a59dd6b356b93f914db2a2a253dc55582bd61e"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tech blog",
    "section": "",
    "text": "Sheet 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvert file like pdf to markdown\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeather App with Streamlit\n\n\n\n\n\n\nAI\n\nPython\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Gemini CLI\n\n\nYour AI assistant in the terminal\n\n\n\nTool\n\nAI\n\nCLI\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nKimi2 with openrouter\n\n\n\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nGithub trend\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nJul 10, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÂ§öËØ≠Ë®Ä quarto blog\n\n\nbabelquarto\n\n\n\nquarto\n\n\n\n\n\n\n\n\n\nJul 3, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÂâ™ÂàáËßÜÈ¢ë/Èü≥È¢ë\n\n\nvideo/audio editing\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMay 5, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰∏ñÁïåGDP\n\n\nGlobal GDP\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÊå™Â®ÅÂÖªËÄÅÂü∫Èáë\n\n\nNorway The Government Pension Fund Global\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nAIÂõæÁâáËØÜÂà´ÊñáÂ≠ó\n\n\nAI Optical character recognition\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 21, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÊï∞ÊçÆÊòüÊúü‰∫å\n\n\nTidyTuesday\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 10, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nË°®Ê†ºÂ±ïÁ§∫\n\n\nDisplay table\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂\n\n\nUsing code to send email\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å\n\n\nUsing AI to create Summary for podcast\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nË∑ØÂæÑÁÆ°ÁêÜ\n\n\nPath management\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 27, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï\n\n\nUsing AI to create Chinese and English Subtitles\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 27, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÂØÜÁ†ÅÁÆ°ÁêÜ\n\n\nPassword management\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÊ≠£ÂàôË°®ËææÂºè‰ª£Á†Å\n\n\nregular expression\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®git‰ª£Á†ÅÁâàÊú¨ÁÆ°ÁêÜ\n\n\nUsing git for version control\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nDocker‰ΩøÁî®‰ªãÁªç\n\n\nDocker intro\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nLinuxÁ≥ªÁªüÊìç‰Ωú‰ª£Á†Å\n\n\nLinux command\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nË∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã\n\n\nRun AI model online\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÊú¨Âú∞ËøêË°åAIÊ®°Âûã\n\n\nRun AI model on local machine\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã\n\n\n(LLM)Large language model\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nMake QR code\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 16, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nR code optimization with lintr and styler\n\n\n\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nAI Code assistant\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®R httr2 Ë∞ÉÁî®API\n\n\nUsing R httr2 to call API\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì\n\n\nFor data transfer between local and cloud\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nPython code optimization with ruff\n\n\n\n\n\n\nTool\n\nPython\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nVersion control for Python with uv\n\n\n\n\n\n\nTool\n\nPython\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nR pacakge download and managment tool\n\n\n\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nCPU and GPU\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nClassification Metrics\n\n\n\n\n\n\nMachine learning\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube\n\n\n\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping in R with rvest\n\n\n\n\n\n\nTool\n\nWebscrap\n\nR\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping in Python\n\n\n\n\n\n\nTool\n\nWebscrap\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nSubscribe to a YouTube channel via email\n\n\n\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nVersion control with renv\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nYoutube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp\n\n\nYoutube download tool:yt-dlp\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nUseful resource\n\n\n\n\n\n\nnews\n\nresource\n\n\n\n\n\n\n\n\n\nMar 1, 2025\n\n\nTony D\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\n¬†\n\n\n¬†\n\n\n¬†\n\n\n\n\n\n\n¬†\n\n\nSheet 1\n\n\n¬†\n\n\n\n\n\n\nJul 24, 2025\n\n\nConvert file like pdf to markdown\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nWeather App with Streamlit\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nIntroduction to Gemini CLI\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nKimi2 with openrouter\n\n\nTony D\n\n\n\n\n\n\nJul 10, 2025\n\n\nGithub trend\n\n\nTony D\n\n\n\n\n\n\nJul 3, 2025\n\n\nÂ§öËØ≠Ë®Ä quarto blog\n\n\nTony D\n\n\n\n\n\n\nMay 5, 2025\n\n\nÂâ™ÂàáËßÜÈ¢ë/Èü≥È¢ë\n\n\nTony D\n\n\n\n\n\n\nApr 24, 2025\n\n\n‰∏ñÁïåGDP\n\n\nTony D\n\n\n\n\n\n\nApr 24, 2025\n\n\nÊå™Â®ÅÂÖªËÄÅÂü∫Èáë\n\n\nTony D\n\n\n\n\n\n\nApr 21, 2025\n\n\nAIÂõæÁâáËØÜÂà´ÊñáÂ≠ó\n\n\nTony D\n\n\n\n\n\n\nApr 10, 2025\n\n\nÊï∞ÊçÆÊòüÊúü‰∫å\n\n\nTony D\n\n\n\n\n\n\nApr 7, 2025\n\n\nË°®Ê†ºÂ±ïÁ§∫\n\n\nTony D\n\n\n\n\n\n\nMar 31, 2025\n\n\n‰ΩøÁî®‰ª£Á†ÅÂèëÈÇÆ‰ª∂\n\n\nTony D\n\n\n\n\n\n\nMar 28, 2025\n\n\n‰ΩøÁî®AIÁªôÊí≠ÂÆ¢ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂπ∂‰ΩúÊëòË¶Å\n\n\nTony D\n\n\n\n\n\n\nMar 27, 2025\n\n\nË∑ØÂæÑÁÆ°ÁêÜ\n\n\nTony D\n\n\n\n\n\n\nMar 27, 2025\n\n\n‰ΩøÁî®AIÁªôËßÜÈ¢ëËá™Âä®ÁîüÊàê‰∏≠Ëã±ÊñáÂ≠óÂπï\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\nÂØÜÁ†ÅÁÆ°ÁêÜ\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\nÊ≠£ÂàôË°®ËææÂºè‰ª£Á†Å\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\n‰ΩøÁî®git‰ª£Á†ÅÁâàÊú¨ÁÆ°ÁêÜ\n\n\nTony D\n\n\n\n\n\n\nMar 24, 2025\n\n\nDocker‰ΩøÁî®‰ªãÁªç\n\n\nTony D\n\n\n\n\n\n\nMar 24, 2025\n\n\nLinuxÁ≥ªÁªüÊìç‰Ωú‰ª£Á†Å\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\nË∞ÉÁî®ÁΩëÁªúÁ´ØAIÊ®°Âûã\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\nÊú¨Âú∞ËøêË°åAIÊ®°Âûã\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\nÔºàLLMÔºâÂ§ßËØ≠Ë®ÄÊ®°Âûã\n\n\nTony D\n\n\n\n\n\n\nMar 16, 2025\n\n\nMake QR code\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\nR code optimization with lintr and styler\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\nAI Code assistant\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\n‰ΩøÁî®R httr2 Ë∞ÉÁî®API\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\n‰ΩøÁî®R pinÊï∞ÊçÆ‰º†Ëæì\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nPython code optimization with ruff\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nVersion control for Python with uv\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nR pacakge download and managment tool\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nCPU and GPU\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nClassification Metrics\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\n‰ΩøÁî®iphoneÊàñipad‰∏ãËΩΩyoutube\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nWeb scraping in R with rvest\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nWeb scraping in Python\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nSubscribe to a YouTube channel via email\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nVersion control with renv\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nYoutube‰∏ãËΩΩÂ∑•ÂÖ∑Ôºöyt-dlp\n\n\nTony D\n\n\n\n\n\n\nMar 1, 2025\n\n\nUseful resource\n\n\nTony D\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/gemini_cli/index.html",
    "href": "posts/gemini_cli/index.html",
    "title": "Introduction to Gemini CLI",
    "section": "",
    "text": "This post is an introduction to the Gemini CLI, a powerful tool that brings Google‚Äôs Gemini models to your command line interface."
  },
  {
    "objectID": "posts/gemini_cli/index.html#what-is-gemini-cli",
    "href": "posts/gemini_cli/index.html#what-is-gemini-cli",
    "title": "Introduction to Gemini CLI",
    "section": "What is Gemini CLI?",
    "text": "What is Gemini CLI?\nGemini CLI is a command-line interface that allows you to interact with Google‚Äôs Gemini large language models directly from your terminal. It‚Äôs designed for developers, data scientists, and anyone who wants to leverage the power of AI for their daily tasks without leaving the command line."
  },
  {
    "objectID": "posts/gemini_cli/index.html#key-features",
    "href": "posts/gemini_cli/index.html#key-features",
    "title": "Introduction to Gemini CLI",
    "section": "Key Features",
    "text": "Key Features\n\nDirect access to Gemini models: Interact with Gemini Pro and other models.\nCode generation and understanding: Ask for code snippets, get explanations of code, and even get help with debugging.\nFile system interaction: Gemini CLI can read your files, help you search for content, and even apply changes to your code.\nShell command execution: Run shell commands directly through the CLI.\nContext-aware: Gemini CLI can understand the context of your project and provide more relevant assistance."
  },
  {
    "objectID": "posts/gemini_cli/index.html#getting-started",
    "href": "posts/gemini_cli/index.html#getting-started",
    "title": "Introduction to Gemini CLI",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstallation\n(This is a hypothetical installation command)\nYou can install Gemini CLI using npm:\nnpm install -g @google/gemini-cli\n\n\nBasic Usage\nOnce installed, you can start a chat with Gemini CLI by running:\ngemini chat\nYou can ask it questions, ask it to write code, or ask it to perform tasks on your local file system.\nFor example, to list the files in the current directory, you can just ask: list files here\nTo read a file: read the file path/to/your/file.txt\nTo write a new file: write a new file named hello.txt with the content \"Hello, Gemini!\""
  },
  {
    "objectID": "posts/gemini_cli/index.html#use-cases",
    "href": "posts/gemini_cli/index.html#use-cases",
    "title": "Introduction to Gemini CLI",
    "section": "Use Cases",
    "text": "Use Cases\n\nRapid Prototyping: Quickly generate code for new ideas.\nLearning and Exploration: Get explanations for complex code or concepts.\nAutomation: Automate repetitive tasks by asking Gemini to write scripts.\nContent Creation: Draft emails, write documentation, or generate blog posts.\n\nGemini CLI is a versatile tool that can significantly boost your productivity. Explore its capabilities and integrate it into your workflow!"
  },
  {
    "objectID": "posts/gemini_cli/index.html#upgrading-the-gemini-cli",
    "href": "posts/gemini_cli/index.html#upgrading-the-gemini-cli",
    "title": "Introduction to Gemini CLI",
    "section": "Upgrading the Gemini CLI",
    "text": "Upgrading the Gemini CLI\nTo ensure you have the latest features and bug fixes, you can upgrade the package from time to time.\n\n\nCode\n# Upgrade the Gemini CLI to the latest version\nnpm upgrade -g @google/gemini-cli"
  },
  {
    "objectID": "posts/gemini_cli/index.html#login-with-your-google-account",
    "href": "posts/gemini_cli/index.html#login-with-your-google-account",
    "title": "Introduction to Gemini CLI",
    "section": "Login with Your Google Account",
    "text": "Login with Your Google Account\nYou can either log in with your Google Cloud account or use an API key.\n\nOption 1: Login with Google Cloud Account\n\n\nCode\n# Set your Google Cloud project ID\nexport GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"\n\n\nor save the GOOGLE_CLOUD_PROJECT into environment variable.So that do not need to re enter everytime\n\ncheck using zsh or bash\n\n\nCode\necho $SHELL\n\n\n\n\nfor zsh\n\n\nCode\necho 'export GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"' &gt;&gt; ~/.zshrc\n\nsource ~/.zshrc\n\n\n\n\nfor bash\n\n\nCode\necho 'export GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"' &gt;&gt; ~/.bashrc\n\nsource ~/.bashrc\n\n\n\n\ncheck wheather added or not\n\n\nCode\necho $GOOGLE_CLOUD_PROJECT\n\n\n\n\n\nOption 2: Login with API Key\nAlternatively, you can use an API key for authentication.\n\n\nCode\n# Set your Gemini API key as an environment variable\nexport GEMINI_API_KEY=\"your-gemini-api-key\""
  },
  {
    "objectID": "posts/gemini_cli/index.html#set-the-location",
    "href": "posts/gemini_cli/index.html#set-the-location",
    "title": "Introduction to Gemini CLI",
    "section": "Set the Location",
    "text": "Set the Location\nYou also need to specify the Google Cloud location where your resources will be managed.\n\n\nCode\n# Set the Google Cloud location\nexport GOOGLE_CLOUD_LOCATION='us-central1'"
  },
  {
    "objectID": "posts/gemini_cli/index.html#memory-tool-save_memory",
    "href": "posts/gemini_cli/index.html#memory-tool-save_memory",
    "title": "Introduction to Gemini CLI",
    "section": "Memory Tool (save_memory)",
    "text": "Memory Tool (save_memory)\nThe tool appends the provided fact to a special GEMINI.md file located in the user‚Äôs home directory (~/.gemini/GEMINI.md). This file can be configured to have a different name.\nOnce added, the facts are stored under a ## Gemini Added Memories section. This file is loaded as context in subsequent sessions, allowing the CLI to recall the saved information.\n\n\nCode\nsave_memory(fact=\"R program code chunk in quarto:\n```{r}  \n  \n```\n\")\n\n\n\n\nCode\nsave_memory(fact=\"Python program code chunk in quarto:\n```{python}  \n  \n```\n\")\n\n\nview the saved memory file\n\n\nCode\ncat ~/.gemini/GEMINI.md\n\n\nor open with sublime text editor\n\n\nCode\necho 'export PATH=\"/Applications/Sublime Text.app/Contents/SharedSupport/bin:$PATH\"' &gt;&gt; ~/.zprofile\n\nsubl ~/.gemini/GEMINI.md"
  },
  {
    "objectID": "posts/kimi2/index.html",
    "href": "posts/kimi2/index.html",
    "title": "Kimi2 with openrouter",
    "section": "",
    "text": "OpenRouter is a platform that provides a unified API for accessing a wide variety of large language models (LLMs) from different providers like Anthropic, Google, and Meta. It simplifies the process of integrating and using these models for developers, offering a single point of access instead of managing multiple APIs and accounts\n\n\nget api key from https://openrouter.ai/\n\n\nload package\n\n\nCode\nfrom openai import OpenAI\nimport keyring\n\n\n\n\ndefine model\n\n\nCode\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=keyring.get_password(\"system\", \"openrouter\"),\n)\n\n\n\n\ncall model\n\n\nCode\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;YOUR_SITE_URL&gt;\", # Optional. Site URL for rankings on openrouter.ai.\n    \"X-Title\": \"&lt;YOUR_SITE_NAME&gt;\", # Optional. Site title for rankings on openrouter.ai.\n  },\n  extra_body={},\n  model=\"moonshotai/kimi-k2:free\",\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"What is the meaning of life?\"\n    }\n  ]\n)\n\n\n\n\nget result\n\n\nCode\nprint(completion.choices[0].message.content)"
  },
  {
    "objectID": "posts/Streamlit/index.html",
    "href": "posts/Streamlit/index.html",
    "title": "Weather App with Streamlit",
    "section": "",
    "text": "Streamlit is an open-source Python library designed for building interactive web applications for data science and machine learning projects.\nWith Streamlit, you can quickly create web apps to visualize data, share machine learning models, and interact with datasets‚Äîall using simple Python scripts.\nThis project is to create a website using python and streamlit weather APP example\nCity Weather App"
  },
  {
    "objectID": "posts/Streamlit/index.html#first-setup-virtual-environment-with-python-version-3.13-using-uv-and-add-package",
    "href": "posts/Streamlit/index.html#first-setup-virtual-environment-with-python-version-3.13-using-uv-and-add-package",
    "title": "Weather App with Streamlit",
    "section": "1. First setup virtual environment with python version 3.13 using uv and add package",
    "text": "1. First setup virtual environment with python version 3.13 using uv and add package\nuv init --python python3.13\nuv add streamlit pandas requests great_tables plotly"
  },
  {
    "objectID": "posts/Streamlit/index.html#download-data-from-api",
    "href": "posts/Streamlit/index.html#download-data-from-api",
    "title": "Weather App with Streamlit",
    "section": "2. Download data from API",
    "text": "2. Download data from API\npython script download_data.py to download weather forcast data from open-meteo.com. This script will be run by a github action every day.\n\n\nCode\nimport pandas as pd\nimport requests\nfrom datetime import date, timedelta\nimport concurrent.futures\n\ndef generate_weather_data(city_name, lat, lon):\n    \"\"\"\n    Fetches weather and air quality data for a given city.\n    \"\"\"\n    # 1. Define Date Range\n    today = date.today()\n    start_date = today - timedelta(days=7)\n    end_date = today + timedelta(days=7)\n\n    # 2. Fetch Weather and Rain Probability Data\n    weather_df = None\n    try:\n        weather_url = \"https://api.open-meteo.com/v1/forecast\"\n        params = {\n            \"latitude\": lat,\n            \"longitude\": lon,\n            \"daily\": \"weather_code,temperature_2m_max,temperature_2m_min,precipitation_probability_mean\",\n            \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n            \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n            \"timezone\": \"auto\"\n        }\n        resp_weather = requests.get(weather_url, params=params)\n        resp_weather.raise_for_status()\n        weather_data_raw = resp_weather.json()\n        \n        weather_df = pd.DataFrame(weather_data_raw['daily'])\n        weather_df = weather_df.rename(columns={\n            \"time\": \"date\",\n            \"temperature_2m_max\": \"temperature_max\",\n            \"temperature_2m_min\": \"temperature_min\",\n            \"precipitation_probability_mean\": \"rain_prob\"\n        })\n        weather_df['date'] = pd.to_datetime(weather_df['date'])\n        weather_df['day'] = weather_df['date'].dt.strftime('%a')\n\n        weather_mapping = {\n            0: \"Clear\", 1: \"Mainly Clear\", 2: \"Partly Cloudy\", 3: \"Overcast\",\n            45: \"Fog\", 48: \"Rime Fog\", 51: \"Light Drizzle\", 53: \"Drizzle\", 55: \"Heavy Drizzle\",\n            56: \"Light Freezing Drizzle\", 57: \"Freezing Drizzle\", 61: \"Light Rain\", 63: \"Rain\",\n            65: \"Heavy Rain\", 66: \"Light Freezing Rain\", 67: \"Freezing Rain\", 71: \"Light Snow\",\n            73: \"Snow\", 75: \"Heavy Snow\", 77: \"Snow Grains\", 80: \"Light Showers\", 81: \"Showers\",\n            82: \"Heavy Showers\", 85: \"Light Snow Showers\", 86: \"Snow Showers\", 95: \"Thunderstorm\",\n            96: \"Thunderstorm with Hail\", 99: \"Heavy Thunderstorm with Hail\"\n        }\n        weather_df['weather'] = weather_df['weather_code'].map(weather_mapping)\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to fetch weather data for {city_name}: {e}\")\n        return None\n\n    # 3. Fetch Air Quality Data\n    aqi_df = None\n    try:\n        aqi_start_date = today - timedelta(days=7)\n        aqi_end_date = today\n        aqi_url = \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n        params = {\n            \"latitude\": lat,\n            \"longitude\": lon,\n            \"start_date\": aqi_start_date.strftime(\"%Y-%m-%d\"),\n            \"end_date\": aqi_end_date.strftime(\"%Y-%m-%d\"),\n            \"hourly\": \"pm2_5,us_aqi\",\n            \"timezone\": \"auto\"\n        }\n        resp_aqi = requests.get(aqi_url, params=params)\n        resp_aqi.raise_for_status()\n        aqi_data_raw = resp_aqi.json()\n        \n        if 'hourly' in aqi_data_raw:\n            aqi_df = pd.DataFrame(aqi_data_raw['hourly'])\n            aqi_df['date'] = pd.to_datetime(aqi_df['time']).dt.date\n            aqi_df = aqi_df.groupby('date').agg(\n                pm2_5=('pm2_5', 'median'),\n                us_aqi=('us_aqi', 'median')\n            ).reset_index()\n            aqi_df['date'] = pd.to_datetime(aqi_df['date'])\n\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to fetch AQI data for {city_name}: {e}\")\n\n    # 4. Combine and Process Data\n    combined_df = weather_df\n    if aqi_df is not None:\n        combined_df = pd.merge(combined_df, aqi_df, on=\"date\", how=\"left\")\n\n    combined_df['City'] = city_name\n    combined_df['lat'] = lat\n    combined_df['lon'] = lon\n    combined_df['forecast_flag'] = combined_df['date'].apply(lambda x: 'forecast' if x.date() &gt; today else 'current')\n    \n    def get_aqi_status(us_aqi):\n        if pd.isna(us_aqi):\n            return \"N/A\"\n        if us_aqi &lt;= 50:\n            return \"Good\"\n        if us_aqi &lt;= 100:\n            return \"Moderate\"\n        if us_aqi &lt;= 150:\n            return \"Unhealthy for Sensitive Groups\"\n        if us_aqi &lt;= 200:\n            return \"Unhealthy\"\n        if us_aqi &lt;= 300:\n            return \"Very Unhealthy\"\n        return \"Hazardous\"\n\n    if 'us_aqi' in combined_df.columns:\n        combined_df['us_aqi_status'] = combined_df['us_aqi'].apply(get_aqi_status)\n    else:\n        combined_df['us_aqi_status'] = \"N/A\"\n        combined_df['pm2_5'] = None\n        combined_df['us_aqi'] = None\n\n\n    return combined_df"
  },
  {
    "objectID": "posts/Streamlit/index.html#create-a-streamlit-app-to-display-the-plot-and-table",
    "href": "posts/Streamlit/index.html#create-a-streamlit-app-to-display-the-plot-and-table",
    "title": "Weather App with Streamlit",
    "section": "3. Create a streamlit app to display the plot and table",
    "text": "3. Create a streamlit app to display the plot and table\na streamlit app weather_app.py to display the weather with plotly and greate table\n\n\nCode\nimport pandas as pd\nimport streamlit as st\nfrom great_tables import GT, loc, style\nimport plotly.express as px\n\nst.set_page_config(layout=\"wide\")\n\n# Load the data\n@st.cache_data\ndef load_data():\n    return pd.read_csv(\"weather_data.csv\")\n\nweather_df = load_data()\n\n# City selection\ncities = weather_df[\"City\"].unique()\nselected_city = st.selectbox(\"Select a city\", cities)\n\n# Filter data for the selected city\ncity_df = weather_df[weather_df[\"City\"] == selected_city].reset_index(drop=True)\n\n@st.cache_data\ndef convert_df_to_csv(df):\n    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n    return df.to_csv(index=False).encode(\"utf-8\")\n\n\ncsv = convert_df_to_csv(city_df)\n\nst.download_button(\n    label=\"Download Weather Data (CSV)\",\n    data=csv,\n    file_name=f\"{selected_city}_weather_data.csv\",\n    mime=\"text/csv\",\n)\n\n\n# Display the Plotly chart\nst.header(\"Temperature Trend\")\nfig = px.line(city_df, x=\"date\", y=[\"temperature_max\", \"temperature_min\"], \n              labels={\"value\": \"Temperature (¬∞C)\", \"variable\": \"Temperature Type\"},\n              title=\"Max and Min Daily Temperatures\")\nst.plotly_chart(fig, use_container_width=True)\n\n\n\n# Display the Great Table\nst.header(f\"Weather Forecast for {selected_city}\")\n\ngt = GT(city_df)\n\ngt = gt.tab_header(\n    title=f\"{selected_city}\",\n    subtitle=f\"Weather from {pd.to_datetime(city_df['date'].min()).strftime('%B %d')} to {pd.to_datetime(city_df['date'].max()).strftime('%B %d, %Y')}\"\n)\n\n# Color AQI status\naqi_colors = {\n    \"Good\": \"#90EE90\",\n    \"Moderate\": \"#FFFF00\",\n    \"Unhealthy for Sensitive Groups\": \"#FFA500\",\n    \"Unhealthy\": \"#FF0000\",\n    \"Very Unhealthy\": \"#800080\",\n    \"Hazardous\": \"#808080\"\n}\n\nfor status, color in aqi_colors.items():\n    gt = gt.tab_style(\n        style=style.fill(color=color),\n        locations=loc.body(\n            columns=\"us_aqi_status\",\n            rows=lambda df: df[\"us_aqi_status\"] == status\n        )\n    )\n\n\ngt = gt.data_color(\n    columns=[\"rain_prob\"],\n    domain=[50, 100],\n    palette=[\"#ffcdd2\", \"#f44336\"],\n    na_color=\"#FFFFFF00\"\n)\n\ngt = gt.fmt_number(columns=[\"temperature_max\", \"temperature_min\", \"pm2_5\", \"us_aqi\"], decimals=1)\ngt = gt.fmt_percent(columns=[\"rain_prob\"], scale_values=False, decimals=0)\n\ngt = gt.cols_label(\n    date=\"Date\",\n    day=\"Day\",\n    temperature_max=\"Max Temp (¬∞C)\",\n    temperature_min=\"Min Temp (¬∞C)\",\n    weather=\"Weather\",\n    rain_prob=\"Rain Probability\",\n    pm2_5=\"PM2.5\",\n    us_aqi=\"US AQI\",\n    us_aqi_status=\"AQI Status\"\n)\n\nst.html(gt._repr_html_())"
  },
  {
    "objectID": "posts/Streamlit/index.html#run-the-streamlit-app-using-github-action",
    "href": "posts/Streamlit/index.html#run-the-streamlit-app-using-github-action",
    "title": "Weather App with Streamlit",
    "section": "4. Run the streamlit app using github action",
    "text": "4. Run the streamlit app using github action\ngithub action to run the streamlit app: .github/workflows/schedule-email.yml. it run every day 6:00PM Beijing time (22:00 UTC).And it will also run when a new push to the main branch.\nname: Refresh weather data\n\non: \n  push:\n    branches:\n      - main\n  schedule:\n    - cron: '0 22 * * *' # 6:00 AM Beijing time is 22:00 UTC\n\njobs:\n  refresh-data:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version-file: \"pyproject.toml\"\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v6\n\n      - name: Install the project\n        run: uv sync --locked --all-extras --dev\n            \n      - name: Run data download script\n        run: uv run download_data.py\n\n      - name: Commit and push if it changed\n        run: |-\n          git config user.name \"Automated Publisher\"\n          git config user.email \"actions@users.noreply.github.com\"\n          git add -A\n          timestamp=$(date -u)\n          git commit -m \"Latest data: ${timestamp}\" || exit 0\n          git push"
  },
  {
    "objectID": "posts/intro_markitdown/index.html",
    "href": "posts/intro_markitdown/index.html",
    "title": "Convert file like pdf to markdown",
    "section": "",
    "text": "MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines\n\n\ninstall markitdown\ngit clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e 'packages/markitdown[all]'\n\n\nconvert xlsx to md\n\n\nCode\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"weight.xlsx\")\nprint(result.text_content)\n\n\n\n\nCode\nwith open(\"weight.md\", \"w\") as f:\n    f.write(result.text_content)\n\n\n\n\nconvert pdf to md\n\n\nCode\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"Modern_intro_probability_statistics.pdf\")\n#print(result.text_content)\n\n\n\n\nCode\nwith open(\"Modern_intro_probability_statistics.md\", \"w\") as f:\n    f.write(result.text_content)\n\n\n\n\nconvert image to md with LLM model(currently only support Open AI)\nhttps://github.com/microsoft/markitdown/issues/1129\n\n\nCode\nfrom markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)\n\n\n\n\nreference:\nhttps://github.com/microsoft/markitdown"
  }
]