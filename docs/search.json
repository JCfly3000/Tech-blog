[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "SQL Handbook\nThis document provides a comprehensive guide to performing common data manipulation tasks using SQL, R, and Python. It serves as a reference for understanding how to achieve similar outcomes across these three popular data analysis tools.\n\n\nR Handboook\nThis project is a comprehensive guide to the R programming language, built with Quarto. It covers a wide range of topics, from the fundamentals of R to advanced applications in data manipulation, visualization, and publishing.\n\n\nPython Handbook\na comprehensive guide to Python for data science, covering a range of topics from the fundamentals to more advanced applications.\n\n\nStat Handbook\nThis collection of documents serves as a practical guide and a series of case studies in statistical analysis and machine learning. Each section explores a different dataset and a different set of techniques, providing a hands-on approach to learning and applying these methods.\n\n\nAI Handbook\na comprehensive resource for developers and data scientists looking to harness the power of Artificial Intelligence. This Quarto-based website provides a curated collection of tutorials, guides, and practical examples for using a variety of AI tools and models in both R and Python."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This page provides a brief introduction to the author of the blog and includes a link to their GitHub profile."
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html",
    "href": "posts/youtube_yt-dlp/index.html",
    "title": "Youtube下载工具：yt-dlp",
    "section": "",
    "text": "A guide to using yt-dlp, a command-line tool for downloading audio and video from YouTube and other sites.\nyt-dlp is a feature-rich command-line audio/video downloader with support for thousands of sites. The project is a fork of youtube-dl based on the now inactive youtube-dlc. This guide will walk you through the installation, update, and basic usage of yt-dlp for downloading YouTube videos.\nhttps://github.com/yt-dlp/yt-dlp"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#start-download-youtube",
    "href": "posts/youtube_yt-dlp/index.html#start-download-youtube",
    "title": "Youtube下载工具：yt-dlp",
    "section": "Start download youtube",
    "text": "Start download youtube\n\nCommand lineRPython\n\n\n\ndownload video with chrome cookies\nyt-dlp --cookies-from-browser chrome 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video with firefox cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\nyt-dlp --cookies-from-browser firefox 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video with export cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\n\n\nget video titles\nyt-dlp --cookies-from-browser firefox --get-title 'https://www.youtube.com/watch?v=yBl8UdSav5Y'\n\n\ndownload video to mp3 format\nyt-dlp --cookies-from-browser chrome -x --audio-format mp3 --audio-quality 0 'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\ndownload video with timestamp\nyt-dlp --cookies-from-browser chrome --download-sections '*00:02-03:00' 'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\ndownload video to mp4 with timestamp\nyt-dlp -f mp4 --cookies-from-browser chrome  --download-sections '*00:02-03:00'  'https://www.youtube.com/watch?v=FkOpwodhROI'\n\n\n\n\n\n\n\n\n\n\n="
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-chrome-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-chrome-cookies",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video with chrome cookies",
    "text": "download video with chrome cookies\nyt-dlp --cookies-from-browser chrome 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-firefox-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-firefox-cookies",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video with firefox cookies",
    "text": "download video with firefox cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome\nyt-dlp --cookies-from-browser firefox 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-export-cookies",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-export-cookies",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video with export cookies",
    "text": "download video with export cookies\nYou may also use a conforming browser extension for exporting cookies, such as Get cookies.txt LOCALLY for Chrome"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#get-video-titles",
    "href": "posts/youtube_yt-dlp/index.html#get-video-titles",
    "title": "Youtube下载工具：yt-dlp",
    "section": "get video titles",
    "text": "get video titles\nyt-dlp --cookies-from-browser firefox --get-title 'https://www.youtube.com/watch?v=yBl8UdSav5Y'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-to-mp3-format",
    "href": "posts/youtube_yt-dlp/index.html#download-video-to-mp3-format",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video to mp3 format",
    "text": "download video to mp3 format\nyt-dlp --cookies-from-browser chrome -x --audio-format mp3 --audio-quality 0 'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-with-timestamp",
    "href": "posts/youtube_yt-dlp/index.html#download-video-with-timestamp",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video with timestamp",
    "text": "download video with timestamp\nyt-dlp --cookies-from-browser chrome --download-sections '*00:02-03:00' 'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/youtube_yt-dlp/index.html#download-video-to-mp4-with-timestamp",
    "href": "posts/youtube_yt-dlp/index.html#download-video-to-mp4-with-timestamp",
    "title": "Youtube下载工具：yt-dlp",
    "section": "download video to mp4 with timestamp",
    "text": "download video to mp4 with timestamp\nyt-dlp -f mp4 --cookies-from-browser chrome  --download-sections '*00:02-03:00'  'https://www.youtube.com/watch?v=FkOpwodhROI'"
  },
  {
    "objectID": "posts/web_scraping_in_Python/index.html",
    "href": "posts/web_scraping_in_Python/index.html",
    "title": "Web scraping in Python",
    "section": "",
    "text": "A guide to web scraping in Python using the requests and BeautifulSoup libraries. This document outlines the basic steps and required libraries for extracting data from websites.\nThis document serves as a placeholder for a guide to web scraping in Python. It currently includes the necessary imports for the requests, BeautifulSoup, StringIO, re, and pandas libraries, indicating that the full guide will cover a comprehensive workflow for extracting and processing data from websites. The content is currently incomplete, but it sets the stage for a detailed tutorial on this topic.\nA placeholder document for demonstrating web scraping techniques using Python. It currently only includes imports for requests, BeautifulSoup, StringIO, re, and pandas, indicating an intention to use these libraries for web scraping tasks. The content is incomplete.\n\npython web scraping with requests and BeautifulSoup\n\n\nCode\nimport requests\nfrom bs4 import BeautifulSoup\nfrom io import StringIO\nimport re\nimport pandas as pd\n\n\n\n\nReference"
  },
  {
    "objectID": "posts/LLM_model/index.html",
    "href": "posts/LLM_model/index.html",
    "title": "（LLM）大语言模型",
    "section": "",
    "text": "An overview of Large Language Models (LLMs) and their performance across various benchmarks, including math, code, English, and science.\nThis document provides a comprehensive overview of Large Language Models (LLMs) and their performance across a variety of benchmarks. It categorizes the performance of different models by subject area, including mathematics, coding, English language understanding, and science. The document also provides links to resources where you can compare the performance of different LLM models online.\n(LLM)Large language model\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)\nCode\ndata001=read_excel('AI model.xlsx')\nhead(data001)"
  },
  {
    "objectID": "posts/LLM_model/index.html#math",
    "href": "posts/LLM_model/index.html#math",
    "title": "（LLM）大语言模型",
    "section": "math",
    "text": "math\n\nAIME\nhttps://en.wikipedia.org/wiki/American_Invitational_Mathematics_Examination\n\n\nMATH-500"
  },
  {
    "objectID": "posts/LLM_model/index.html#code",
    "href": "posts/LLM_model/index.html#code",
    "title": "（LLM）大语言模型",
    "section": "Code",
    "text": "Code"
  },
  {
    "objectID": "posts/LLM_model/index.html#codeforces",
    "href": "posts/LLM_model/index.html#codeforces",
    "title": "（LLM）大语言模型",
    "section": "Codeforces",
    "text": "Codeforces"
  },
  {
    "objectID": "posts/LLM_model/index.html#livecodebench",
    "href": "posts/LLM_model/index.html#livecodebench",
    "title": "（LLM）大语言模型",
    "section": "LiveCodeBench",
    "text": "LiveCodeBench"
  },
  {
    "objectID": "posts/LLM_model/index.html#english",
    "href": "posts/LLM_model/index.html#english",
    "title": "（LLM）大语言模型",
    "section": "English",
    "text": "English\n\nMMLU\nMeasuring Massive Multitask Language Understanding (MMLU)\nhttps://en.wikipedia.org/wiki/MMLU"
  },
  {
    "objectID": "posts/LLM_model/index.html#science",
    "href": "posts/LLM_model/index.html#science",
    "title": "（LLM）大语言模型",
    "section": "Science",
    "text": "Science\n\nGPQA-Diamond\nGraduate-Level Google-Proof Q&A\nDescription: GPQA consists of 448 multiple-choice questions meticulously crafted by domain experts in biology, physics, and chemistry. These questions are intentionally designed to be high-quality and extremely difficult.\nExpert Accuracy: Even experts who hold or are pursuing PhDs in the corresponding domains achieve only 65% accuracy on these questions (or 74% when excluding clear mistakes identified in retrospect).\nGoogle-Proof: The questions are “Google-proof,” meaning that even with unrestricted access to the web, highly skilled non-expert validators only reach an accuracy of 34% despite spending over 30 minutes searching for answers.\nAI Systems Difficulty: State-of-the-art AI systems, including our strongest GPT-4 based baseline, achieve only 39% accuracy on this challenging dataset."
  },
  {
    "objectID": "posts/send_email/index.html",
    "href": "posts/send_email/index.html",
    "title": "使用代码发邮件",
    "section": "",
    "text": "A guide to sending emails programmatically using the blastula package in R, covering credential setup, email composition, and sending from Gmail and Outlook.\nThis document provides a comprehensive guide to sending emails programmatically using R and Python. For R, it focuses on the blastula package, covering the entire workflow from creating SMTP credentials for Gmail and Outlook to composing and sending emails. It also demonstrates how to render Quarto content directly into an email body. The Python section is a placeholder for future content.\nUsing R or Python to send email"
  },
  {
    "objectID": "posts/send_email/index.html#load-library",
    "href": "posts/send_email/index.html#load-library",
    "title": "使用代码发邮件",
    "section": "load library",
    "text": "load library\n\n\nCode\nlibrary(blastula)\nlibrary(keyring)"
  },
  {
    "objectID": "posts/send_email/index.html#step-1-create-smtp-credentials",
    "href": "posts/send_email/index.html#step-1-create-smtp-credentials",
    "title": "使用代码发邮件",
    "section": "Step 1 create smtp credentials",
    "text": "Step 1 create smtp credentials\n\ngmail\n\n\nCode\ncreate_smtp_creds_key(\n  id = \"gmail001_creds\",\n  provider = \"gmail\",\n  user = \"verykoala@gmail.com\",\n  overwrite = TRUE\n  )\n\n\n\n\noutlook\n\n\nCode\n# create_smtp_creds_key(\n#   id = \"outlook001_creds\",\n#   provider = \"outlook\",\n#   user = \"jcpartner@outlook.com\",\n#   overwrite = TRUE\n#   )\n\ncreate_smtp_creds_file(file = \"ggnot_throwaway_creds\",\n                       user = \"jcpartner@outlook.com\",\n                       provider = \"outlook\")\n\n\n\n\nCode\n#delete_credential_key(\"gmail001_creds\")\n\n\n\n\nCode\nview_credential_keys()"
  },
  {
    "objectID": "posts/send_email/index.html#step-2-email-content",
    "href": "posts/send_email/index.html#step-2-email-content",
    "title": "使用代码发邮件",
    "section": "Step 2 email content",
    "text": "Step 2 email content\n\n\nCode\nlibrary(blastula)\nmsg=compose_email(\n  body = md(\n  \"Hi there 👋,\n  \n  This is an email to let you now thatrunning job **finished**.\n\n  Best,&lt;br&gt;\n  Tony\"\n  )\n)\n\nmsg"
  },
  {
    "objectID": "posts/send_email/index.html#step-3-send-email",
    "href": "posts/send_email/index.html#step-3-send-email",
    "title": "使用代码发邮件",
    "section": "Step 3 send email",
    "text": "Step 3 send email\n\nsend from gmailsend from outlook\n\n\n\n\nCode\nmsg %&gt;% \n  smtp_send(\n    from = 'verykoala@gmail.com',\n    to = \"jcflyingco@outlook.com\",\n    subject = \"Testing the email function\",\n    credentials = creds_key(id = \"gmail001_creds\")\n  )\n\n\n\n\n\n\nCode\nlibrary(Microsoft365R)\noutl &lt;- get_personal_outlook()\n\n\n\n\nCode\n# list the most recent emails in your Inbox\n#outl$list_emails()\n\n\n\n\nCode\nem &lt;- outl$create_email(msg, subject=\"Hello\", to=\"jcflyingco@outlook.com\")\n\n\n\n\nCode\nem$send()"
  },
  {
    "objectID": "posts/send_email/index.html#step3-option-b-send-email-with-quarto-content",
    "href": "posts/send_email/index.html#step3-option-b-send-email-with-quarto-content",
    "title": "使用代码发邮件",
    "section": "Step3 (option B) send email with quarto content",
    "text": "Step3 (option B) send email with quarto content\ncreate email Rmd file(.quarto_email.Rmd):\n\n\n\n\nCode\n\n.quarto_email.Rmd\n\n---\ntitle: \"Quarto Email\"\noutput: blastula::blastula_email \n---\n\n\n\n# tesing\n\ntesting\n\n\n# Reference:\nhttps://www.youtube.com/watch?v=PihKq1GPlcc\n\n\n\n\ncreate email\n\n\nCode\nemail_obj=render_email('.quarto_email.Rmd')\n\n\nView the email\n\n\nCode\nemail_obj\n\n\n\nsend from gmailsend from outlook\n\n\n\n\nCode\nemail_obj%&gt;% \n  smtp_send(\n    from = 'verykoala@gmail.com',\n    to = \"jcflyingco@outlook.com\",\n    subject = \"Testing the email function\",\n    credentials = creds_key(id = \"gmail001_creds\")\n  )\n\n\n\n\n\n\nCode\nem &lt;- outl$create_email(email_obj, subject=\"Hello\", to=\"jcflyingco@outlook.com\")\nem$send()"
  },
  {
    "objectID": "posts/run_ai_local/index.html",
    "href": "posts/run_ai_local/index.html",
    "title": "本地运行AI模型",
    "section": "",
    "text": "A guide to running AI models locally using Ollama and Hugging Face, with examples in R, Python, and the terminal.\nThis document provides a comprehensive guide to running AI models locally on your machine. It covers two popular platforms: Ollama and Hugging Face. For Ollama, it details the installation process and demonstrates how to manage and run LLM models using R (with the ollamar and ellmer packages), Python, and the terminal. For Hugging Face, it shows how to use models for tasks like text generation through both high-level pipelines and direct model loading in Python. The guide also includes examples of running other local models from the terminal."
  },
  {
    "objectID": "posts/run_ai_local/index.html#download-and-install-the-ollama-app",
    "href": "posts/run_ai_local/index.html#download-and-install-the-ollama-app",
    "title": "本地运行AI模型",
    "section": "Download and install the Ollama app",
    "text": "Download and install the Ollama app\nhttps://ollama.com/download\nand open the app on computer"
  },
  {
    "objectID": "posts/run_ai_local/index.html#run-llm-model-on-ollama",
    "href": "posts/run_ai_local/index.html#run-llm-model-on-ollama",
    "title": "本地运行AI模型",
    "section": "Run LLM model on Ollama",
    "text": "Run LLM model on Ollama\n\nRun in R with ollamar pacakgeRun in R with ellmer packageRun in terminal\n\n\n\ndownload pacakge check connection\n\n\nCode\npak::pak(\"ollamar\")\npak::pkg_deps_tree(\"ollamar\")\n\n\n\n\nCode\nlibrary(ollamar)\ntest_connection() \n\n\ndownload model\n\n\nCode\nollamar::pull(\"llama3.1\")\n\n\nlist downloaded model\n\n\nCode\nlist_models()\n\n\nshow model detail\n\n\nCode\nollamar::show(\"gemma3\")\n\n\nrun model\n\n\nCode\nresp &lt;- generate(\"gemma3\", \"tell me a 5-word story\")\nresp\n\n\n\n\nCode\n# get just the text from the response object\nresp_process(resp, \"text\")\n\n\n\n\nCode\n# get the text as a tibble dataframe\nresp_process(resp, \"df\")\n\n\nusing multiple models\n\n\nCode\n(list_models())$name\n\n\n\n\nCode\nmodels_name=(list_models())$name[-1]\nmodels_name\n\n\n\n\nCode\ninput_prompt=\"tell me a 5-word story\"\n\n\n\n\nCode\nall_model=c()\n\nfor (i in models_name){\n  resp &lt;- generate(i, input_prompt)\n  #print(paste0(\"Model: \", i))\n  print(resp_process(resp, \"text\"))\n  #resp_process(resp, \"df\")\n  all_model=rbind(all_model, resp_process(resp, \"df\"))\n}\n\n\n\n\nCode\nall_model\n\n\n\n\n\n\n\n\n\n\nCode\n!ollama pull llama3.1\n\n\n\n\nCode\n!ollama run llama3.1 \"tell me a 5-word story\"\n\n\n\nRun in Python\ninstall package\n\n\nCode\n!pip install ollama\n\n\nlocal pacakge\n\n\nCode\nimport json\nimport pandas as pd\nfrom pandas import json_normalize\n\n\nfrom ollama import chat\nfrom ollama import ChatResponse\nimport ollama\n\n\ndownload model\n\n\nCode\n#ollama.pull('llama3.2:1b')\n\n\nlist all download model\n\n\nCode\nollama_model=ollama.list()\n\n\n\n\nCode\n# Extracting data from the ListResponse\ndata = []\nfor model in ollama_model.models:\n    model_data = {\n        'model': model.model,\n        'modified_at': model.modified_at,\n        'digest': model.digest,\n        'size': (model.size/1000000000),\n        'parent_model': model.details.parent_model,\n        'format': model.details.format,\n        'family': model.details.family,\n        'families': model.details.families,\n        'parameter_size': model.details.parameter_size,\n        'quantization_level': model.details.quantization_level\n    }\n    data.append(model_data)\n\n# Convert the list of dictionaries into a pandas DataFrame\nollama_model_df = pd.DataFrame(data)\n\n# Show the DataFrame\nprint(ollama_model_df)\n\n\nslow model detail\n\n\nCode\nollama.show('deepseek-r1:7b-qwen-distill-q4_K_M')\n\n\ndelete model\n\n\nCode\n#ollama.delete('llama3.2:1b')\n\n\nrun model\n\n\nCode\nresponse: ChatResponse=ollama.chat(model='deepseek-r1:7b-qwen-distill-q4_K_M', messages=[\n  {'role': 'system', \n  'content': '你是一个诗人，你只能输出中文'},\n  \n  {'role': 'assistant', \n  'content': ''},\n  \n  {'role': 'user', \n  'content': 'give me a 3 lines story'}\n  ])\n\n\n\n\nCode\nprint(response.message.content)\n\n\n\n\nCode\nresponse: ChatResponse =ollama.chat(model='gemma3', messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n\n\n\n\nCode\nprint(response.message.content)\n\n\ncreate model\n\n\nCode\nollama.create(model='example_model', from_='llama3.2', system=\"You are Mario from Super Mario Bros.\")\n\n\npush model to ollama\n\n\nCode\nollama.push('user/example_model')"
  },
  {
    "objectID": "posts/run_ai_online/index.html",
    "href": "posts/run_ai_online/index.html",
    "title": "调用网络端AI模型",
    "section": "",
    "text": "A guide to interacting with online Large Language Models (LLMs) using R and Python, with examples for Google Gemini, local Ollama, and ChatGPT.\nThis document provides a comprehensive guide to interacting with online Large Language Models (LLMs) using both R and Python. It demonstrates how to use the ellmer and chattr packages in R, and the chatlas library in Python, to connect to various LLM services, including Google Gemini, locally hosted Ollama models, and ChatGPT. The guide covers setting up API keys, defining models, sending prompts, and processing responses for tasks like text generation and translation.\nrun LLM model online with ellmer or chatter"
  },
  {
    "objectID": "posts/run_ai_online/index.html#google-gemini",
    "href": "posts/run_ai_online/index.html#google-gemini",
    "title": "调用网络端AI模型",
    "section": "google gemini",
    "text": "google gemini\n\ngemini-2.0-flash\n\n\nCode\nchat_gemini_model=chat_gemini(\n  system_prompt = NULL,\n  turns = NULL,\n  base_url = \"https://generativelanguage.googleapis.com/v1beta/\",\n  api_key = key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  api_args = list(),\n  echo = NULL\n)\n\nchat_gemini_model\n\n\n\n\nCode\nchat_gemini_model$chat(\"Tell me three jokes about statisticians\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#ollama-on-local",
    "href": "posts/run_ai_online/index.html#ollama-on-local",
    "title": "调用网络端AI模型",
    "section": "ollama on local",
    "text": "ollama on local\n\nset up ollama local\n\n\nCode\nlibrary(ollamar)\nollamar::pull(\"llama3.1\")\n\n\n\n\nCode\nollamar::list_models()\n\n\n\n\ndifine model\n\n\nCode\nchat=chat_ollama(\n  system_prompt = NULL,\n  turns = NULL,\n  base_url = \"http://localhost:11434\",\n  model=\"llama3.1\",\n  seed = NULL,\n  api_args = list(),\n  echo = NULL\n)\n\nchat$get_model()\n\n\n\n\nrun LLM\n\n\nCode\nchat$chat(\"Tell me three jokes about statisticians\")\n\n\n\n\nrun on console\n\n\nCode\nlive_console(chat)\n\n\n\n\n\ncheck token usage\n\n\nCode\ntoken_usage()"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-1-install-package",
    "href": "posts/run_ai_online/index.html#step-1-install-package",
    "title": "调用网络端AI模型",
    "section": "Step 1 Install package",
    "text": "Step 1 Install package\n\n\nCode\n#remotes::install_github(\"mlverse/chattr\")\n\n\n\n\nCode\nlibrary(chattr)"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-2-set-key",
    "href": "posts/run_ai_online/index.html#step-2-set-key",
    "title": "调用网络端AI模型",
    "section": "Step 2 set key",
    "text": "Step 2 set key\n\nLogin at https://platform.openai.com/\nGoto Settings (gear icon on top right)\nFind API Keys from menu on left\nFollow the process to Create new secret key\nCopy your secret key (it will only show once so make sure you copy it)\n\n\n\nCode\nSys.setenv(OpenAI_API_KEY=\"sk-xxxxxxxx\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#step-3-run-chatgpt-as-background-job",
    "href": "posts/run_ai_online/index.html#step-3-run-chatgpt-as-background-job",
    "title": "调用网络端AI模型",
    "section": "Step 3 run ChatGPT as background job",
    "text": "Step 3 run ChatGPT as background job\n\nselect model\n\n\nCode\n#copilot do not need OpenAI_API_KEY\nchattr_use(\"copilot\")\n\n\n\n\nadd prompt\n\n\nCode\nchattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n\n\n\n\nrun ChatGPT as background jobs\nDo not use Copilot (GitHub) model for chattr(). Github will block this behavior.\n\n\nCode\n# run \nchattr_app(as_job = TRUE)\n\n\nDone!"
  },
  {
    "objectID": "posts/run_ai_online/index.html#or-setup-auto-open-chat-gpt-when-rstudio-start",
    "href": "posts/run_ai_online/index.html#or-setup-auto-open-chat-gpt-when-rstudio-start",
    "title": "调用网络端AI模型",
    "section": "Or setup auto open Chat GPT when Rstudio start",
    "text": "Or setup auto open Chat GPT when Rstudio start\n\nStep 1 find Rprofile file\n\n\nCode\n#install.packages(\"usethis\")  # Install if not already installed\nusethis::edit_r_profile()\n\n\n\n\nStep 2 edit Rprofile file as below\n\n\n\nCode\n\n.RProfile\n\n#|eval: false\n# Load chattr app after RStudio is fully loaded\nsetHook(\"rstudio.sessionInit\", function(newSession) {\n  if (newSession) {\n    Sys.sleep(2)  # Wait 2 seconds before starting chattr to ensure RStudio is ready\n    tryCatch({\n      library(chattr)\n      chattr_use(\"copilot\")\n      #Sys.setenv(\"OPENAI_API_KEY\" = \"your-api-key-here\")\n      chattr_defaults(prompt = \"{readLines(system.file('prompt/base.txt', package = 'chattr'))}\")\n\n      chattr_app(as_job = TRUE)\n    }, error = function(e)\n      message(\"Error starting chattr: \", e$message))\n  }\n}, action = \"append\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#gemini-model",
    "href": "posts/run_ai_online/index.html#gemini-model",
    "title": "调用网络端AI模型",
    "section": "gemini model",
    "text": "gemini model\n\n\nCode\nfrom chatlas import ChatGoogle\n\nchat_google_model = ChatGoogle(\n  model = \"gemini-2.0-flash\",\n  api_key=keyring.get_password(\"system\", \"google_ai_api_key\"),\n  system_prompt = \"You are a whisky expert\",\n)\n\nchat_google_model\n\n\n\n\nCode\nchat_google_model.chat(\"translate following whisky tasting note to English:微酸，脏麦芽。菲特肯还是要找1988\")"
  },
  {
    "objectID": "posts/run_ai_online/index.html#local-ollama-model",
    "href": "posts/run_ai_online/index.html#local-ollama-model",
    "title": "调用网络端AI模型",
    "section": "local Ollama model",
    "text": "local Ollama model\n\n\nCode\nfrom chatlas import ChatOllama\n\nchat_llama_model = ChatOllama(\n  model=\"llama3.2\",\n  #api_key=keyring.get_password(\"system\", \"google_ai_api_key\"),\n  system_prompt = \"You are a whisky expert\",\n)\n\nchat_llama_model\n\n\n\n\nCode\nchat_llama_model.chat(\"translate following whisky tasting note to English:微酸，脏麦芽。菲特肯还是要找1988\")\n\n\n\n\nCode\ntoken_usage()"
  },
  {
    "objectID": "posts/versioncontrol/index.html",
    "href": "posts/versioncontrol/index.html",
    "title": "Version control with renv",
    "section": "",
    "text": "A guide to using the renv package in R for creating reproducible environments and managing package versions. This document covers initialization, package installation, lock file management, and Python integration.\nThis document provides a comprehensive guide to using the renv package in R for creating reproducible environments and managing package versions. It covers the entire workflow, from initializing renv in a project to installing and updating packages, managing the lock file, and even integrating renv with Python. This guide is also part of the R handbook, making it a valuable resource for anyone looking to improve the reproducibility of their R projects.\nExplains how to use the renv package in R for reproducible environments and package version management. Covers renv initialization, package installation/updates, lock file management, and Python integration.\nThe renv package helps you create reproducible environments for your R projects\nIt section also update into R handbook\n# renv for R"
  },
  {
    "objectID": "posts/versioncontrol/index.html#inital-renv-and-create-renv.lock-with-current-loaded-pacakge",
    "href": "posts/versioncontrol/index.html#inital-renv-and-create-renv.lock-with-current-loaded-pacakge",
    "title": "Version control with renv",
    "section": "inital renv and create renv.lock with current loaded pacakge",
    "text": "inital renv and create renv.lock with current loaded pacakge\n\n\nCode\nrenv::init()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#show-all-installed-pacakge",
    "href": "posts/versioncontrol/index.html#show-all-installed-pacakge",
    "title": "Version control with renv",
    "section": "show all installed pacakge",
    "text": "show all installed pacakge\n\n\nCode\ninstalled_pacakge = as.data.frame(installed.packages()[,c(1,3:4)])\ninstalled_pacakge = installed_pacakge[is.na(installed_pacakge$Priority),1:2,drop=FALSE]\ninstalled_pacakge"
  },
  {
    "objectID": "posts/versioncontrol/index.html#show-all-installed-pacakge-and-uploaded-pacakge",
    "href": "posts/versioncontrol/index.html#show-all-installed-pacakge-and-uploaded-pacakge",
    "title": "Version control with renv",
    "section": "show all installed pacakge and uploaded pacakge",
    "text": "show all installed pacakge and uploaded pacakge\n\n\nCode\nlibrary(dplyr)\ninstalled_pacakge = as.data.frame(installed.packages()[,c(1,3:4)])\ninstalled_pacakge = installed_pacakge[is.na(installed_pacakge$Priority),1:2,drop=FALSE]\ninstalled_pacakge |&gt; filter(Package %in% (.packages()))"
  },
  {
    "objectID": "posts/versioncontrol/index.html#when-using-renv-and-install-new-pakcage",
    "href": "posts/versioncontrol/index.html#when-using-renv-and-install-new-pakcage",
    "title": "Version control with renv",
    "section": "when using renv and install new pakcage",
    "text": "when using renv and install new pakcage\n\n\nCode\n# it will not work\n# library(lubridate)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#need-to-install-new-package-with-renvinstall",
    "href": "posts/versioncontrol/index.html#need-to-install-new-package-with-renvinstall",
    "title": "Version control with renv",
    "section": "need to install new package with renv::install",
    "text": "need to install new package with renv::install\n\n\nCode\nrenv::install('lubridate')\n\n\n\n\nCode\nlibrary(lubridate)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-current-package-and-renv-package",
    "href": "posts/versioncontrol/index.html#check-current-package-and-renv-package",
    "title": "Version control with renv",
    "section": "check current package and renv package",
    "text": "check current package and renv package\n\n\nCode\nrenv::status()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file",
    "href": "posts/versioncontrol/index.html#update-lock-file",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-status-again",
    "href": "posts/versioncontrol/index.html#check-status-again",
    "title": "Version control with renv",
    "section": "check status again",
    "text": "check status again\n\n\nCode\nrenv::status()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list",
    "href": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list",
    "title": "Version control with renv",
    "section": "make all current pakcage version back to renv list",
    "text": "make all current pakcage version back to renv list\n\n\nCode\nrenv::restore()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-all-pakcage-in-renv.-recommand-do-it-once-a-year-to-keep-package-updated.",
    "href": "posts/versioncontrol/index.html#update-all-pakcage-in-renv.-recommand-do-it-once-a-year-to-keep-package-updated.",
    "title": "Version control with renv",
    "section": "update all pakcage in renv. recommand do it once a year to keep package updated.",
    "text": "update all pakcage in renv. recommand do it once a year to keep package updated.\n\n\nCode\nrenv::update()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-renv-itself-only",
    "href": "posts/versioncontrol/index.html#update-renv-itself-only",
    "title": "Version control with renv",
    "section": "update renv itself only",
    "text": "update renv itself only\n\n\nCode\nrenv::upgrade()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#close-renv-in-a-project",
    "href": "posts/versioncontrol/index.html#close-renv-in-a-project",
    "title": "Version control with renv",
    "section": "close renv in a project",
    "text": "close renv in a project\n\n\nCode\nrenv::deactivate()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#re-enable-renv-in-a-project",
    "href": "posts/versioncontrol/index.html#re-enable-renv-in-a-project",
    "title": "Version control with renv",
    "section": "re enable renv in a project",
    "text": "re enable renv in a project\n\n\nCode\nrenv::activate()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#set-python-version",
    "href": "posts/versioncontrol/index.html#set-python-version",
    "title": "Version control with renv",
    "section": "set python version",
    "text": "set python version\n\n\nCode\nrenv::use_python()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#check-python-version-in-renv",
    "href": "posts/versioncontrol/index.html#check-python-version-in-renv",
    "title": "Version control with renv",
    "section": "check python version in renv",
    "text": "check python version in renv\n\n\nCode\nfrom sys import version as python_formatted_version\nprint(python_formatted_version)"
  },
  {
    "objectID": "posts/versioncontrol/index.html#list-all-installed-pacakge-in-python",
    "href": "posts/versioncontrol/index.html#list-all-installed-pacakge-in-python",
    "title": "Version control with renv",
    "section": "list all installed pacakge in python",
    "text": "list all installed pacakge in python\n\n\nCode\nimport os\nprint(os.system('pip freeze'))"
  },
  {
    "objectID": "posts/versioncontrol/index.html#install-package",
    "href": "posts/versioncontrol/index.html#install-package",
    "title": "Version control with renv",
    "section": "install package",
    "text": "install package\n\n\nCode\nimport os\nos.system('python3.10 -m pip install siuba')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file-1",
    "href": "posts/versioncontrol/index.html#update-lock-file-1",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#uninstall-package",
    "href": "posts/versioncontrol/index.html#uninstall-package",
    "title": "Version control with renv",
    "section": "uninstall package",
    "text": "uninstall package\n\n\nCode\nimport os\nos.system('yes | python3.10 -m pip uninstall siuba')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list-1",
    "href": "posts/versioncontrol/index.html#make-all-current-pakcage-version-back-to-renv-list-1",
    "title": "Version control with renv",
    "section": "make all current pakcage version back to renv list",
    "text": "make all current pakcage version back to renv list\n\n\nCode\nrenv::restore()"
  },
  {
    "objectID": "posts/versioncontrol/index.html#install-package-1",
    "href": "posts/versioncontrol/index.html#install-package-1",
    "title": "Version control with renv",
    "section": "install package",
    "text": "install package\n\n\nCode\nimport os\nos.system('python3.10 -m pip install requests')"
  },
  {
    "objectID": "posts/versioncontrol/index.html#update-lock-file-2",
    "href": "posts/versioncontrol/index.html#update-lock-file-2",
    "title": "Version control with renv",
    "section": "update lock file",
    "text": "update lock file\n\n\nCode\nrenv::snapshot()"
  },
  {
    "objectID": "posts/TidyTuesday/index.html",
    "href": "posts/TidyTuesday/index.html",
    "title": "数据星期二",
    "section": "",
    "text": "A guide to the TidyTuesday data project, demonstrating how to access data and create interactive Shiny apps in both R and Python for data exploration and visualization.\nThis document provides a comprehensive guide to the TidyTuesday data project, demonstrating how to access and work with the data in both R and Python. It also includes detailed instructions on how to create interactive Shiny apps for data exploration and visualization. The guide covers everything from downloading the data to building a complete Shiny app with various plots and user inputs. This is a valuable resource for anyone looking to participate in the TidyTuesday project and improve their data science skills.\nExplores the TidyTuesday data project, demonstrating data access and interactive Shiny app creation in R and Python.\nTidyTuesday data project\ndata from github\n\ngetting the data\n\nRPython\n\n\n\n\nCode\n#pak::pak('tidytuesdayR')\n\n\n\n\nCode\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n\n\ndownload the data\nall available data\n\n\nCode\n#tt_available() \n\n\n\n\nCode\ntuesdata &lt;- tidytuesdayR::tt_load('2025-04-01')\n\n\n\n\nCode\ntuesdata\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport pydytuesday\n\n\n\n\nCode\npydytuesday.get_date('2025-04-15')\n\n\n\n\n\n\n\nmake a shiny\n\nRPython\n\n\n\nread data\n\n\nCode\ndata=tuesdata$pokemon_df\n#glimpse(data)\n\n\nor read directly from the url\n\n\nCode\ndata&lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv')\n\n\n\n\nusing shinyapps assistant to create shinyapp\nhttps://gallery.shinyapps.io/assistant\ngo to project folder and install quarto-ext/shinylive\n\n\nCode\nquarto add quarto-ext/shinylive\n\n\n\n\nPrompt:\ncreate a shinyapp with this data from github:https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv. left side: selector type_1 number of pokemon right side: histogram of height, color by type_2 histogram of weight, color by type_2 histogram of attack, color by type_2 histogram of defense color by type_2 barplot of color_1\nthere is no weight_kg,height_m.please use correct name.\n\n\nShiny R in quarto\nif adding shiny in quarto then adding this to yaml header\n---\n\nfilters:\n  - shinylive\n---\n\n\nCode\nlibrary(shiny)\nlibrary(bslib)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Load the Pokemon data\npokemon_data &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv\")\n\nui &lt;- page_sidebar(\n  title = \"Pokemon Data Explorer\",\n  sidebar = sidebar(\n    selectInput(\"type1\", \"Select Type 1:\", \n                choices = sort(unique(pokemon_data$type_1)),\n                selected = \"water\"),\n    hr(),\n    textOutput(\"pokemon_count\")\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Height Distribution by Type 2\"),\n      plotOutput(\"height_hist\")\n    ),\n    card(\n      card_header(\"Weight Distribution by Type 2\"),\n      plotOutput(\"weight_hist\")\n    )\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Attack Distribution by Type 2\"),\n      plotOutput(\"attack_hist\")\n    ),\n    card(\n      card_header(\"Defense Distribution by Type 2\"),\n      plotOutput(\"defense_hist\")\n    )\n  ),\n  \n  card(\n    card_header(\"Pokemon Color Distribution\"),\n    plotOutput(\"color_barplot\")\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # Filtered data based on the selected type_1\n  filtered_data &lt;- reactive({\n    pokemon_data %&gt;%\n      filter(type_1 == input$type1)\n  })\n  \n  # Display number of Pokemon\n  output$pokemon_count &lt;- renderText({\n    count &lt;- nrow(filtered_data())\n    paste(\"Number of Pokemon with Type 1 '\", input$type1, \"': \", count)\n  })\n  \n  # Height histogram colored by type_2\n  output$height_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = height, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Height\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Weight histogram colored by type_2\n  output$weight_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = weight, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Weight\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Attack histogram colored by type_2\n  output$attack_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = attack, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Attack\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Defense histogram colored by type_2\n  output$defense_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = defense, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Defense\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Barplot of color_1\n  output$color_barplot &lt;- renderPlot({\n    color_counts &lt;- filtered_data() %&gt;%\n      count(color_1) %&gt;%\n      arrange(desc(n))\n    \n    ggplot(color_counts, aes(x = reorder(color_1, n), y = n, fill = color_1)) +\n      geom_col() +\n      coord_flip() +\n      scale_fill_brewer(palette = \"Set3\") +\n      theme_minimal() +\n      labs(x = \"Color\", y = \"Count\", fill = \"Color\") +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui, server)\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 800\nlibrary(shiny)\nlibrary(bslib)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Load the Pokemon data\npokemon_data &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv\")\n\nui &lt;- page_sidebar(\n  title = \"Pokemon Data Explorer\",\n  sidebar = sidebar(\n    selectInput(\"type1\", \"Select Type 1:\", \n                choices = sort(unique(pokemon_data$type_1)),\n                selected = \"water\"),\n    hr(),\n    textOutput(\"pokemon_count\")\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Height Distribution by Type 2\"),\n      plotOutput(\"height_hist\")\n    ),\n    card(\n      card_header(\"Weight Distribution by Type 2\"),\n      plotOutput(\"weight_hist\")\n    )\n  ),\n  \n  layout_columns(\n    card(\n      card_header(\"Attack Distribution by Type 2\"),\n      plotOutput(\"attack_hist\")\n    ),\n    card(\n      card_header(\"Defense Distribution by Type 2\"),\n      plotOutput(\"defense_hist\")\n    )\n  ),\n  \n  card(\n    card_header(\"Pokemon Color Distribution\"),\n    plotOutput(\"color_barplot\")\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # Filtered data based on the selected type_1\n  filtered_data &lt;- reactive({\n    pokemon_data %&gt;%\n      filter(type_1 == input$type1)\n  })\n  \n  # Display number of Pokemon\n  output$pokemon_count &lt;- renderText({\n    count &lt;- nrow(filtered_data())\n    paste(\"Number of Pokemon with Type 1 '\", input$type1, \"': \", count)\n  })\n  \n  # Height histogram colored by type_2\n  output$height_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = height, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Height\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Weight histogram colored by type_2\n  output$weight_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = weight, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Weight\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Attack histogram colored by type_2\n  output$attack_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = attack, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Attack\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Defense histogram colored by type_2\n  output$defense_hist &lt;- renderPlot({\n    ggplot(filtered_data(), aes(x = defense, fill = type_2)) +\n      geom_histogram(alpha = 0.7, bins = 20, position = \"identity\") +\n      scale_fill_viridis_d() +\n      theme_minimal() +\n      labs(x = \"Defense\", y = \"Count\", fill = \"Type 2\")\n  })\n  \n  # Barplot of color_1\n  output$color_barplot &lt;- renderPlot({\n    color_counts &lt;- filtered_data() %&gt;%\n      count(color_1) %&gt;%\n      arrange(desc(n))\n    \n    ggplot(color_counts, aes(x = reorder(color_1, n), y = n, fill = color_1)) +\n      geom_col() +\n      coord_flip() +\n      scale_fill_brewer(palette = \"Set3\") +\n      theme_minimal() +\n      labs(x = \"Color\", y = \"Count\", fill = \"Color\") +\n      theme(legend.position = \"none\")\n  })\n}\n\nshinyApp(ui, server)\n\n\n\n\n\ninstall shiny in python\nNeed to down grade shinylive Python version to 0.7.1 in order to match shinylive R version\n\n\nCode\nimport os\nos.system(\"pip install 'shinylive==0.7.1'\")\n\n\n\n\nread data\n\n\nCode\npenguins = pd.read_csv('penguins.csv')\npenguins_raw = pd.read_csv('penguins_raw.csv')\n\n\n\n\nCode\n# Option 2: Read directly from GitHub and assign to an object\n#penguins = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n#penguins_raw = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv')\n\n\n\n\nusing shinyapps assistant to create shinyapp\nhttps://gallery.shinyapps.io/assistant\ninstall shinylive\n\n\nCode\npip install shinylive\n\n\n\n\nPrompt:\ncreate a shinyapp with this data from github:https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv.\nspecies choices is not correct,please use correct choices.\n\n\nShiny Python in quarto\nif adding shiny in quarto then adding this to yaml header\n---\n\nfilters:\n  - shinylive\n---\n\n\nCode\nfrom shiny import App, reactive, render, ui\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport urllib3\n\napp_ui = ui.page_sidebar(\n    ui.sidebar(\n        ui.h3(\"Penguin Data Explorer\"),\n        ui.input_select(\n            \"species\",\n            \"Select Penguin Species\",\n            choices=[\"All Species\", \"Adelie Penguin (Pygoscelis adeliae)\", \n                     \"Gentoo penguin (Pygoscelis papua)\", \n                     \"Chinstrap penguin (Pygoscelis antarctica)\"]\n        ),\n        ui.input_select(\n            \"plot_type\",\n            \"Select Plot Type\",\n            choices=[\n                \"Body Mass vs Flipper Length\",\n                \"Culmen Length vs Depth\",\n                \"Histogram of Body Mass\"\n            ]\n        ),\n        ui.input_checkbox_group(\n            \"islands\",\n            \"Select Islands\",\n            choices=[\"Torgersen\", \"Biscoe\", \"Dream\"],\n            selected=[\"Torgersen\", \"Biscoe\", \"Dream\"]\n        ),\n        ui.hr(),\n        ui.p(\"Data from Palmer Penguins dataset via TidyTuesday.\"),\n    ),\n    ui.card(\n        ui.card_header(\"Penguin Data Visualization\"),\n        ui.output_plot(\"penguin_plot\")\n    ),\n    ui.card(\n        ui.card_header(\"Data Summary\"),\n        ui.output_table(\"summary_table\")\n    )\n)\n\ndef server(input, output, session):\n    # Load data\n    @reactive.calc\n    def load_data():\n        http = urllib3.PoolManager()\n        url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv\"\n        \n        try:\n            response = http.request('GET', url)\n            if response.status != 200:\n                # If file not found, use fallback URL\n                fallback_url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins_raw.csv\"\n                response = http.request('GET', fallback_url)\n                \n            data = pd.read_csv(pd.io.common.StringIO(response.data.decode('utf-8')))\n            return data\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            # Return empty dataframe if there are issues\n            return pd.DataFrame()\n\n    @reactive.calc\n    def filtered_data():\n        data = load_data()\n        if data.empty:\n            return pd.DataFrame()\n        \n        # Clean column names\n        data.columns = [col.strip() for col in data.columns]\n        \n        # Filter data based on inputs\n        filtered = data.copy()\n        \n        # Filter by species\n        if input.species() != \"All Species\":\n            filtered = filtered[filtered['Species'] == input.species()]\n        \n        # Filter by islands\n        filtered = filtered[filtered['Island'].isin(input.islands())]\n        \n        return filtered\n\n    @output\n    @render.plot\n    def penguin_plot():\n        data = filtered_data()\n        if data.empty:\n            fig, ax = plt.subplots()\n            ax.text(0.5, 0.5, \"No data available or error loading data\", \n                    ha='center', va='center')\n            ax.set_xlim(0, 1)\n            ax.set_ylim(0, 1)\n            ax.axis('off')\n            return fig\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        plot_type = input.plot_type()\n        \n        if plot_type == \"Body Mass vs Flipper Length\":\n            sns.scatterplot(\n                data=data, \n                x='Flipper Length (mm)', \n                y='Body Mass (g)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Body Mass vs Flipper Length\")\n            \n        elif plot_type == \"Culmen Length vs Depth\":\n            sns.scatterplot(\n                data=data, \n                x='Culmen Length (mm)', \n                y='Culmen Depth (mm)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Culmen Length vs Depth\")\n            \n        elif plot_type == \"Histogram of Body Mass\":\n            sns.histplot(\n                data=data,\n                x='Body Mass (g)',\n                hue='Species',\n                kde=True,\n                ax=ax\n            )\n            ax.set_title(\"Distribution of Body Mass\")\n            \n        plt.tight_layout()\n        return fig\n\n    @output\n    @render.table\n    def summary_table():\n        data = filtered_data()\n        if data.empty:\n            return pd.DataFrame({'Message': ['No data available or error loading data']})\n        \n        # Create a summary table with counts by species and island\n        summary = data.groupby(['Species', 'Island', 'Sex']).size().reset_index(name='Count')\n        \n        # Add some descriptive statistics\n        stats = data.groupby(['Species']).agg({\n            'Body Mass (g)': ['mean', 'std'],\n            'Flipper Length (mm)': ['mean', 'std'],\n            'Culmen Length (mm)': ['mean', 'std'],\n            'Culmen Depth (mm)': ['mean', 'std']\n        }).round(2)\n        \n        stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n        stats = stats.reset_index()\n        \n        return summary\n\napp = App(app_ui, server)\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 800\nfrom shiny import App, reactive, render, ui\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport urllib3\n\napp_ui = ui.page_sidebar(\n    ui.sidebar(\n        ui.h3(\"Penguin Data Explorer\"),\n        ui.input_select(\n            \"species\",\n            \"Select Penguin Species\",\n            choices=[\"All Species\", \"Adelie Penguin (Pygoscelis adeliae)\", \n                     \"Gentoo penguin (Pygoscelis papua)\", \n                     \"Chinstrap penguin (Pygoscelis antarctica)\"]\n        ),\n        ui.input_select(\n            \"plot_type\",\n            \"Select Plot Type\",\n            choices=[\n                \"Body Mass vs Flipper Length\",\n                \"Culmen Length vs Depth\",\n                \"Histogram of Body Mass\"\n            ]\n        ),\n        ui.input_checkbox_group(\n            \"islands\",\n            \"Select Islands\",\n            choices=[\"Torgersen\", \"Biscoe\", \"Dream\"],\n            selected=[\"Torgersen\", \"Biscoe\", \"Dream\"]\n        ),\n        ui.hr(),\n        ui.p(\"Data from Palmer Penguins dataset via TidyTuesday.\"),\n    ),\n    ui.card(\n        ui.card_header(\"Penguin Data Visualization\"),\n        ui.output_plot(\"penguin_plot\")\n    ),\n    ui.card(\n        ui.card_header(\"Data Summary\"),\n        ui.output_table(\"summary_table\")\n    )\n)\n\ndef server(input, output, session):\n    # Load data\n    @reactive.calc\n    def load_data():\n        http = urllib3.PoolManager()\n        url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins_raw.csv\"\n        \n        try:\n            response = http.request('GET', url)\n            if response.status != 200:\n                # If file not found, use fallback URL\n                fallback_url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins_raw.csv\"\n                response = http.request('GET', fallback_url)\n                \n            data = pd.read_csv(pd.io.common.StringIO(response.data.decode('utf-8')))\n            return data\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            # Return empty dataframe if there are issues\n            return pd.DataFrame()\n\n    @reactive.calc\n    def filtered_data():\n        data = load_data()\n        if data.empty:\n            return pd.DataFrame()\n        \n        # Clean column names\n        data.columns = [col.strip() for col in data.columns]\n        \n        # Filter data based on inputs\n        filtered = data.copy()\n        \n        # Filter by species\n        if input.species() != \"All Species\":\n            filtered = filtered[filtered['Species'] == input.species()]\n        \n        # Filter by islands\n        filtered = filtered[filtered['Island'].isin(input.islands())]\n        \n        return filtered\n\n    @output\n    @render.plot\n    def penguin_plot():\n        data = filtered_data()\n        if data.empty:\n            fig, ax = plt.subplots()\n            ax.text(0.5, 0.5, \"No data available or error loading data\", \n                    ha='center', va='center')\n            ax.set_xlim(0, 1)\n            ax.set_ylim(0, 1)\n            ax.axis('off')\n            return fig\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        plot_type = input.plot_type()\n        \n        if plot_type == \"Body Mass vs Flipper Length\":\n            sns.scatterplot(\n                data=data, \n                x='Flipper Length (mm)', \n                y='Body Mass (g)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Body Mass vs Flipper Length\")\n            \n        elif plot_type == \"Culmen Length vs Depth\":\n            sns.scatterplot(\n                data=data, \n                x='Culmen Length (mm)', \n                y='Culmen Depth (mm)',\n                hue='Species',\n                style='Sex',\n                ax=ax\n            )\n            ax.set_title(\"Culmen Length vs Depth\")\n            \n        elif plot_type == \"Histogram of Body Mass\":\n            sns.histplot(\n                data=data,\n                x='Body Mass (g)',\n                hue='Species',\n                kde=True,\n                ax=ax\n            )\n            ax.set_title(\"Distribution of Body Mass\")\n            \n        plt.tight_layout()\n        return fig\n\n    @output\n    @render.table\n    def summary_table():\n        data = filtered_data()\n        if data.empty:\n            return pd.DataFrame({'Message': ['No data available or error loading data']})\n        \n        # Create a summary table with counts by species and island\n        summary = data.groupby(['Species', 'Island', 'Sex']).size().reset_index(name='Count')\n        \n        # Add some descriptive statistics\n        stats = data.groupby(['Species']).agg({\n            'Body Mass (g)': ['mean', 'std'],\n            'Flipper Length (mm)': ['mean', 'std'],\n            'Culmen Length (mm)': ['mean', 'std'],\n            'Culmen Depth (mm)': ['mean', 'std']\n        }).round(2)\n        \n        stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n        stats = stats.reset_index()\n        \n        return summary\n\napp = App(app_ui, server)\n\n\n\n\n\n\n\n\nReference\nhttps://github.com/rfordatascience/tidytuesday\nhttps://github.com/posit-dev/python-tidytuesday"
  },
  {
    "objectID": "posts/makeQRcode/index.html",
    "href": "posts/makeQRcode/index.html",
    "title": "Make QR code",
    "section": "",
    "text": "A guide to generating QR codes in R and Python.\nThis document demonstrates how to generate QR codes using both R and Python. It provides code examples for creating QR codes from a given string, saving them as SVG or PNG files, and displaying them. The R section uses the qrcode package, while the Python section uses the qrcode and scikit-image libraries.\n\nR\n\n\nCode\npak::pkg_install('qrcode')\n\n\n\n\nCode\nlibrary(reticulate)\nuse_python(\"/Library/Frameworks/Python.framework/Versions/3.13/bin/python3.13\")\npy_require(c('qrcode','Pillow','numpy','scikit-image'))\n\n\n\n\nCode\nlibrary(qrcode)\ncode=qr_code(\"https://rfor.us/posit2024slides\") \n\n\nSave the QR code as a SVG file\n\n\nCode\ngenerate_svg(code, filename = \"qr.svg\")\n\n\n\n\nCode\nplot(code)\n\n\n\n\n\n\n\n\n\n\n\nPython\n\n\nCode\n!pip install qrcode scikit-image\n\n\n\n\nCode\nimport platform\nprint(platform.python_version())\n\n\n3.13.2\n\n\n\n\nCode\nimport qrcode\nimg = qrcode.make(\"https://rfor.us/posit2024slides\")\ntype(img)  # qrcode.image.pil.PilImage\n\n\n&lt;class 'qrcode.image.pil.PilImage'&gt;\n\n\nsave the QR code as a PNG file\n\n\nCode\nimg.save(\"some_file.png\")\n\n\n\n\nCode\nfrom skimage import io\nimg = io.imread(\"some_file.png\")\nio.imshow(img)"
  },
  {
    "objectID": "posts/python_code_optimization/index.html",
    "href": "posts/python_code_optimization/index.html",
    "title": "Python code optimization with ruff",
    "section": "",
    "text": "A guide to using ruff for Python code linting and formatting, including installation, usage, and integration with Positron.\nThis document provides a comprehensive guide to using ruff, a fast and efficient Python linter and formatter. It covers the essential steps for getting started with ruff, including installation, checking your code for issues, and automatically fixing them. The guide also demonstrates how to format your code with ruff and how to integrate it as an extension in the Positron IDE. Additionally, it outlines a practical workflow for using ruff on .qmd files by first converting them to .py format."
  },
  {
    "objectID": "posts/python_code_optimization/index.html#convert-.qmd-to-.py",
    "href": "posts/python_code_optimization/index.html#convert-.qmd-to-.py",
    "title": "Python code optimization with ruff",
    "section": "convert .qmd to .py",
    "text": "convert .qmd to .py\n\n\n\nCode\n\nTerminal\n\nquarto convert index.qmd    # → index.ipynb\n\n\n\n\n\n\nCode\n\nTerminal\n\n!jupyter nbconvert --to python index.ipynb    # → index.py"
  },
  {
    "objectID": "posts/python_code_optimization/index.html#check-.py-with-ruff",
    "href": "posts/python_code_optimization/index.html#check-.py-with-ruff",
    "title": "Python code optimization with ruff",
    "section": "check .py with ruff",
    "text": "check .py with ruff\n\n\n\nCode\n\nTerminal\n\n!ruff check index.py"
  },
  {
    "objectID": "posts/linux_command/index.html",
    "href": "posts/linux_command/index.html",
    "title": "Linux系统操作代码",
    "section": "",
    "text": "A quick reference guide for common Linux commands, covering basic file operations, system information, and process management.\nThis document serves as a quick reference guide for a wide range of common Linux commands. It covers fundamental operations such as printing text, viewing manual pages, and navigating the file system. The guide also includes commands for file and folder management, such as listing, creating, and deleting files and folders, as well as downloading files from the internet and changing file permissions. Additionally, it provides commands for system information and process management, including checking folder sizes, installing software, editing files, viewing file content, and managing running processes.\nTop useful Linux command"
  },
  {
    "objectID": "posts/linux_command/index.html#create-txt-file",
    "href": "posts/linux_command/index.html#create-txt-file",
    "title": "Linux系统操作代码",
    "section": "create txt file",
    "text": "create txt file\nnano"
  },
  {
    "objectID": "posts/linux_command/index.html#edit-current-txt-file",
    "href": "posts/linux_command/index.html#edit-current-txt-file",
    "title": "Linux系统操作代码",
    "section": "edit current txt file",
    "text": "edit current txt file\nnano test.txt"
  },
  {
    "objectID": "posts/AI_subtitles/index.html",
    "href": "posts/AI_subtitles/index.html",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "",
    "text": "A workflow for generating and embedding bilingual subtitles for videos, covering video/audio downloading, transcription with mlx_whisper, translation with Gemini 2.0 Flash, and embedding with FFmpeg.\nThis document outlines a complete workflow for automatically generating and embedding bilingual (Chinese and English) subtitles for videos. It covers every step of the process, from downloading the video and audio from YouTube using yt-dlp to transcribing the audio to text with the mlx_whisper model. The guide also demonstrates how to use the Gemini 2.0 Flash model to correct and translate the transcribed text, and finally, how to embed the generated subtitles into the video using FFmpeg. This is a comprehensive resource for anyone looking to make their video content more accessible to a wider audience.\nUse mlx_whisper for transcribing audio to text, and use gemini-2.0-flash for correction\nLoad R packages\nCode\n#pak::pkg_install('tuneR')\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#check-mp3-duration",
    "href": "posts/AI_subtitles/index.html#check-mp3-duration",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "check mp3 duration",
    "text": "check mp3 duration\n\n\nCode\n# Load the MP3 file\n# Load the MP3 file\nmp3_file &lt;- readMP3(mp3_title)\n\n# Get the duration in seconds\nduration_mins &lt;- (length(mp3_file@left) / mp3_file@samp.rate)/60\nduration_mins"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#trim-mp3-if-needed",
    "href": "posts/AI_subtitles/index.html#trim-mp3-if-needed",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "trim mp3 if needed",
    "text": "trim mp3 if needed\n\n\nCode\n# library(lares)\n# trim_mp3(\n#   mp3_title,\n#   start_time = 1,\n#   end_time = 9999999,\n#   overwrite = FALSE,\n#   ext = \"mp3\",\n#   quiet = FALSE\n# )\n\n\n# output file:\n#paste0(mp3_title |&gt; str_replace('.mp3,',''),\"_trim.mp3\")"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#define-model",
    "href": "posts/AI_subtitles/index.html#define-model",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"你是一个中文和英文的语言学家\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model\n\n\n\n\nCode\n#testing model connection\nchat_result=chat_gemini_model$chat(\"hello\")\nchat_result"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#run-model",
    "href": "posts/AI_subtitles/index.html#run-model",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt0=read_srt('text.srt')\nsrt_txt2=srt_txt0$subtitle|&gt; as.character()\n\n\n\n\nCode\nlength(srt_txt2)\n\n\n\n\nCode\nprompt_text=paste0('把以下文字是通过语言识别出来的文字。如果有错别字请更正并输出中文。保持更正后的文字与原文的文字长度一样。也保持句子总长度与更正后的句子总长度一致。比如hovah请更正为福建人。没有错则不变。有更正的句子后面加上!!!!。不要多余的反馈。输出格式为:更正前的句子《---》更正后的句子 ',srt_txt2)\nchat_result1=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\nall_result2=unlist(strsplit(chat_result1, \"\\n\"))\nlength(all_result2)\n#all_result2= c(all_result2,\"\")"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#add-to-data",
    "href": "posts/AI_subtitles/index.html#add-to-data",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "add to data",
    "text": "add to data\n\n\nCode\nsrt_txt=srt_txt0 |&gt; mutate(correct_txt=all_result2 |&gt; str_replace('!!!!','')|&gt; str_extract( \"(?&lt;=《---》).*\")\n                           ,all_correct_txt=all_result2\n                           \n                           )"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#define-model-1",
    "href": "posts/AI_subtitles/index.html#define-model-1",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "define model",
    "text": "define model\n中翻英 using google LLM model gemini-2.0-flash\n\n\nCode\nchat_gemini_model_translate&lt;- chat_gemini(\n  system_prompt = \"你是一个中文和英文的翻译专家\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model_translate"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#run-model-1",
    "href": "posts/AI_subtitles/index.html#run-model-1",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "run model",
    "text": "run model\n\n\nCode\ncorrect_txt=srt_txt$correct_txt|&gt; as.character()\n\n\n\n\nCode\nprompt_text=paste0('请联系上下文把以下文字翻译成英文。总句子数量不变。不要多余的反馈。输出格式为:原来的文字《---》翻译成英文',correct_txt)\nchat_result1=chat_gemini_model_translate$chat(prompt_text)\n\n\n\n\nCode\nall_result2=unlist(strsplit(chat_result1, \"\\n\"))\nlength(all_result2)\n#all_result2=all_result2[1:422]"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#add-to-data-1",
    "href": "posts/AI_subtitles/index.html#add-to-data-1",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "add to data",
    "text": "add to data\n\n\nCode\nsrt_txt=srt_txt |&gt; mutate(correct_english_txt=all_result2 |&gt; str_extract( \"(?&lt;=《---》).*\"))"
  },
  {
    "objectID": "posts/AI_subtitles/index.html#output-srt_txt",
    "href": "posts/AI_subtitles/index.html#output-srt_txt",
    "title": "使用AI给视频自动生成中英文字幕",
    "section": "output srt_txt",
    "text": "output srt_txt\n\n\nCode\nwrite.xlsx(srt_txt,'srt_data.xlsx')"
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html",
    "href": "posts/web_scraping_in_R_with_rvest/index.html",
    "title": "Web scraping in R with rvest",
    "section": "",
    "text": "A guide to web scraping in R using the rvest package, with examples of how to extract text, links, and tables from web pages.\nThis document provides a comprehensive guide to web scraping in R using the rvest package. It covers the entire workflow, from reading HTML content from a URL to extracting specific elements like text, links, and tables. The guide also introduces advanced techniques with read_html_live() for dynamic web pages that require interaction, such as scrolling, to load content. This document is also part of the R handbook."
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html#get-3rd-table",
    "href": "posts/web_scraping_in_R_with_rvest/index.html#get-3rd-table",
    "title": "Web scraping in R with rvest",
    "section": "get 3rd table",
    "text": "get 3rd table\nfind table xpath\n\n\nCode\ntable=page %&gt;%html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[3]') |&gt; html_table()\ntable |&gt; head()\n\n\n# A tibble: 6 × 11\n  `Driver name`     Nationality    `Seasons competed` `Drivers' Championships`\n  &lt;chr&gt;             &lt;chr&gt;          &lt;chr&gt;              &lt;chr&gt;                   \n1 Carlo Abate       Italy          1962–1963          0                       \n2 George Abecassis  United Kingdom 1951–1952          0                       \n3 Kenny Acheson     United Kingdom 1983, 1985         0                       \n4 Andrea de Adamich Italy          1968, 1970–1973    0                       \n5 Philippe Adams    Belgium        1994               0                       \n6 Walt Ader         United States  1950               0                       \n# ℹ 7 more variables: `Race entries` &lt;chr&gt;, `Race starts` &lt;chr&gt;,\n#   `Pole positions` &lt;chr&gt;, `Race wins` &lt;chr&gt;, Podiums &lt;chr&gt;,\n#   `Fastest laps` &lt;chr&gt;, `Points[a]` &lt;chr&gt;"
  },
  {
    "objectID": "posts/web_scraping_in_R_with_rvest/index.html#get-4th-table",
    "href": "posts/web_scraping_in_R_with_rvest/index.html#get-4th-table",
    "title": "Web scraping in R with rvest",
    "section": "get 4th table",
    "text": "get 4th table\nfind table xpath\n\n\nCode\ntable=page %&gt;%html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[4]') |&gt; html_table()\ntable |&gt; head()\n\n\n# A tibble: 6 × 7\n  Country     Totaldrivers Champions Championships `Race wins` `First driver(s)`\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;            \n1 Argentinad… 26           1(Fangio… 5(1951, 1954… \"38\\n(Fang… Juan Manuel Fang…\n2 Australiad… 18           2(Brabha… 4(1959, 1960… \"50\\n(Brab… Tony Gaze(1952 B…\n3 Austriadet… 16           2(Rindt,… 4(1970, 1975… \"41\\n(Rind… Jochen Rindt(196…\n4 Belgiumdet… 24           0         0             \"11\\n(Ickx… Johnny Claes(195…\n5 Brazildeta… 33           3(Fittip… 8(1972, 1974… \"101\\n(Fit… Chico Landi(1951…\n6 Canadadeta… 15           1(J. Vil… 1(1997)       \"17\\n(G. V… Peter Ryan(1961 …\n# ℹ 1 more variable: `Most recent driver(s)/Current driver(s)` &lt;chr&gt;"
  },
  {
    "objectID": "posts/r_code_optimization/index.html",
    "href": "posts/r_code_optimization/index.html",
    "title": "R code optimization with lintr and styler",
    "section": "",
    "text": "An introduction to lintr and styler for R code optimization, with examples of how to use them for static code analysis and formatting.\nThis document introduces two essential R packages for code optimization: lintr and styler. It explains how lintr performs static code analysis to help you identify and fix style inconsistencies, syntax errors, and other potential issues in your R code. The document also demonstrates how styler can automatically format your code to adhere to the tidyverse style guide, ensuring consistency and readability. You’ll find practical examples of how to use both packages to improve the quality of your R code.\npacakge for R code optimization"
  },
  {
    "objectID": "posts/r_code_optimization/index.html#before",
    "href": "posts/r_code_optimization/index.html#before",
    "title": "R code optimization with lintr and styler",
    "section": "Before",
    "text": "Before\n\n\nCode\nlibrary(\"dplyr\")\n\n   Good &lt;- 1\napplePie &lt;- Good + 1\n    Peter &lt;- d + 1"
  },
  {
    "objectID": "posts/r_code_optimization/index.html#auto-formating",
    "href": "posts/r_code_optimization/index.html#auto-formating",
    "title": "R code optimization with lintr and styler",
    "section": "Auto formating",
    "text": "Auto formating\n\n\n\nCode\n\ntest.R\n\nstyle_file(\"test.R\")\n\n\n\nStyling  1  files:\n test.R ✔ \n────────────────────────────────────────\nStatus  Count   Legend \n✔   1   File unchanged.\nℹ   0   File changed.\n✖   0   Styling threw an error.\n────────────────────────────────────────\n\n\nAfter\n\n\nCode\nlibrary(\"dplyr\")\n\nGood &lt;- 1\napplePie &lt;- Good + 1\nPeter &lt;- d + 1"
  },
  {
    "objectID": "posts/display_table/index.html",
    "href": "posts/display_table/index.html",
    "title": "表格展示",
    "section": "",
    "text": "A guide to creating visually appealing tables in R and Python using the gt and great_tables packages, with examples of styling, image embedding, and nanoplots.\nThis document provides a comprehensive guide to creating visually appealing and informative tables in both R and Python. It focuses on the gt package in R and the great_tables package in Python, demonstrating how to style tables, embed images, handle missing data, and even incorporate nanoplots (bar charts) directly into table cells. The guide also includes a practical example of translating great_tables code from Python to R, making it a valuable resource for users of both languages.\nWith the gt package, anyone can make wonderful-looking tables using the R/Python programming language.\n\nGT package\n\n\n\nRPython\n\n\n\n\nCode\nlibrary(gt)\nlibrary(dplyr) # Using dplyr for mutate, optional but convenient\nlibrary(gtExtras) # For image embedding\n\n\n\n\nCode\nlibrary(reticulate)\npy_require(c(\"polars\",\"great-tables\",\"pandas\",\"pyarrow\"))\n\n\n\n\nCode\nexibble |&gt; gt() |&gt; opt_stylize(style=3,color = \"green\") |&gt; fmt_auto()\n\n\n\n\n\n\n\n\nnum\nchar\nfctr\ndate\ntime\ndatetime\ncurrency\nrow\ngroup\n\n\n\n\n0.111\napricot\none\n2015-01-15\n13:35\n2018-01-01 02:22\n    49.95 \nrow_1\ngrp_a\n\n\n2.222\nbanana\ntwo\n2015-02-15\n14:40\n2018-02-02 14:33\n    17.95 \nrow_2\ngrp_a\n\n\n33.33\ncoconut\nthree\n2015-03-15\n15:45\n2018-03-03 03:44\n     1.39 \nrow_3\ngrp_a\n\n\n444.4\ndurian\nfour\n2015-04-15\n16:50\n2018-04-04 15:55\n65,100    \nrow_4\ngrp_a\n\n\n5,550\nNA\nfive\n2015-05-15\n17:55\n2018-05-05 04:00\n 1,325.81 \nrow_5\ngrp_b\n\n\nNA\nfig\nsix\n2015-06-15\nNA\n2018-06-06 16:11\n    13.255\nrow_6\ngrp_b\n\n\n777,000\ngrapefruit\nseven\nNA\n19:10\n2018-07-07 05:22\nNA\nrow_7\ngrp_b\n\n\n8.880 × 106\nhoneydew\neight\n2015-08-15\n20:20\nNA\n     0.44 \nrow_8\ngrp_b\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport polars.selectors as cs\nfrom great_tables import GT, md,exibble\nfrom great_tables.data import reactions\n\n\n\n\nCode\n#exibble\n\n\n\n\nCode\nGT(exibble).opt_stylize(style=3,color = \"green\")\n\n\n\n\n\n\n\n\nnum\nchar\nfctr\ndate\ntime\ndatetime\ncurrency\nrow\ngroup\n\n\n\n\n0.1111\napricot\none\n2015-01-15\n13:35\n2018-01-01 02:22\n49.95\nrow_1\ngrp_a\n\n\n2.222\nbanana\ntwo\n2015-02-15\n14:40\n2018-02-02 14:33\n17.95\nrow_2\ngrp_a\n\n\n33.33\ncoconut\nthree\n2015-03-15\n15:45\n2018-03-03 03:44\n1.39\nrow_3\ngrp_a\n\n\n444.4\ndurian\nfour\n2015-04-15\n16:50\n2018-04-04 15:55\n65100.0\nrow_4\ngrp_a\n\n\n5550.0\n\nfive\n2015-05-15\n17:55\n2018-05-05 04:00\n1325.81\nrow_5\ngrp_b\n\n\n\nfig\nsix\n2015-06-15\n\n2018-06-06 16:11\n13.255\nrow_6\ngrp_b\n\n\n777000.0\ngrapefruit\nseven\n\n19:10\n2018-07-07 05:22\n\nrow_7\ngrp_b\n\n\n8880000.0\nhoneydew\neight\n2015-08-15\n20:20\n\n0.44\nrow_8\ngrp_b\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\nTable 1\nOriginal table:\n\n\nRPython\n\n\n\n\nCode\n# Load the necessary library\nlibrary(gt)\nlibrary(dplyr) # Using dplyr for mutate, optional but convenient\nlibrary(gtExtras) # For image embedding\n\n\n\n\nCode\n# 1. Create the data frame\n# Note: Storing percentages as numbers (0-100) for easier formatting\nhoosiers_data &lt;- data.frame(\n  TEAM = c(\"Wake Forest\", \"Indiana\", \"North Carolina\", \"Coppin St.\", \"Vermont\", \"New Mexico St.\"),\n  logo_url = c(\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/154.png\",      # Wake Forest\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/84.png\",       # Indiana\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/153.png\",      # North Carolina\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/2154.png\",     # Coppin St.\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/261.png\",     # Vermont\n    \"https://a.espncdn.com/i/teamlogos/ncaa/500/166.png\"       # New Mexico St.\n  ),\n  `3FG_Text` = c(\"17-61\", \"19-79\", \"20-60\", \"21-60\", \"22-89\", \"22-72\"), # Keep original text for display\n  `3FG%` = c(27.87, 24.05, 33.33, 35.00, 24.72, 30.56),\n  PER_GAME = c(2.83, 3.17, 3.33, 3.50, 3.67, 3.67),\n  SEED = c(4, NA, 6, 16, 16, 13),\n  ROUND = c(\"R64\", NA, \"R32\", \"R68\", \"R64\", \"R64\"),\n  YEAR = c(2009, 2024, 2014, 2008, 2010, 2014),\n  stringsAsFactors = FALSE # Good practice\n)\n\n\n\n\nCode\n# 2. Create the gt table\ngt_table &lt;- hoosiers_data %&gt;%\n  gt() %&gt;%\n  # --- Add Logos ---\n  gt_img_rows(columns = logo_url, height = 25) %&gt;% # Use URL column, set image height\n  # --- Move logo column ---\n  cols_move_to_start(columns = logo_url) %&gt;% # Place logo column first\n  # Add title and subtitle\n  tab_header(\n    title = \"History does not bode well for the Hoosiers\",\n    subtitle = \"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n  ) %&gt;%\n  # Create the spanner header over the shooting columns\n  tab_spanner(\n    label = \"Shooting\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME)\n  ) %&gt;%\n  # Format column labels\n  cols_label(\n    logo_url = \"\", # No header text for the logo column\n    TEAM = \"TEAM\",\n    `X3FG_Text` = \"3FG\", # Use the text column for display\n    `X3FG.` = \"3FG%\",\n    PER_GAME = \"PER GAME\",\n    SEED = \"SEED\",\n    ROUND = \"ROUND\",\n    YEAR = \"YEAR\"\n  ) %&gt;%\n  # Format the percentage column\n  fmt_percent(\n    columns = `X3FG.`,\n    decimals = 2,\n    scale_values = FALSE # Values are already 0-100\n  ) %&gt;%\n  # Format the 'PER GAME' column to two decimal places\n  fmt_number(\n    columns = PER_GAME,\n    decimals = 2\n  ) %&gt;%\n  # Replace NA values with \"???\"\n  sub_missing(\n    columns = c(SEED, ROUND),\n    missing_text = \"???\"\n  ) %&gt;%\n   # Align columns (optional, but often improves appearance)\n  cols_align(\n    align = \"center\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME, SEED, ROUND, YEAR)\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = TEAM\n  ) %&gt;%\n  # Highlight the Indiana row (using a light blue background as an example)\n  tab_style(\n    style = cell_fill(color = \"#ADD8E6\"), # AliceBlue, adjust as needed\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n  tab_style(\n    style = cell_borders(\n      sides = c(\"top\", 'bottom',\"left\", \"right\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(2)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`)\n  ) %&gt;%\n  # Add the source note\n  tab_source_note(\n    source_note = \"Viz. + Analysis by @andreweatherman\"\n  )%&gt;%\n  # Adjust width of the logo column if needed (optional)\n  cols_width(\n      logo_url ~ px(40) # Set logo column width to 40 pixels\n  )\ngt_table\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\n\nShooting\n\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n\n\nthe row Team Indiana background color is not correct,and also letter is not bold,So adjust it.\n\n\nCode\nlibrary(magick)\n\n# Read the image\nimg &lt;- image_read(\"images/my screenshots.png\")\n\n# Display the image to inspect it (optional, opens in a viewer)\n#image_browse(img)\n\n\n\n\nCode\n# Get image dimensions\nimg_info &lt;- image_info(img)\nprint(img_info)\n\n\n# A tibble: 1 × 7\n  format width height colorspace matte filesize density\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n1 PNG     1066    872 sRGB       TRUE    983185 57x57  \n\n\n\n\nCode\n# Crop a 50x50 pixel section from the Indiana row background\n# Adjust coordinates based on your image dimensions\nimg_cropped &lt;- image_crop(img, \"50x50+200+400\")\n\n# Display the cropped section to confirm (optional)\n#image_browse(img_cropped)\n\n\n\n\nCode\n# Convert the cropped image to a raster\nimg_raster &lt;- as.raster(img_cropped)\n\n# Convert the raster to a matrix of colors\nimg_matrix &lt;- as.matrix(img_raster)\n\n# Extract RGB values from the matrix\n# col2rgb expects a vector of colors, so we flatten the matrix\nrgb_values &lt;- col2rgb(img_matrix)\n\n# Calculate the average RGB values (to approximate the dominant background color)\navg_rgb &lt;- rowMeans(rgb_values, na.rm = TRUE)\n\n# Convert the average RGB to Hex\n# col2rgb returns values in the range 0-255, so we can use them directly\nhex_code &lt;- rgb(avg_rgb[1], avg_rgb[2], avg_rgb[3], maxColorValue = 255)\n\n# Print the Hex code\nprint(hex_code)\n\n\n[1] \"#70AACA\"\n\n\n\n\nCode\n# 2. Create the gt table\ngt_table &lt;- hoosiers_data %&gt;%\n  gt() %&gt;%\n  # --- Add Logos ---\n  gt_img_rows(columns = logo_url, height = 25) %&gt;% # Use URL column, set image height\n  # --- Move logo column ---\n  cols_move_to_start(columns = logo_url) %&gt;% # Place logo column first\n  # Add title and subtitle\n  tab_header(\n    title = \"History does not bode well for the Hoosiers\",\n    subtitle = \"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n  ) %&gt;%\n  # Create the spanner header over the shooting columns\n  tab_spanner(\n    label = \"Shooting\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME)\n  ) %&gt;%\n  # Format column labels\n  cols_label(\n    logo_url = \"\", # No header text for the logo column\n    TEAM = \"TEAM\",\n    `X3FG_Text` = \"3FG\", # Use the text column for display\n    `X3FG.` = \"3FG%\",\n    PER_GAME = \"PER GAME\",\n    SEED = \"SEED\",\n    ROUND = \"ROUND\",\n    YEAR = \"YEAR\"\n  ) %&gt;%\n  # Format the percentage column\n  fmt_percent(\n    columns = `X3FG.`,\n    decimals = 2,\n    scale_values = FALSE # Values are already 0-100\n  ) %&gt;%\n  # Format the 'PER GAME' column to two decimal places\n  fmt_number(\n    columns = PER_GAME,\n    decimals = 2\n  ) %&gt;%\n  # Replace NA values with \"???\"\n  sub_missing(\n    columns = c(SEED, ROUND),\n    missing_text = \"???\"\n  ) %&gt;%\n   # Align columns (optional, but often improves appearance)\n  cols_align(\n    align = \"center\",\n    columns = c(`X3FG_Text`, `X3FG.`, PER_GAME, SEED, ROUND, YEAR)\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = TEAM\n  ) %&gt;%\n  # Highlight the Indiana row (using a light blue background as an example)\n  tab_style(\n    \n    style = cell_fill(color = \"#70AACA\"), # AliceBlue, adjust as needed\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n   tab_style(\n     style = cell_text(weight = \"bold\"),\n    locations = cells_body(rows = TEAM == \"Indiana\")\n  ) %&gt;%\n  ### dotted line\n  tab_style(\n    style = cell_borders(\n      sides = c(\"top\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`,rows = TEAM == \"Wake Forest\") # Apply to Indiana row)\n  ) %&gt;%\n    ### dotted line\n    tab_style(\n    style = cell_borders(\n      sides = c(\"bottom\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`,rows = TEAM == \"New Mexico St.\")\n  ) %&gt;%\n  ### dotted line\n    tab_style(\n    style = cell_borders(\n      sides = c(\"left\",\"right\"), # Or \"top\", \"left\", \"right\", or \"all\"\n      color = \"black\", # Or a hex code\n      style = \"dotted\", # Or \"dashed\", \"dotted\", \"double\", \"hidden\"\n      weight = px(3)  # Default is 1px\n                         \n                         ), # AliceBlue, adjust as needed\n    locations = cells_body(columns = `X3FG.`)\n  ) %&gt;%\n  # Add the source note\n  tab_source_note(\n    source_note = \"Viz. + Analysis by @andreweatherman\"\n  )%&gt;%\n  # Adjust width of the logo column if needed (optional)\n  cols_width(\n      logo_url ~ px(40) # Set logo column width to 40 pixels\n  )\ngt_table\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\n\nShooting\n\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nfrom great_tables import GT, md, html, loc, style, px# Import necessary components\n\n\n\n\nCode\n# 1. Create the Pandas DataFrame\n# Using a dictionary preserves column names with special characters/spaces\nhoosiers_data = pd.DataFrame({\n    \"TEAM\": [\"Wake Forest\", \"Indiana\", \"North Carolina\", \"Coppin St.\", \"Vermont\", \"New Mexico St.\"],\n    \"logo_url\": [\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/154.png\",      # Wake Forest\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/84.png\",       # Indiana\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/153.png\",      # North Carolina\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/2154.png\",     # Coppin St.\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/261.png\",      # Vermont\n        \"https://a.espncdn.com/i/teamlogos/ncaa/500/166.png\"       # New Mexico St.\n    ],\n    \"3FG_Text\": [\"17-61\", \"19-79\", \"20-60\", \"21-60\", \"22-89\", \"22-72\"], # Keep original text\n    \"3FG%\": [27.87, 24.05, 33.33, 35.00, 24.72, 30.56],\n    \"PER_GAME\": [2.83, 3.17, 3.33, 3.50, 3.67, 3.67],\n    \"SEED\": [4, np.nan, 6, 16, 16, 13], # Use numpy.nan for missing values\n    \"ROUND\": [\"R64\", np.nan, \"R32\", \"R68\", \"R64\", \"R64\"],\n    \"YEAR\": [2009, 2024, 2014, 2008, 2010, 2014],\n})\n\nhoosiers_data_pl=pl.from_pandas(hoosiers_data)\n\n\n\n\nCode\n# 2. Create the great_tables table (Using lambda for older versions)\n# NOTE: This assumes fmt_image and loc.body exist in your version.\n# If you get errors on those, your version might be very old.\ngt_table = (\n    GT(data=hoosiers_data_pl)\n    .fmt_image(columns=\"logo_url\", height=25)\n    .cols_move_to_start(columns=[\"logo_url\"])\n    .tab_header(\n        title=\"History does not bode well for the Hoosiers\",\n        subtitle=\"Only one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\"\n    )\n    .tab_spanner(\n        label=\"Shooting\",\n        columns=[\"3FG_Text\", \"3FG%\", \"PER_GAME\"]\n    )\n    .cols_label(\n        logo_url = \"\",\n        TEAM = \"TEAM\",\n        **{\"3FG_Text\": \"3FG\"},\n        **{\"3FG%\": \"3FG%\"},\n        PER_GAME = \"PER GAME\",\n        SEED = \"SEED\",\n        ROUND = \"ROUND\",\n        YEAR = \"YEAR\"\n    )\n    .fmt_percent(\n        columns=\"3FG%\",\n        decimals=2,\n        scale_values=False\n    )\n    .fmt_number(\n        columns=\"PER_GAME\",\n        decimals=2\n    )\n    .sub_missing(\n        columns=[\"SEED\", \"ROUND\"],\n        missing_text=\"???\"\n    )\n    .cols_align(\n        align=\"center\",\n        columns=[\"3FG_Text\", \"3FG%\", \"PER_GAME\", \"SEED\", \"ROUND\", \"YEAR\"]\n    )\n    .cols_align(\n        align=\"left\",\n        columns=\"TEAM\"\n    )\n    # Highlight the Indiana row (Using lambda function)\n    .tab_style(\n        style=style.fill(color=\"#70AACA\"),\n        # pandas way   Use a lambda function to define the row condition\n      # locations=[loc.body(rows=lambda x: x[\"TEAM\"] == \"Indiana\")]\n        locations=[loc.body(rows=pl.col(\"TEAM\")  == \"Indiana\")]\n    )\n    # Make letter bold the Indiana row (Using lambda function)\n    .tab_style(\n        style=style.text(weight = \"bold\"),\n        # pandas way   Use a lambda function to define the row condition\n      # locations=[loc.body(rows=lambda x: x[\"TEAM\"] == \"Indiana\")]\n        locations=[loc.body(rows=pl.col(\"TEAM\")  == \"Indiana\")]\n    )\n\n    # Add the source note\n    .tab_source_note(\n        source_note=md(\"Viz. + Analysis by @andreweatherman\")\n    )\n     # Adjust width of the logo column\n     .cols_width(\n        logo_url = px(40)\n     )\n)\n\n\n\n\nCode\n# save:\n# gt_table.save(\"hoosiers_table.html\")\n\n# To display(In Jupyter):\ngt_table # In Jupyter\n\n\n\n\n\n\n\n\nHistory does not bode well for the Hoosiers\n\n\nOnly one future tournament team made fewer 3PTs through their first six games than Indiana in 2024.\n\n\n\nTEAM\nShooting\nSEED\nROUND\nYEAR\n\n\n3FG\n3FG%\nPER GAME\n\n\n\n\n\nWake Forest\n17-61\n27.87%\n2.83\n4.0\nR64\n2009\n\n\n\nIndiana\n19-79\n24.05%\n3.17\n???\n???\n2024\n\n\n\nNorth Carolina\n20-60\n33.33%\n3.33\n6.0\nR32\n2014\n\n\n\nCoppin St.\n21-60\n35.00%\n3.50\n16.0\nR68\n2008\n\n\n\nVermont\n22-89\n24.72%\n3.67\n16.0\nR64\n2010\n\n\n\nNew Mexico St.\n22-72\n30.56%\n3.67\n13.0\nR64\n2014\n\n\n\nViz. + Analysis by @andreweatherman\n\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\nTable 2\nOriginal table:\n\n\nRPython\n\n\n\n\nCode\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(dplyr)\nlibrary(jsonlite)\nlibrary(scales)\nlibrary(lubridate)\n\n\n\n\nCode\n# URL for the data\ndata_url &lt;- \"https://github.com/machow/coffee-sales-data/raw/main/data/coffee-sales.ndjson\"\ncoffee_data_raw =stream_in(url(data_url), simplifyDataFrame = TRUE)\n\n\n\n Found 14 records...\n Imported 14 records. Simplifying...\n\n\n\nPrompt gemini 2.5\nusing R GT package to recreate this table.data source from https://github.com/machow/coffee-sales-data/blob/main/data/coffee-sales.ndjson\nStep 1 load package and read in data from github library(gt) library(gtExtras) library(dplyr) library(jsonlite) library(scales) library(lubridate) data_url &lt;- “https://github.com/machow/coffee-sales-data/raw/main/data/coffee-sales.ndjson” coffee_data_raw =stream_in(url(data_url), simplifyDataFrame = TRUE)\nno need to no need to Aggregate data for the table.all number are given\nStep 2 create GT table,using cols_nanoplot() to add the bar plot for column Monthly Sales\nno need to create the icon at left side\nSince gt v0.3.0, columns = vars(...) has been deprecated. • Please use columns = c(...) instead.\n\n\nCode\n# Step 1: Load necessary packages\n# ----------------------------------------------------\n# Ensure gt and gtExtras are installed and loaded\n# install.packages(\"gt\")\n# install.packages(\"gtExtras\")\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(dplyr) # Still useful for data frame creation/manipulation\nlibrary(tibble) # Good for defining data frames\n\n# Step 2: Define the data frame manually based on the image\n# ----------------------------------------------------\n# Note:\n# - Amounts are entered as numbers (e.g., 904000 for $904K, 2.05e6 for $2.05M)\n#   so fmt_currency(scale_suffixing = TRUE) works correctly.\n# - Percentages are entered as proportions (e.g., 0.03 for 3%) for fmt_percent.\n# - Monthly Sales data needs to be a list of numeric vectors. Since we don't\n#   have the exact monthly data, we create approximate data representative\n#   of the bar patterns shown in the image. The length (14) is arbitrary.\n\n# coffee_table_data &lt;- tibble(\n#   Product = c(\"Grinder\", \"Moka pot\", \"Cold brew\", \"Filter\", \"Drip machine\",\n#               \"AeroPress\", \"Pour over\", \"French press\", \"Cezve\", \"Chemex\",\n#               \"Scale\", \"Kettle\", \"Espresso Machine\"),\n#   Revenue_Amount = c(904000, 2050000, 289000, 404000, 2630000,\n#                      2600000, 846000, 1110000, 2510000, 3140000,\n#                      3800000, 756000, 8410000),\n#   Revenue_Percent = c(0.03, 0.07, 0.01, 0.01, 0.09,\n#                       0.09, 0.03, 0.04, 0.09, 0.11,\n#                       0.13, 0.03, 0.29),\n#   Profit_Amount = c(568000, 181000, 242000, 70000, 1370000,\n#                     1290000, 365000, 748000, 1970000, 818000,\n#                     2910000, 618000, 3640000),\n#   Profit_Percent = c(0.04, 0.01, 0.02, 0.00, 0.09,\n#                      0.09, 0.02, 0.05, 0.13, 0.06,\n#                      0.20, 0.04, 0.25),\n#   # --- Estimated Monthly Sales Data (List Column) ---\n#   # Create lists of numbers that approximate the bar patterns\n#   Monthly_Sales = list(\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Grinder (Consistent high)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # Moka pot (Consistent medium-high)\n#     c(2,3,4,5,6,7,8,7,6,5,4,3,2,1),         # Cold brew (Peak in middle)\n#     c(6,7,6,7,6,7,6,7,6,7,6,7,6,7),         # Filter (Consistent medium)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Drip machine (Consistent high)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # AeroPress (Consistent high)\n#     c(5,6,7,6,5,6,7,6,5,6,7,6,5,6),         # Pour over (Slight variation medium)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # French press (Consistent medium-high)\n#     c(6,7,8,7,6,7,8,7,6,7,8,7,6,7),         # Cezve (Slight variation medium-high)\n#     c(7,8,9,8,7,8,9,8,7,8,9,8,7,8),         # Chemex (Slight variation high)\n#     c(8,9,8,9,8,9,8,9,8,9,8,9,8,9),         # Scale (Consistent high)\n#     c(7,8,7,8,7,8,7,8,7,8,7,8,7,8),         # Kettle (Consistent medium-high)\n#     c(1,2,3,4,5,6,7,7,6,6,5,5,4,4)          # Espresso Machine (Ramp up, plateau/dip)\n#   )\n# )\n\ncoffee_table_data=coffee_data_raw |&gt; rename(\n  Product=product,\n  Revenue_Amount=revenue_dollars,\n  Revenue_Percent=revenue_pct,\n  Profit_Amount=profit_dollars,\n  Profit_Percent=profit_pct,\n  Monthly_Sales=monthly_sales\n)\n\n# Step 3: Create the GT table\n# --------------------------------------------------\n\ncoffee_gt_table_manual &lt;- coffee_table_data %&gt;%\n  # Initialize gt table, using 'Product' column as row labels (stub)\n  gt(rowname_col = \"icon\") %&gt;%\n\n  # --- Add Column Spanners ---\n  tab_spanner(\n    label = \"Revenue\",\n    columns = c(Revenue_Amount, Revenue_Percent)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Profit\",\n    columns = c(Profit_Amount, Profit_Percent)\n  ) %&gt;%\n\n  # --- Format Columns ---\n  # Format Amounts using short scale (K, M)\n  fmt_currency(\n      columns = c(Revenue_Amount, Profit_Amount),\n      currency = \"USD\", # Assuming USD\n      decimals = 1,     # One decimal place shown in image for totals, apply consistently\n      suffixing = TRUE # Key for K, M suffixes\n  ) %&gt;%\n  # Format percentage columns\n  fmt_percent(\n      columns = c(Revenue_Percent, Profit_Percent),\n      decimals = 0 # Zero decimal places\n  ) %&gt;%\n\n  # --- Add Nanoplot (Bar Chart) ---\n  cols_nanoplot(\n     columns = Monthly_Sales,\n     plot_type = \"bar\",\n     options = nanoplot_options(\n         data_bar_fill_color = \"steelblue\",\n         data_bar_stroke_color = \"steelblue\"\n     )\n  ) %&gt;%\n\n  # --- Add Grand Summary Row ---\n  # Calculate sums directly from the numeric columns we created\n  # Verify these match the totals in the image ($29.4M, 100%, $14.8M, 100%)\n  # grand_summary_rows(\n  #   columns = c(Revenue_Amount, Profit_Amount),\n  #   fns = list(\n  #     Total = ~sum(., na.rm = TRUE)\n  #   ),\n  #   formatter = fmt_currency,\n  #    #currency = \"USD\",\n  #    decimals = 1,\n  #    suffixing = TRUE\n  # ) %&gt;%\n  #  grand_summary_rows(\n  #   columns = c(Revenue_Percent, Profit_Percent),\n  #   fns = list(\n  #       Total = ~sum(., na.rm = TRUE)\n  #   ),\n  #   formatter = fmt_percent,\n  #   decimals = 0\n  #  ) %&gt;%\n\n  # --- Add Title and Labels ---\n  tab_header(\n    title = \"Sales of Coffee Equipment\"\n  ) %&gt;%\n  cols_label(\n    Revenue_Amount = \"Amount\",\n    Revenue_Percent = \"Percent\",\n    Profit_Amount = \"Amount\",\n    Profit_Percent = \"Percent\",\n    Monthly_Sales = \"Monthly Sales\"\n  ) %&gt;%\n\n  # --- Styling ---\n   cols_width(\n      c(Product) ~ px(150),\n      contains(\"Amount\") ~ px(100),\n      contains(\"Percent\") ~ px(80),\n      Monthly_Sales ~ px(150)\n   ) %&gt;%\n   tab_style(\n      style = cell_text(align = \"center\", weight = \"bold\"),\n      locations = list(\n          cells_column_spanners(),\n          cells_column_labels()\n          )\n   ) %&gt;%\n   cols_align(\n      align = \"right\",\n      columns = c(Revenue_Amount, Profit_Amount, Revenue_Percent, Profit_Percent)\n   ) %&gt;%\n    cols_align( # Center align product names (stub) and monthly sales plot\n      align = \"center\",\n      columns = c(Product, Monthly_Sales)\n   ) %&gt;%\n   cols_align( # Left align product names (stub)\n      align = \"left\",\n      columns = Product\n   ) %&gt;%\n   tab_options(\n       column_labels.padding = px(5),\n       data_row.padding = px(5),\n       summary_row.padding = px(5), # Controls grand summary padding too\n       grand_summary_row.padding = px(5)\n   )\n\n\n\n\nCode\n# --- Display the table ---\ncoffee_gt_table_manual |&gt; tab_style(\n        style= list(cell_fill(color =\"aliceblue\")),\n        locations=cells_body(columns = c(Revenue_Amount, Revenue_Percent))\n        )|&gt; tab_style(\n        style= list(cell_fill(color =\"papayawhip\")),\n        locations=cells_body(columns = c(Profit_Amount, Profit_Percent))\n    )|&gt; tab_style(\n        style= list(cell_text(weight=\"bold\")),\n        locations=cells_body(rows = Revenue_Amount == max(Revenue_Amount))\n    ) |&gt; fmt_image(\"icon\", path=\"assets\") |&gt; sub_missing(missing_text=\"\")\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\n\nRevenue\n\n\nProfit\n\nnanoplots\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904.5K\n3%\n$568.0K\n4%\n\n\n     \n\n               765 0   521   494   596   613   667   748   765   686   607   594   568   751\n\n\n\n\n\nMoka pot\n$2.0M\n7%\n$181.1K\n1%\n\n\n     \n\n               6.87K 0   4.73K   4.74K   4.79K   5.51K   6.16K   6.62K   6.87K   6.03K   5.30K   4.88K   4.65K   6.28K\n\n\n\n\n\nCold brew\n$288.8K\n1%\n$241.8K\n2%\n\n\n     \n\n               2.70K 0   244   249   438   981   1.77K   2.70K   2.61K   2.35K   1.74K   896   499   244\n\n\n\n\n\nFilter\n$404.2K\n1%\n$70.0K\n0%\n\n\n     \n\n               2.74K 0   2.07K   1.81K   1.84K   2.12K   2.25K   2.63K   2.56K   2.37K   2.16K   2.19K   2.07K   2.74K\n\n\n\n\n\nDrip machine\n$2.6M\n9%\n$1.4M\n9%\n\n\n     \n\n               2.58K 0   2.14K   1.62K   1.97K   2.10K   2.58K   2.46K   2.34K   2.32K   2.05K   1.97K   1.84K   2.33K\n\n\n\n\n\nAeroPress\n$2.6M\n9%\n$1.3M\n9%\n\n\n     \n\n               9.27K 0   6.33K   5.20K   6.37K   7.02K   7.91K   8.70K   8.69K   7.80K   6.83K   6.96K   6.88K   9.27K\n\n\n\n\n\nPour over\n$846.0K\n3%\n$364.5K\n2%\n\n\n     \n\n               2.18K 0   1.56K   1.29K   1.51K   1.69K   1.94K   2.18K   2.14K   1.86K   1.72K   1.81K   1.60K   2.16K\n\n\n\n\n\nFrench press\n$1.1M\n4%\n$748.1K\n5%\n\n\n     \n\n               4.82K 0   3.51K   2.88K   3.35K   3.79K   3.90K   4.10K   4.18K   4.43K   3.28K   3.42K   3.30K   4.82K\n\n\n\n\n\nCezve\n$2.5M\n9%\n$2.0M\n13%\n\n\n     \n\n               17.1K 0   12.2K   11.5K   11.8K   13.6K   15.4K   16.5K   17.1K   14.4K   13.0K   12.9K   11.6K   15.9K\n\n\n\n\n\nChemex\n$3.1M\n11%\n$817.7K\n6%\n\n\n     \n\n               7.22K 0   4.94K   4.17K   5.24K   6.00K   6.36K   6.77K   7.11K   6.25K   5.60K   6.08K   4.98K   7.22K\n\n\n\n\n\nScale\n$3.8M\n13%\n$2.9M\n20%\n\n\n     \n\n               3.18K 0   1.54K   1.57K   1.68K   2.03K   2.43K   2.55K   2.57K   2.23K   2.04K   2.09K   1.69K   3.18K\n\n\n\n\n\nKettle\n$756.2K\n3%\n$617.5K\n4%\n\n\n     \n\n               1.53K 0   1.14K   1.02K   1.09K   1.13K   1.41K   1.48K   1.46K   1.30K   1.14K   1.23K   1.19K   1.53K\n\n\n\n\n\nEspresso Machine\n$8.4M\n29%\n$3.6M\n25%\n\n\n     \n\n               2.58K 0   686   840   618   598   2.15K   533   797   996   1.00K   668   858   2.58K\n\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport polars.selectors as cs\nfrom great_tables import GT, loc, style\n\ncoffee_sales = pl.read_ndjson(\"coffee-sales.ndjson\")\nsel_rev = cs.starts_with(\"revenue\")\nsel_prof = cs.starts_with(\"profit\")\n\n\ncoffee_table = (\n    GT(coffee_sales)\n    .tab_header(\"Sales of Coffee Equipment\")\n    .tab_spanner(label=\"Revenue\", columns=sel_rev)\n    .tab_spanner(label=\"Profit\", columns=sel_prof)\n    .cols_label(\n        revenue_dollars=\"Amount\",\n        profit_dollars=\"Amount\",\n        revenue_pct=\"Percent\",\n        profit_pct=\"Percent\",\n        monthly_sales=\"Monthly Sales\",\n        icon=\"\",\n        product=\"Product\",\n    )\n    # formatting ----\n    .fmt_number(\n        columns=cs.ends_with(\"dollars\"),\n        compact=True,\n        pattern=\"${x}\",\n        n_sigfig=3,\n    )\n    .fmt_percent(columns=cs.ends_with(\"pct\"), decimals=0)\n    # style ----\n    .tab_style(\n        style=style.fill(color=\"aliceblue\"),\n        locations=loc.body(columns=sel_rev),\n    )\n    .tab_style(\n        style=style.fill(color=\"papayawhip\"),\n        locations=loc.body(columns=sel_prof),\n    )\n    .tab_style(\n        style=style.text(weight=\"bold\"),\n        locations=loc.body(rows=pl.col(\"product\") == \"Total\"),\n    )\n    .fmt_nanoplot(\"monthly_sales\", plot_type=\"bar\")\n    .fmt_image(\"icon\", path=\"assets\")\n    .sub_missing(missing_text=\"\")\n)\n\ncoffee_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\nRevenue\nProfit\nMonthly Sales\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904K\n3%\n$568K\n4%\n\n\n\n\n7650521494596613667748765686607594568751\n\n\n\n\n\nMoka pot\n$2.05M\n7%\n$181K\n1%\n\n\n\n\n6.87K04.73K4.74K4.79K5.51K6.16K6.62K6.87K6.03K5.30K4.88K4.65K6.28K\n\n\n\n\n\nCold brew\n$289K\n1%\n$242K\n2%\n\n\n\n\n2.70K02442494389811.77K2.70K2.61K2.35K1.74K896499244\n\n\n\n\n\nFilter\n$404K\n1%\n$70.0K\n0%\n\n\n\n\n2.74K02.07K1.81K1.84K2.12K2.25K2.63K2.56K2.37K2.16K2.19K2.07K2.74K\n\n\n\n\n\nDrip machine\n$2.63M\n9%\n$1.37M\n9%\n\n\n\n\n2.58K02.14K1.62K1.97K2.10K2.58K2.46K2.34K2.32K2.05K1.97K1.84K2.33K\n\n\n\n\n\nAeroPress\n$2.60M\n9%\n$1.29M\n9%\n\n\n\n\n9.27K06.33K5.20K6.37K7.02K7.91K8.70K8.69K7.80K6.83K6.96K6.88K9.27K\n\n\n\n\n\nPour over\n$846K\n3%\n$365K\n2%\n\n\n\n\n2.18K01.56K1.29K1.51K1.69K1.94K2.18K2.14K1.86K1.72K1.81K1.60K2.16K\n\n\n\n\n\nFrench press\n$1.11M\n4%\n$748K\n5%\n\n\n\n\n4.82K03.51K2.88K3.35K3.79K3.90K4.10K4.18K4.43K3.28K3.42K3.30K4.82K\n\n\n\n\n\nCezve\n$2.51M\n9%\n$1.97M\n13%\n\n\n\n\n17.1K012.2K11.5K11.8K13.6K15.4K16.5K17.1K14.4K13.0K12.9K11.6K15.9K\n\n\n\n\n\nChemex\n$3.14M\n11%\n$818K\n6%\n\n\n\n\n7.22K04.94K4.17K5.24K6.00K6.36K6.77K7.11K6.25K5.60K6.08K4.98K7.22K\n\n\n\n\n\nScale\n$3.80M\n13%\n$2.91M\n20%\n\n\n\n\n3.18K01.54K1.57K1.68K2.03K2.42K2.55K2.57K2.23K2.04K2.09K1.69K3.18K\n\n\n\n\n\nKettle\n$756K\n3%\n$618K\n4%\n\n\n\n\n1.53K01.14K1.02K1.09K1.13K1.41K1.48K1.46K1.30K1.14K1.23K1.19K1.53K\n\n\n\n\n\nEspresso Machine\n$8.41M\n29%\n$3.64M\n25%\n\n\n\n\n2.58K06868406185982.15K5337979961.00K6688582.58K\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n        \n\n\nCode\n#coffee_table.save(\"data/coffee-table.png\",  scale=2)\n\n\n\npython to R with gemini 2.5\ntranslate following python code to R code,using cols_nanoplot in R to replace fmt_nanoplot()\nError in fmt_currency(., columns = ends_with(“dollars”), currency = “USD”, : unused arguments (use_sigfig = TRUE, sigfig = 3)\n\n\nCode\n# --- Load necessary libraries ---\nlibrary(gt)\nlibrary(dplyr)\nlibrary(jsonlite)\nlibrary(gtExtras)\n\n# --- Data Loading ---\n# (Assuming coffee_sales is loaded as before)\ncon &lt;- file(\"coffee-sales.ndjson\", \"r\")\ncoffee_sales &lt;- stream_in(con, simplifyDataFrame = TRUE) %&gt;%\n  as_tibble()\n\n\n\n Found 14 records...\n Imported 14 records. Simplifying...\n\n\nCode\nclose(con)\n\n# --- Table Creation and Styling with gt ---\ncoffee_table &lt;-\n  gt(coffee_sales) %&gt;%\n\n  # --- Headers and Spanners ---\n  tab_header(title = \"Sales of Coffee Equipment\") %&gt;%\n  tab_spanner(label = \"Revenue\", columns = starts_with(\"revenue\")) %&gt;%\n  tab_spanner(label = \"Profit\", columns = starts_with(\"profit\")) %&gt;%\n\n  # --- Column Labels ---\n  cols_label(\n    revenue_dollars = \"Amount\",\n    profit_dollars = \"Amount\",\n    revenue_pct = \"Percent\",\n    profit_pct = \"Percent\",\n    monthly_sales = \"Monthly Sales\",\n    icon = \"\",\n    product = \"Product\"\n  ) %&gt;%\n\n  # --- Formatting ---\n  # *** CORRECTED SECTION ***\n  # Format numeric columns using significant figures and add '$' prefix with pattern\n  fmt_number(\n      columns = ends_with(\"dollars\"),\n      pattern = \"${x}\",  # Use pattern to add the dollar sign\n      n_sigfig = 3 ,      # Specify 3 significant figures\n      # If you also wanted the compact K/M notation like in Python's compact=True:\n      suffixing = TRUE\n  ) %&gt;%\n  # Format percentage columns\n  fmt_percent(columns = ends_with(\"pct\"), decimals = 0) %&gt;%\n\n  # --- Styling ---\n  tab_style(\n    style = cell_fill(color = \"aliceblue\"),\n    locations = cells_body(columns = starts_with(\"revenue\"))\n  ) %&gt;%\n  tab_style(\n    style = cell_fill(color = \"papayawhip\"),\n    locations = cells_body(columns = starts_with(\"profit\"))\n  ) %&gt;%\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body(columns = everything(), rows = product == \"Total\")\n  ) %&gt;%\n\n  # --- Special Formatting ---\n  #gt_plt_bar(column = monthly_sales, color=\"grey\", background = \"lightgrey\") %&gt;%\n  # text_transform(\n  #   locations = cells_body(columns = icon),\n  #   fn = function(x) {\n  #       image_path &lt;- file.path(\"assets\", x)\n  #        if (!file.exists(image_path)) {\n  #           warning(\"Image file not found: \", image_path)\n  #           return(\"\")\n  #         }\n  #       local_image(filename = image_path, height = px(25))\n  #   }\n  # ) %&gt;%\n  sub_missing(missing_text = \"\")\n\n\n\n# --- Save the table (optional) ---\n# gtsave(coffee_table, filename = \"data/coffee-table.png\", zoom = 2)\n\n\n\n\nCode\n# --- Display the table ---\ncoffee_table|&gt; fmt_image(\"icon\", path=\"assets\") |&gt;  \n  # --- Add Nanoplot (Bar Chart) ---\n  cols_nanoplot(\n     columns = monthly_sales,\n     plot_type = \"bar\",\n     options = nanoplot_options(\n         data_bar_fill_color = \"steelblue\",\n         data_bar_stroke_color = \"steelblue\"\n     )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales of Coffee Equipment\n\n\n\nProduct\n\nRevenue\n\n\nProfit\n\nnanoplots\n\n\nAmount\nPercent\nAmount\nPercent\n\n\n\n\n\nGrinder\n$904K\n3%\n$568K\n4%\n\n\n     \n\n               765 0   521   494   596   613   667   748   765   686   607   594   568   751\n\n\n\n\n\nMoka pot\n$2.05M\n7%\n$181K\n1%\n\n\n     \n\n               6.87K 0   4.73K   4.74K   4.79K   5.51K   6.16K   6.62K   6.87K   6.03K   5.30K   4.88K   4.65K   6.28K\n\n\n\n\n\nCold brew\n$289K\n1%\n$242K\n2%\n\n\n     \n\n               2.70K 0   244   249   438   981   1.77K   2.70K   2.61K   2.35K   1.74K   896   499   244\n\n\n\n\n\nFilter\n$404K\n1%\n$70.0K\n0%\n\n\n     \n\n               2.74K 0   2.07K   1.81K   1.84K   2.12K   2.25K   2.63K   2.56K   2.37K   2.16K   2.19K   2.07K   2.74K\n\n\n\n\n\nDrip machine\n$2.63M\n9%\n$1.37M\n9%\n\n\n     \n\n               2.58K 0   2.14K   1.62K   1.97K   2.10K   2.58K   2.46K   2.34K   2.32K   2.05K   1.97K   1.84K   2.33K\n\n\n\n\n\nAeroPress\n$2.60M\n9%\n$1.29M\n9%\n\n\n     \n\n               9.27K 0   6.33K   5.20K   6.37K   7.02K   7.91K   8.70K   8.69K   7.80K   6.83K   6.96K   6.88K   9.27K\n\n\n\n\n\nPour over\n$846K\n3%\n$365K\n2%\n\n\n     \n\n               2.18K 0   1.56K   1.29K   1.51K   1.69K   1.94K   2.18K   2.14K   1.86K   1.72K   1.81K   1.60K   2.16K\n\n\n\n\n\nFrench press\n$1.11M\n4%\n$748K\n5%\n\n\n     \n\n               4.82K 0   3.51K   2.88K   3.35K   3.79K   3.90K   4.10K   4.18K   4.43K   3.28K   3.42K   3.30K   4.82K\n\n\n\n\n\nCezve\n$2.51M\n9%\n$1.97M\n13%\n\n\n     \n\n               17.1K 0   12.2K   11.5K   11.8K   13.6K   15.4K   16.5K   17.1K   14.4K   13.0K   12.9K   11.6K   15.9K\n\n\n\n\n\nChemex\n$3.14M\n11%\n$818K\n6%\n\n\n     \n\n               7.22K 0   4.94K   4.17K   5.24K   6.00K   6.36K   6.77K   7.11K   6.25K   5.60K   6.08K   4.98K   7.22K\n\n\n\n\n\nScale\n$3.80M\n13%\n$2.91M\n20%\n\n\n     \n\n               3.18K 0   1.54K   1.57K   1.68K   2.03K   2.43K   2.55K   2.57K   2.23K   2.04K   2.09K   1.69K   3.18K\n\n\n\n\n\nKettle\n$756K\n3%\n$618K\n4%\n\n\n     \n\n               1.53K 0   1.14K   1.02K   1.09K   1.13K   1.41K   1.48K   1.46K   1.30K   1.14K   1.23K   1.19K   1.53K\n\n\n\n\n\nEspresso Machine\n$8.41M\n29%\n$3.64M\n25%\n\n\n     \n\n               2.58K 0   686   840   618   598   2.15K   533   797   996   1.00K   668   858   2.58K\n\n\n\n\n\n\nTotal\n$29.4M\n100%\n$14.8M\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3\nOriginal table:\n\n\nRPython\n\n\n\nPrompt\nwrite R code using GT package to recreate this table\n1.opt_align change to cols_align 2.cols_labels change to cols_label\n\n\ninput data\n\n\nCode\nlibrary(gt)\nlibrary(dplyr)\n\n# Create the data frame (replace with your actual data loading if needed)\ndata &lt;-read.csv(\"power-generation.csv\")\n\n\n\n\nmake GT table\n\n\nCode\n# Create the gt table\ngt_table &lt;- data %&gt;%\n  gt() %&gt;%\n  # Title and subtitle\n  tab_header(\n    title = md(\"2023 Mean **Carbon Intensity** (gCO2eq/kWh) and **Power Consumption** Breakdown (%)\")\n  ) %&gt;%\n  # Column labels\n  cols_label(\n    CO2.Intensity = \"CO2 Intensity\",\n    Hydro.Discharge = \"Hydro Discharge\",\n    Battery.Discharge = \"Battery Discharge\"\n  ) %&gt;%\n  # Format the numeric columns to have one decimal place\n  fmt_number(\n    columns = -Zone, # Apply to all columns except Zone\n    decimals = 1\n  ) %&gt;%\n  # Add a spanning header for the power consumption breakdown\n  # tab_spanner(\n  #   label = \"Power Consumption Breakdown (%)\",\n  #   columns = c(Hydro, Nuclear, Wind, Solar, Geothermal, Biomass, Gas, Coal, Oil, Unknown, Hydro.Discharge, Battery.Discharge)\n  # ) %&gt;%\n  # Add source note\n  tab_source_note(md(\"Source: [Your Data Source Information Here]\")) %&gt;%\n  # Add a footnote about the methodology\n  tab_footnote(\n    md(\"Some emissions factors are based on IPCC 2014 defaults, while some are based on more accurate regional factors.\")\n  ) %&gt;%\n  # Style the table (optional, customize as needed)\n   cols_align(align = \"center\") %&gt;%\n  opt_row_striping()\n\n# Display the table\ngt_table\n\n\n\n\n\n  \n    \n      2023 Mean Carbon Intensity (gCO2eq/kWh) and Power Consumption Breakdown (%)\n    \n    \n    \n      Zone\n      CO2 Intensity\n      Hydro\n      Nuclear\n      Wind\n      Solar\n      Geothermal\n      Biomass\n      Gas\n      Coal\n      Oil\n      Unknown\n      Hydro Discharge\n      Battery Discharge\n    \n  \n  \n    Sweden\n23.5\n0.4\n0.3\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    Iceland\n27.6\n0.7\n0.0\n0.0\n0.0\n0.3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    Quebec\n30.6\n0.9\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n    France\n52.7\n0.1\n0.6\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Ontario\n72.6\n0.3\n0.5\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Finland\n87.2\n0.2\n0.4\n0.2\n0.0\n0.0\n0.1\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    Tasmania\n92.2\n0.7\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    New Zealand\n94.5\n0.6\n0.0\n0.1\n0.0\n0.2\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n    Belgium\n139.6\n0.0\n0.4\n0.2\n0.1\n0.0\n0.0\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n    West Denmark\n143.1\n0.2\n0.0\n0.5\n0.1\n0.0\n0.1\n0.1\n0.1\n0.0\n0.0\n0.0\n0.0\n    East Denmark\n147.6\n0.1\n0.1\n0.4\n0.1\n0.0\n0.1\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n    Spain\n154.0\n0.1\n0.2\n0.2\n0.2\n0.0\n0.0\n0.2\n0.0\n0.0\n0.0\n0.0\n0.0\n    South Australia\n185.8\n0.0\n0.0\n0.4\n0.2\n0.0\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.0\n    Great Britain\n199.8\n0.0\n0.2\n0.3\n0.1\n0.0\n0.1\n0.3\n0.0\n0.0\n0.0\n0.0\n0.0\n    California\n257.7\n0.1\n0.1\n0.1\n0.2\n0.0\n0.0\n0.4\n0.0\n0.0\n0.0\n0.0\n0.0\n    Netherlands\n272.8\n0.0\n0.0\n0.3\n0.2\n0.0\n0.1\n0.3\n0.1\n0.0\n0.0\n0.0\n0.0\n    New York ISO\n280.0\n0.2\n0.2\n0.0\n0.0\n0.0\n0.0\n0.5\n0.0\n0.0\n0.0\n0.0\n0.0\n    Italy (North)\n307.3\n0.2\n0.1\n0.0\n0.1\n0.0\n0.0\n0.4\n0.0\n0.0\n0.1\n0.0\n0.0\n    Texas\n383.2\n0.0\n0.1\n0.3\n0.1\n0.0\n0.0\n0.4\n0.1\n0.0\n0.0\n0.0\n0.0\n    Germany\n396.8\n0.1\n0.0\n0.3\n0.1\n0.0\n0.1\n0.1\n0.2\n0.0\n0.0\n0.0\n0.0\n    Western Australia\n433.3\n0.0\n0.0\n0.2\n0.2\n0.0\n0.0\n0.4\n0.3\n0.0\n0.0\n0.0\n0.0\n    Alberta\n438.9\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.7\n0.1\n0.0\n0.0\n0.0\n0.0\n    Victoria\n506.4\n0.1\n0.0\n0.2\n0.1\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    New South Wales\n556.3\n0.0\n0.0\n0.1\n0.2\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    India (North)\n558.2\n0.2\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.6\n0.0\n0.0\n0.0\n0.0\n    Queensland\n607.0\n0.0\n0.0\n0.0\n0.2\n0.0\n0.0\n0.1\n0.7\n0.0\n0.0\n0.0\n0.0\n    South Africa\n701.0\n0.0\n0.0\n0.1\n0.0\n0.0\n0.0\n0.0\n0.8\n0.0\n0.0\n0.0\n0.0\n  \n  \n    \n      Source: [Your Data Source Information Here]\n    \n  \n  \n    \n       Some emissions factors are based on IPCC 2014 defaults, while some are based on more accurate regional factors.\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nReference:\nhttps://github.com/rich-iannone/great-tables-mini-workshop?tab=readme-ov-file"
  },
  {
    "objectID": "posts/docker/index.html",
    "href": "posts/docker/index.html",
    "title": "Docker使用介绍",
    "section": "",
    "text": "A comprehensive introduction to Docker, covering essential commands, Dockerfiles, and an example of building and managing an RStudio Docker image.\nThis document provides a comprehensive introduction to Docker, a platform for developing, shipping, and running applications in containers. It covers the essential Docker commands for managing images and containers, from pulling and running images to stopping and deleting containers. The guide also explains the role of Dockerfiles in building custom images and provides a practical example of creating an RStudio image with Tidyverse pre-installed. This document is designed to be a helpful resource for anyone getting started with Docker."
  },
  {
    "objectID": "posts/docker/index.html#create-docker-file",
    "href": "posts/docker/index.html#create-docker-file",
    "title": "Docker使用介绍",
    "section": "create Docker file",
    "text": "create Docker file\n\n\n\nCode\n\ntidyverse_4.3.3.Dockerfile\n\nFROM docker.io/library/ubuntu:jammy\n\nENV R_VERSION=\"4.3.3\"\nENV R_HOME=\"/usr/local/lib/R\"\nENV TZ=\"Etc/UTC\"\n\nCOPY scripts/install_R_source.sh /rocker_scripts/install_R_source.sh\nRUN /rocker_scripts/install_R_source.sh\n\nENV CRAN=\"https://p3m.dev/cran/__linux__/jammy/2024-04-23\"\nENV LANG=en_US.UTF-8\n\nCOPY scripts/bin/ /rocker_scripts/bin/\nCOPY scripts/setup_R.sh /rocker_scripts/setup_R.sh\nRUN /rocker_scripts/setup_R.sh\n\nCOPY scripts/install_tidyverse.sh /rocker_scripts/install_tidyverse.sh\nRUN /rocker_scripts/install_tidyverse.sh\n\nENV S6_VERSION=\"v2.1.0.2\"\nENV RSTUDIO_VERSION=\"2023.12.1+402\"\nENV DEFAULT_USER=\"rstudio\"\n\nCOPY scripts/install_rstudio.sh /rocker_scripts/install_rstudio.sh\nCOPY scripts/install_s6init.sh /rocker_scripts/install_s6init.sh\nCOPY scripts/default_user.sh /rocker_scripts/default_user.sh\nCOPY scripts/init_set_env.sh /rocker_scripts/init_set_env.sh\nCOPY scripts/init_userconf.sh /rocker_scripts/init_userconf.sh\nCOPY scripts/pam-helper.sh /rocker_scripts/pam-helper.sh\nRUN /rocker_scripts/install_rstudio.sh\n\nEXPOSE 8787\nCMD [\"/init\"]\n\nCOPY scripts/install_pandoc.sh /rocker_scripts/install_pandoc.sh\nRUN /rocker_scripts/install_pandoc.sh\n\nCOPY scripts/install_quarto.sh /rocker_scripts/install_quarto.sh\nRUN /rocker_scripts/install_quarto.sh\n\nCOPY scripts /rocker_scripts"
  },
  {
    "objectID": "posts/docker/index.html#bulid-docker-image-from-dockerfile",
    "href": "posts/docker/index.html#bulid-docker-image-from-dockerfile",
    "title": "Docker使用介绍",
    "section": "bulid Docker image from dockerfile",
    "text": "bulid Docker image from dockerfile\n\n\nCode\ndocker build -f tidyverse_4.3.3.Dockerfile -t proj:myapp ."
  },
  {
    "objectID": "posts/docker/index.html#run-docker-image",
    "href": "posts/docker/index.html#run-docker-image",
    "title": "Docker使用介绍",
    "section": "run Docker image",
    "text": "run Docker image\n\n\nCode\ndocker run -p 8787:8787 proj:myapp\n\n\nrun at backend\n\n\nCode\ndocker run -d proj:myapp\n\n\nRstuido server is open at: http://localhost:8787/\nuser name is rstudio\npassword is show on terminal"
  },
  {
    "objectID": "posts/docker/index.html#go-inside-docker-containers-with-containers-id",
    "href": "posts/docker/index.html#go-inside-docker-containers-with-containers-id",
    "title": "Docker使用介绍",
    "section": "go inside docker containers with containers id",
    "text": "go inside docker containers with containers id\n\n\nCode\ndocker exec -it b28a1b8eeeb6 sh\n\n\nexit docker linux\n\n\nCode\nexit"
  },
  {
    "objectID": "posts/docker/index.html#stop-container-with-container-id",
    "href": "posts/docker/index.html#stop-container-with-container-id",
    "title": "Docker使用介绍",
    "section": "stop container with container id",
    "text": "stop container with container id\n\n\nCode\ndocker stop b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#restart-container-with-container-id",
    "href": "posts/docker/index.html#restart-container-with-container-id",
    "title": "Docker使用介绍",
    "section": "restart container with container id",
    "text": "restart container with container id\n\n\nCode\ndocker start b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#delete-a-stop-container",
    "href": "posts/docker/index.html#delete-a-stop-container",
    "title": "Docker使用介绍",
    "section": "delete a stop container",
    "text": "delete a stop container\n\n\nCode\ndocker rm -f b28a1b8eeeb6"
  },
  {
    "objectID": "posts/docker/index.html#delete-image-with-image-id",
    "href": "posts/docker/index.html#delete-image-with-image-id",
    "title": "Docker使用介绍",
    "section": "delete image with image id",
    "text": "delete image with image id\n\n\nCode\ndocker rmi -f 7e1a4e2d11e2"
  },
  {
    "objectID": "posts/AI_podcast/index.html",
    "href": "posts/AI_podcast/index.html",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "",
    "text": "A guide on transcribing podcast audio and generating summaries using AI, covering downloading MP3s, using mlx_whisper for transcription, and leveraging the Gemini 2.0 Flash model for summarization.\nThis document provides a comprehensive guide to transcribing podcast audio and generating summaries using a combination of AI tools. It outlines a multi-step process that includes downloading MP3 files from various podcast platforms, using the mlx_whisper model for accurate audio-to-text transcription, and then leveraging the Gemini 2.0 Flash model for summarization and correction of the transcribed text. The guide includes R code snippets for each step, making it a practical resource for anyone looking to automate the process of podcast transcription and summarization.\nArticle abstract for podcast like firstory/poddtoppen/小宇宙FM using mlx_whisper for transcription and Gemini 2.0 Flash for summarization\nCode\n#pak::pkg_install('tuneR')\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(av)"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model",
    "href": "posts/AI_podcast/index.html#define-model",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"你是一个中文，英文，威士忌专家\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model\n\n\n\n\nCode\n#testing model connection\nchat_result=chat_gemini_model$chat(\"hello\")\nchat_result\n\n\n\n\nCode\nchat_gemini_model$get_turns(include_system_prompt = TRUE)"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model",
    "href": "posts/AI_podcast/index.html#run-model",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt0=read_srt('text.srt')\nsrt_txt2=srt_txt0$subtitle|&gt; as.character()\n\n\n\n\nCode\nlength(srt_txt2)\n\n\n\n\nCode\nprompt_text=paste0('请给以下文字作500字内摘要：',srt_txt2)\nsummary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\nsummary_text |&gt; tibble() |&gt; write_delim('summary.txt')"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model-1",
    "href": "posts/AI_podcast/index.html#define-model-1",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"你是一个中文和英文的威士忌专家\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model-1",
    "href": "posts/AI_podcast/index.html#run-model-1",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nprompt_text=paste0('请更正以下文字的错别字，并且改正胡云为壶云，希游记为嬉游忌,Wish Jokey为WhisJockey,不要空白行',summary_text)\ncorrect_summary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\ncorrect_summary_text |&gt; str_replace_all('\\n\\n','\\n')|&gt; tibble() |&gt; write_delim('correct_summary2.txt')"
  },
  {
    "objectID": "posts/AI_podcast/index.html#define-model-2",
    "href": "posts/AI_podcast/index.html#define-model-2",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "define model",
    "text": "define model\n\n\nCode\nchat_gemini_model&lt;- chat_gemini(\n  system_prompt = \"你是一个中文和英文的威士忌专家\",\n  turns = NULL,\n  # base_url = \"https://generativelanguage.googleapis.com/v1beta\",\n  api_key = keyring::key_get(\"google_ai_api_key\"),\n  model = \"gemini-2.0-flash\",\n  #model = \"gemini-2.5-pro-exp-03-25\",\n  #api_args = list(),\n  #echo = NULL\n)\nchat_gemini_model"
  },
  {
    "objectID": "posts/AI_podcast/index.html#run-model-2",
    "href": "posts/AI_podcast/index.html#run-model-2",
    "title": "使用AI给播客语音转文字并作摘要",
    "section": "Run model",
    "text": "Run model\n\n\nCode\nsrt_txt_format=read.delim('text.srt')\n\n\n\n\nCode\nprompt_text=paste0('下面的内容是srt文档。请按每5分钟做一个摘要，再更正以下文字，胡云为壶云，希游记为嬉游忌,Wish Jokey为WhisJockey',srt_txt_format)\ncorrect_summary_text=chat_gemini_model$chat(prompt_text)\n\n\n\n\nCode\ncorrect_summary_text|&gt; tibble() |&gt; write_delim('correct_srt_summary.txt')"
  },
  {
    "objectID": "posts/GDP/index.html",
    "href": "posts/GDP/index.html",
    "title": "世界GDP",
    "section": "",
    "text": "This document demonstrates how to download and analyze global GDP data using R, utilizing the wbstats and WDI packages to retrieve and visualize various indicators from the World Bank.\nThis document provides a guide to downloading and analyzing global GDP data using R. It demonstrates how to use the wbstats and WDI packages to retrieve a variety of economic indicators from the World Bank, including GDP, GDP per capita, and the sectoral contributions of agriculture, industry, and services to GDP. The document includes R code for data acquisition, cleaning, and creating visualizations to compare the economic performance of different countries over time. The Python section is a placeholder for future content."
  },
  {
    "objectID": "posts/GDP/index.html#wbstats-package",
    "href": "posts/GDP/index.html#wbstats-package",
    "title": "世界GDP",
    "section": "wbstats package",
    "text": "wbstats package\n\n\nCode\n#install.packages(\"wbstats\")\nlibrary(wbstats)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\ndata from World Bank:https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n\n\nCode\nindustry_search_results &lt;- wbsearch(pattern = \"% of GDP\")\nprint(industry_search_results)\n\n\n\n\nCode\n# Define the indicators you want to download\n# \"NY.GDP.MKTP.CD\" for GDP (current US$)\n# \"NY.GDP.PCAP.CD\" for GDP per capita (current US$)\n\n#NV.AGR.TOTL.ZS Agriculture, forestry, and fishing, value added (% of GDP)\n#NV.IND.TOTL.ZS Industry (including construction), value added (% of GDP)\n#NV.SRV.TOTL.ZS Services, value added (% of GDP)\ngdp_indicators &lt;- c(\"NY.GDP.MKTP.CD\", \"NY.GDP.PCAP.CD\",\n                    \"NV.AGR.TOTL.ZS\",\"NV.IND.TOTL.ZS\",\"NV.SRV.TOTL.ZS\" )\n\n\n# Download the data\nworld_gdp_data &lt;- wb_data(\n  indicator = gdp_indicators,\n  start_date = 2000, # You can change the start and end years as needed\n  end_date = 2023\n)\n\n# Print the first few rows of the data to see the structure\nhead(world_gdp_data)\n\n# You can also use summary() to get a quick overview of the data\nsummary(world_gdp_data)\n\n# To get the data with country names, you can merge with wb_countries()\n#world_gdp_data_with_names &lt;- merge(world_gdp_data, wb_countries(), by = \"country_code\", all.x = TRUE)\n\n# Print the first few rows of the merged data\n#head(world_gdp_data_with_names)\n\n# Clean up the column names\nworld_gdp_data_with_names &lt;- world_gdp_data %&gt;%\n  rename(\n    GDP = NY.GDP.MKTP.CD,\n    GDP_per_capita = NY.GDP.PCAP.CD,\n    \n    Agriculture_of_GDP=NV.AGR.TOTL.ZS,\n    Industry_of_GDP=NV.IND.TOTL.ZS,\n    Services_of_GDP=NV.SRV.TOTL.ZS,\n    Year = date,\n    Country_Name = country\n  )\n\n# Select only the columns you need\nfinal_gdp_data &lt;- world_gdp_data_with_names %&gt;%mutate(total=Agriculture_of_GDP+Industry_of_GDP+Services_of_GDP)\n  \n\n# Print the first few rows of the final data\nhead(final_gdp_data)\n\n\n\n\nCode\n# Create the line chart\n\nchina_thailand_data=final_gdp_data |&gt; filter(Country_Name %in% c(\"China\", \"Thailand\",\"United States\",\"Japan\",\"Korea, Rep.\")) |&gt; mutate(Year=as.numeric(Year))\n\ngdp_per_capita_plot &lt;- ggplot(data = china_thailand_data, aes(x = Year, y = Services_of_GDP, color = Country_Name)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Services_of_GDP: China vs Thailand vs US\",\n    #subtitle = \"Services_of_GDP\",\n    x = \"Year\",\n    y = \"Services_of_GDP\",\n    color = \"Country_Name\"\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\ngdp_per_capita_plot\n\n\n\n\nCode\ngdp_per_capita_plot &lt;- ggplot(data = china_thailand_data, aes(x = Year, y = GDP_per_capita, color = Country_Name)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"GDP Per Capita: China vs Thailand\",\n    subtitle = \"Comparison of GDP per Capita (current US$)\",\n    x = \"Year\",\n    y = \"GDP Per Capita (USD)\",\n    color = \"Country_Name\"\n  ) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 12),\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\ngdp_per_capita_plot"
  },
  {
    "objectID": "posts/GDP/index.html#wdi-package",
    "href": "posts/GDP/index.html#wdi-package",
    "title": "世界GDP",
    "section": "WDI package",
    "text": "WDI package\n\n\nCode\nlibrary(WDI)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n\n\n\nCode\n# Download GDP data from World Bank\ngdp_data &lt;- WDI(\n  country = \"all\",\n  indicator = c(\n    gdp = \"NY.GDP.MKTP.CD\",               # GDP (current US$)\n    gdp_per_capita = \"NY.GDP.PCAP.CD\",    # GDP per capita (current US$)\n    agriculture = \"NV.AGR.TOTL.ZS\",       # Agriculture value added (% of GDP)\n    industry = \"NV.IND.TOTL.ZS\",          # Industry value added (% of GDP)\n    services = \"NV.SRV.TOTL.ZS\"           # Services value added (% of GDP)\n  ),\n  start = 2000,\n  end = 2023,\n  extra = TRUE\n)"
  },
  {
    "objectID": "posts/GDP/index.html#imf",
    "href": "posts/GDP/index.html#imf",
    "title": "世界GDP",
    "section": "IMF",
    "text": "IMF"
  },
  {
    "objectID": "posts/password_management/index.html",
    "href": "posts/password_management/index.html",
    "title": "密码管理",
    "section": "",
    "text": "A guide to securely managing passwords in R and Python using various methods like local files, environment variables, and the keyring package.\nThis document explores various methods for securely managing passwords and other sensitive credentials in R and Python. For R, it presents three main options: sourcing a local R file, using environment variables, and leveraging the keyring package for more secure storage. For Python, it suggests a similar approach of importing credentials from a separate Python file. These techniques help you avoid hardcoding sensitive information directly in your scripts, improving the security and portability of your code.\nPassword management in R and Python"
  },
  {
    "objectID": "posts/password_management/index.html#option-1-using-source",
    "href": "posts/password_management/index.html#option-1-using-source",
    "title": "密码管理",
    "section": "Option 1 using source",
    "text": "Option 1 using source\n\ncreate pass.r and keep it yourself\n\n\n\nCode\n\npass.r\n\npass1='123'\n\n\n\n\n\nsource the pass.r in the main code\n\n\nCode\nsource('pass.r')\npass1\n\n\n[1] \"123\""
  },
  {
    "objectID": "posts/password_management/index.html#option-2-use-environment-variables",
    "href": "posts/password_management/index.html#option-2-use-environment-variables",
    "title": "密码管理",
    "section": "Option 2 Use Environment variables",
    "text": "Option 2 Use Environment variables\n\nopen /home/.Renviron\n\n\nCode\nusethis::edit_r_environ()\n\n\n\n\nsave following password in .Renviron\n\n\nCode\nfake_userid = \"username\"\nfake_pwd = \"password\"   \n\n\n\n\nget it back\n\n\nCode\nSys.getenv(\"fake_userid\")\n\n\n[1] \"username\"\n\n\nCode\nSys.getenv(\"fake_pwd\")\n\n\n[1] \"password\""
  },
  {
    "objectID": "posts/password_management/index.html#option-3-using-keyringr-package",
    "href": "posts/password_management/index.html#option-3-using-keyringr-package",
    "title": "密码管理",
    "section": "Option 3 using keyringr package",
    "text": "Option 3 using keyringr package\n\n\nCode\npak::pak(\"keyring\")\n\n\n\n\nCode\nlibrary(keyring)\n\n\n\n\nCode\n# Interactively save a secret. This avoids typing the value of the secret\n# into the console as this could be recorded in your `.Rhistory`\nkey_set(\"account_fake_001\")\n\n\n\n\nCode\n# Later retrieve that secret\nkey_get(\"account_fake_001\")"
  },
  {
    "objectID": "posts/password_management/index.html#option-1-using-import",
    "href": "posts/password_management/index.html#option-1-using-import",
    "title": "密码管理",
    "section": "Option 1 using import",
    "text": "Option 1 using import\n\ncreate pass_file.py and keep it yourself\n\n\n\nCode\n\npass_file.py\n\npass1='123'\n\n\n\n\n\ncall pass_file.py with import\n\n\nCode\nfrom pass_file import *\n#from pass_file import acct\npass_w\n\n\n'123'\n\n\nCode\nacct_w\n\n\n'222'"
  },
  {
    "objectID": "posts/AI_OCR/index.html",
    "href": "posts/AI_OCR/index.html",
    "title": "AI图片识别文字",
    "section": "",
    "text": "A demonstration of how to perform OCR using both online (Gemini 2.5) and offline (InternVL3 1B) AI models, with Python code examples for text extraction from images in both English and Chinese.\nThis document demonstrates how to perform Optical Character Recognition (OCR) using both online and offline AI models. It provides Python code examples for extracting text from images in both English and Chinese using the Gemini 2.5 API. Additionally, it includes instructions and code for setting up and using the InternVL3 1B model locally, including functions for image preprocessing and model splitting. This guide is a valuable resource for anyone looking to implement OCR in their projects.\nwith Gemini 2.5 online/InternVL3 offline"
  },
  {
    "objectID": "posts/AI_OCR/index.html#english-extract",
    "href": "posts/AI_OCR/index.html#english-extract",
    "title": "AI图片识别文字",
    "section": "English Extract",
    "text": "English Extract\n\n\n\nCode\nimage = Image.open(\"images/english.jpg\")\n\nresponse_gemini_en = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[image, \"Extract text from image\"])\n\n\n\n\nCode\nprint(response_gemini_en.text)\n\n\nWrite slowly and take the time\nto make sure each letter\nis the perfect shape"
  },
  {
    "objectID": "posts/AI_OCR/index.html#chinese-extract",
    "href": "posts/AI_OCR/index.html#chinese-extract",
    "title": "AI图片识别文字",
    "section": "Chinese Extract",
    "text": "Chinese Extract\n\n\n\nCode\nimage = Image.open(\"images/chinese.png\")\n\nresponse_gemini = client.models.generate_content(\n    model=\"gemini-2.5-pro-exp-03-25\",\n    contents=[image, \"提取图上的文字\"])\n\n\n\n\nCode\nprint(response_gemini.text)\n\n\n放养\n\n把我不羁的灵魂\n放养在可可西里的草原上，\n藏雪狐活泼没人爱人\n我与它捉迷藏\n\n把我不羁的灵魂，\n放养在撒哈拉沙漠上，\n看生命在贫瘠的土地上，\n依然欣欣向荣地生长\n\n把我不羁的灵魂\n放养在昏黄遗迹的小岛\n坐上星期五的木筏\n勇敢地乘风破浪\n\n把我不羁的灵魂\n放养在天涯海角\n就让我自由地去流浪。"
  },
  {
    "objectID": "posts/AI_OCR/index.html#single-image-single-round-conversation-单图单轮对话",
    "href": "posts/AI_OCR/index.html#single-image-single-round-conversation-单图单轮对话",
    "title": "AI图片识别文字",
    "section": "single-image single-round conversation (单图单轮对话)",
    "text": "single-image single-round conversation (单图单轮对话)\n\n\nCode\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.225)\n\ndef build_transform(input_size):\n    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n        T.ToTensor(),\n        T.Normalize(mean=MEAN, std=STD)\n    ])\n    return transform\n\ndef find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n    best_ratio_diff = float('inf')\n    best_ratio = (1, 1)\n    area = width * height\n    for ratio in target_ratios:\n        target_aspect_ratio = ratio[0] / ratio[1]\n        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n        if ratio_diff &lt; best_ratio_diff:\n            best_ratio_diff = ratio_diff\n            best_ratio = ratio\n        elif ratio_diff == best_ratio_diff:\n            if area &gt; 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n                best_ratio = ratio\n    return best_ratio\n\ndef dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n    orig_width, orig_height = image.size\n    aspect_ratio = orig_width / orig_height\n\n    # calculate the existing image aspect ratio\n    target_ratios = set(\n        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n        i * j &lt;= max_num and i * j &gt;= min_num)\n    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n\n    # find the closest aspect ratio to the target\n    target_aspect_ratio = find_closest_aspect_ratio(\n        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n\n    # calculate the target width and height\n    target_width = image_size * target_aspect_ratio[0]\n    target_height = image_size * target_aspect_ratio[1]\n    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n\n    # resize the image\n    resized_img = image.resize((target_width, target_height))\n    processed_images = []\n    for i in range(blocks):\n        box = (\n            (i % (target_width // image_size)) * image_size,\n            (i // (target_width // image_size)) * image_size,\n            ((i % (target_width // image_size)) + 1) * image_size,\n            ((i // (target_width // image_size)) + 1) * image_size\n        )\n        # split the image\n        split_img = resized_img.crop(box)\n        processed_images.append(split_img)\n    assert len(processed_images) == blocks\n    if use_thumbnail and len(processed_images) != 1:\n        thumbnail_img = image.resize((image_size, image_size))\n        processed_images.append(thumbnail_img)\n    return processed_images\n\ndef load_image(image_file, input_size=448, max_num=12):\n    image = Image.open(image_file).convert('RGB')\n    transform = build_transform(input_size=input_size)\n    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n    pixel_values = [transform(image) for image in images]\n    pixel_values = torch.stack(pixel_values)\n    return pixel_values\n\ndef split_model(model_name):\n    device_map = {}\n    world_size = torch.cuda.device_count()\n    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n    num_layers = config.llm_config.num_hidden_layers\n    # Since the first GPU will be used for ViT, treat it as half a GPU.\n    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n    layer_cnt = 0\n    for i, num_layer in enumerate(num_layers_per_gpu):\n        for j in range(num_layer):\n            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n            layer_cnt += 1\n    device_map['vision_model'] = 0\n    device_map['mlp1'] = 0\n    device_map['language_model.model.tok_embeddings'] = 0\n    device_map['language_model.model.embed_tokens'] = 0\n    device_map['language_model.output'] = 0\n    device_map['language_model.model.norm'] = 0\n    device_map['language_model.model.rotary_emb'] = 0\n    device_map['language_model.lm_head'] = 0\n    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n\n    return device_map\n\n\n\nEnglish Extract\n\n\n\nCode\npixel_values = load_image('images/english.jpg').to(torch.bfloat16)\nquestion = '&lt;image&gt;\\nPlease Extract text from image'\nresponse_en = model.chat(tokenizer, pixel_values, question, generation_config)\n\n\n\n\nCode\nprint(response_en)\n\n\nWrite slowly and take the time to make sure each letter is the perfect shape\n\n\n\n\nChinese Extract\n\n\n\nCode\npixel_values = load_image('images/chinese.png').to(torch.bfloat16)\n\nquestion = '&lt;image&gt;\\n提取图上的文字'\nresponse = model.chat(tokenizer, pixel_values, question, generation_config)\n\n\n\n\nCode\nprint(response)\n\n\n放养  \n把我不羁的灵魂  \n放在了鄂西西里的草原上，  \n藏雪狐活发爱人  \n我与它捉迷藏  \n把我不羁的灵魂  \n放在撒哈拉沙漠上，  \n看生命在贫瘠的土地上，  \n依然欣欣欣荣地生长  \n把我不羁的灵魂  \n放在鲁滨逊的小岛上  \n坐上星期五的木筏  \n勇敢地乘风破浪  \n\n把我不羁的灵魂  \n放养在天涯海角  \n让我自由地去流浪。"
  },
  {
    "objectID": "posts/CPUGPU/index.html",
    "href": "posts/CPUGPU/index.html",
    "title": "CPU and GPU",
    "section": "",
    "text": "Provides resources for checking CPU and GPU performance, including local and global benchmarks.\nThis document serves as a resource hub for checking CPU and GPU performance. It provides information and tools for evaluating the performance of both your local machine and comparing it with global benchmarks. The document includes embedded HTML iframes to display local CPU, GPU OpenCL, and GPU Metal performance, as well as links to Geekbench benchmarks for worldwide comparisons. This is a valuable resource for anyone interested in understanding and comparing the performance of their hardware.\nCPU & GPU Performance\n\nlocal computer CPU and GPU info\n\nCPUGPU OpenCL PerformanceGPU Metal Performance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld computer CPU and GPU info\n\nCPUGPU OpenCL PerformanceGPU Metal Performance\n\n\nhttps://browser.geekbench.com/v6/cpu/multicore\n\n\n\nhttps://browser.geekbench.com/opencl-benchmarks\n\n\n\nhttps://browser.geekbench.com/metal-benchmarks\n\n\n\n\n\n\nReference\nhttps://www.geekbench.com/\nhttps://github.com/ProjectPhysX/OpenCL-Benchmark"
  },
  {
    "objectID": "posts/Classification Metrics/index.html",
    "href": "posts/Classification Metrics/index.html",
    "title": "Classification Metrics",
    "section": "",
    "text": "A comprehensive guide to classification metrics in Python, covering concepts like sensitivity, precision, AUROC, and F1-score with practical code examples.\nThis document provides a comprehensive guide to understanding and implementing various classification metrics in Python. It covers key concepts such as sensitivity, precision, AUROC, accuracy, F1-score, and specificity. The guide includes practical code examples that walk you through the entire process, from installing the necessary packages and loading data from Kaggle to training a logistic regression model and visualizing the results with a confusion matrix and ROC/PR curves. This is an essential resource for anyone looking to evaluate the performance of their classification models.\nClassification Metrics Explained | Sensitivity, Precision, AUROC, & More\n\ninstall package\n\n\nCode\npip install -U scikit-learn\npip install -U kaggle\npip install -U kagglehub\n\n\n\n\nload package\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\n\n#from kaggle.api.kaggle_api_extended import KaggleApi\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    precision_score, recall_score, roc_curve,\n    accuracy_score, f1_score, roc_auc_score,\n    average_precision_score, confusion_matrix,\n    precision_recall_curve\n)\n\n\n\n\ndownload data from kaggle\n\n\nCode\nimport kagglehub\n# Download latest version\nkagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\npath = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\nprint(\"Path to dataset files:\", path)\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.12).\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/jinchaoduan/.cache/kagglehub/datasets/uciml/pima-indians-diabetes-database/versions/1\n\n\nshow data file under download folder\n\n\nCode\nimport os\nos.listdir(path)\n\n\n['diabetes.csv']\n\n\n\n\nread data\n\n\nCode\ndf = pd.read_csv(path+'/'+os.listdir(path)[0])\ndf.head()\n\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\n\nCode\ndf.Outcome.value_counts()\n\n\nOutcome\n0    500\n1    268\nName: count, dtype: int64\n\n\n\n\nCode\n# separate features from response\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\n\n\n\n\nCode\n# split data into test and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n\n\nCode\n# initialize and train logistic regression model\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n\nLogisticRegression(max_iter=1000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(max_iter=1000) \n\n\n\n\nCode\n# predict on the test set and get the probas\ny_pred = model.predict(X_test)\ny_pred_proba = model.predict_proba(X_test)[:, 1] \n\n\n\n\nCode\n# quickly look at the distribution of the probas\npercentiles = np.percentile(y_pred_proba, [5, 25, 50, 75, 95])\npercentiles\n\n\narray([0.03455652, 0.11989883, 0.29954411, 0.64776581, 0.87083353])\n\n\n\n\nconfusion matrix\n\n\nCode\n# generate confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.xticks([0.5, 1.5], ['No Diabetes', 'Diabetes'])\nplt.yticks([0.5, 1.5], ['No Diabetes', 'Diabetes'], va='center')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# recall / sensitivity\nrecall = recall_score(y_test, y_pred)\nrecall\n\n\n0.6727272727272727\n\n\n\n\nCode\n# precision / positive predictive value\nprecision = precision_score(y_test, y_pred)\nprecision\n\n\n0.6379310344827587\n\n\n\n\nCode\n# specificity\ntn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\nspecificity = tn / (tn + fp)\nspecificity\n\n\nnp.float64(0.7878787878787878)\n\n\n\n\nCode\n# accuracy\naccuracy = accuracy_score(y_test, y_pred)\naccuracy\n\n\n0.7467532467532467\n\n\n\n\nCode\n# f1\nf1 = f1_score(y_test, y_pred)\nf1\n\n\n0.6548672566371682\n\n\n\n\nCode\n# get ROC curve values\nfpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n\n# get PR curve values\nprecision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n\n# get areas under the curves\nauroc = roc_auc_score(y_test, y_pred_proba)\npr_auc = average_precision_score(y_test, y_pred_proba)\n\n\n\n\nCode\n# plot both curves\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\nax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auroc:.2f}')\nax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate')\nax1.set_title('Receiver Operating Characteristic (ROC) Curve')\nax1.legend(loc=\"lower right\")\n\n# Plot Precision-Recall Curve\nax2.plot(recall, precision, color='purple', lw=2, label=f'PR-AUC = {pr_auc:.2f}')\nax2.set_xlabel('Recall')\nax2.set_ylabel('Precision')\nax2.set_title('Precision-Recall Curve')\nax2.legend(loc=\"lower left\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_test.value_counts()\n\n\nOutcome\n0    99\n1    55\nName: count, dtype: int64\n\n\n\n\nReference\nhttps://www.youtube.com/watch?v=KdUrfY1yM0w\nhttps://github.com/RichardOnData/YouTube/blob/main/Python%20Notebooks/classification_metrics.ipynb"
  },
  {
    "objectID": "posts/multi language blog/index.html",
    "href": "posts/multi language blog/index.html",
    "title": "多语言 quarto blog",
    "section": "",
    "text": "A guide to creating a multi-language Quarto blog using the babelquarto R package.\nThis document provides a step-by-step guide to creating a multi-language blog using Quarto and the babelquarto R package. It covers the entire process, from installing and loading the necessary packages to setting up the main and additional languages. The guide also explains how to modify the _quarto.yml file for language-specific configurations, create new language versions of your .qmd files, and render the final website. It also suggests using LLMs for translation to streamline the content creation process."
  },
  {
    "objectID": "posts/multi language blog/index.html#add-site-url-to-system-environment-before-render",
    "href": "posts/multi language blog/index.html#add-site-url-to-system-environment-before-render",
    "title": "多语言 quarto blog",
    "section": "7.1 add site url to system environment before render",
    "text": "7.1 add site url to system environment before render\n\n\nCode\nSys.setenv(BABELQUARTO_CI_URL=\"https://jcfly3000.github.io/into_AI/\")\n\n\n\n\nCode\nSys.getenv(\"BABELQUARTO_CI_URL\")"
  },
  {
    "objectID": "posts/multi language blog/index.html#we-use-babelquartorender_website.",
    "href": "posts/multi language blog/index.html#we-use-babelquartorender_website.",
    "title": "多语言 quarto blog",
    "section": "7.2 we use babelquarto::render_website().",
    "text": "7.2 we use babelquarto::render_website().\nwe need to render the .qmd files to HTML. If you are used to using Quarto, you may expect to do this with quarto render or quarto preview, but those do not work with babelquarto.\n\n\nCode\nbabelquarto::render_website()"
  },
  {
    "objectID": "posts/path_managment/index.html",
    "href": "posts/path_managment/index.html",
    "title": "路径管理",
    "section": "",
    "text": "A guide to managing file paths in R and Python, with a focus on the fs and here packages in R.\nThis document addresses the common challenge of managing file paths across different operating systems, such as Windows and Mac. It provides a guide to using dedicated packages in R and Python to handle file paths in a robust and reproducible way. The R section focuses on the fs package for a wide range of file system operations and the here package for creating project-relative paths that work seamlessly across different environments. The Python section is a placeholder for future content.\nSince windows and mac have different file path, we use package to manage the file path."
  },
  {
    "objectID": "posts/path_managment/index.html#fs-pacakge",
    "href": "posts/path_managment/index.html#fs-pacakge",
    "title": "路径管理",
    "section": "fs pacakge",
    "text": "fs pacakge\n\n\nCode\n#pak::pkg_install('here')\n#pak::pkg_install('fs')\nlibrary(fs)\n\n\n\n\nCode\ngetwd()\n\n\n\nlist file in the current directory\n\n\nCode\ndir_ls()\n\n\n\n\nshow the current directory file info\n\n\nCode\ndir_info()\n\n\n\n\nshow the current directory file tree\n\n\nCode\ndir_tree()\n\n\n\n\ncreate a new temp directory\n\n\nCode\n# create a new directory\ntmp &lt;- dir_create(file_temp())\ntmp\n\n\n\n\ncreate new files in that directory\n\n\nCode\n# create new files in that directory\nfile_create(path(tmp, \"my-file.txt\"))\ndir_ls(tmp)\n\n\n\n\nremove files from the directory\n\n\nCode\n# remove files from the directory\nfile_delete(path(tmp, \"my-file.txt\"))\ndir_ls(tmp)\n\n\n\n\nremove the directory\n\n\nCode\n# remove the directory\ndir_delete(tmp)"
  },
  {
    "objectID": "posts/path_managment/index.html#here-package",
    "href": "posts/path_managment/index.html#here-package",
    "title": "路径管理",
    "section": "here package",
    "text": "here package\n\n\nCode\nlibrary(here)\n\n\n\nshow project directory\n\n\nCode\nhere()\n\n\n\n\nshow all file in the project directory\n\n\nCode\nlist.files(here())\n\n\n\n\nshow one file path\nhere.png in images folder\n\n\nCode\nimage_path=here('posts/path_managment/images','here.png')\nimage_path"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html",
    "href": "posts/download yotube on iphone or ipad/index.html",
    "title": "使用iphone或ipad下载youtube",
    "section": "",
    "text": "Instructions on how to download YouTube videos on iOS devices using the a-Shell mini app and the SW-DLT shortcut.\nThis document provides a step-by-step guide on how to download YouTube videos on iOS devices. It outlines two primary methods: using the a-Shell mini app to install and run youtube-dl, and using the SW-DLT shortcut for a more automated experience. The guide includes instructions for installing the necessary tools and running the download commands.\n首先需要确认你的iphone或ipad是可以连接youtube的。"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#用iphone或ipad下载-a-shell-mini-app",
    "href": "posts/download yotube on iphone or ipad/index.html#用iphone或ipad下载-a-shell-mini-app",
    "title": "使用iphone或ipad下载youtube",
    "section": "1. 用iphone或ipad下载 a-Shell mini app",
    "text": "1. 用iphone或ipad下载 a-Shell mini app\n\nhttps://apps.apple.com/us/app/a-shell-mini/id1543537943"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#打开a-shell-mini运行以下代码安装youtube-dl",
    "href": "posts/download yotube on iphone or ipad/index.html#打开a-shell-mini运行以下代码安装youtube-dl",
    "title": "使用iphone或ipad下载youtube",
    "section": "2. 打开a-shell mini运行以下代码安装youtube-dl",
    "text": "2. 打开a-shell mini运行以下代码安装youtube-dl\n\n\nCode\npip install youtube-dl\n\n\n如果想要下载高清视频再运行以下代码（可选）：\n\n\nCode\npip install gallery-dl\nmkdir bin\ncd bin\ncurl -L https://github.com/holzschu/a-Shell-commands/releases/download/0.1/ffmpeg.wasm -o ffmpeg.wasm"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#在a-shell-mini中用youtube-dl下载youtube视频",
    "href": "posts/download yotube on iphone or ipad/index.html#在a-shell-mini中用youtube-dl下载youtube视频",
    "title": "使用iphone或ipad下载youtube",
    "section": "3. 在a-shell mini中用youtube-dl下载youtube视频",
    "text": "3. 在a-shell mini中用youtube-dl下载youtube视频\n找到你想要下载的youtube视频网站地址，在a-shell mini里运行以下代码\n\n\nCode\nyoutube-dl https://www.youtube.com/watch?v=FT3ODSg1GFE"
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#使用shortcut-app里的sw-dlt自动下载可选",
    "href": "posts/download yotube on iphone or ipad/index.html#使用shortcut-app里的sw-dlt自动下载可选",
    "title": "使用iphone或ipad下载youtube",
    "section": "4. 使用shortcut app里的SW-DLT自动下载(可选)",
    "text": "4. 使用shortcut app里的SW-DLT自动下载(可选)\n如果你觉得每次都要在a-shell mini里打那么长的代码。也可以使用shortcut app。\n用iphone或ipad扫描下面二维码下载SW-DLT\n\n使用方法：\n1.复制要下载的youtube视频连接\n2.打开shrotcut app点击SW-DLT就会开始自动下载了\n打开shrotcut app：\n\n点击SW-DLT："
  },
  {
    "objectID": "posts/download yotube on iphone or ipad/index.html#reference",
    "href": "posts/download yotube on iphone or ipad/index.html#reference",
    "title": "使用iphone或ipad下载youtube",
    "section": "Reference",
    "text": "Reference\n3 Ways to Run youtube-dl on iOS :https://chrunos.com/youtube-dl-ios/\nSW-DLT:https://routinehub.co/shortcut/7284/"
  },
  {
    "objectID": "posts/copilot/index.html",
    "href": "posts/copilot/index.html",
    "title": "AI Code assistant",
    "section": "",
    "text": "An introduction to AI code assistants, focusing on setting up and using GitHub Copilot in RStudio.\nThis document provides an introduction to AI-powered code assistants, with a specific focus on setting up and using GitHub Copilot within the RStudio IDE. It walks through the necessary steps to enable and configure Copilot, and also mentions other relevant tools like Codeium Copilot for Positron and the chores and gander R packages. This guide is a great starting point for anyone looking to leverage AI to enhance their coding workflow.\nAI tool for writing code"
  },
  {
    "objectID": "posts/copilot/index.html#step-1-enable-on-rstudio",
    "href": "posts/copilot/index.html#step-1-enable-on-rstudio",
    "title": "AI Code assistant",
    "section": "Step 1 Enable on RStudio",
    "text": "Step 1 Enable on RStudio"
  },
  {
    "objectID": "posts/copilot/index.html#step-2-configure-on-github",
    "href": "posts/copilot/index.html#step-2-configure-on-github",
    "title": "AI Code assistant",
    "section": "Step 2 configure on github",
    "text": "Step 2 configure on github\nfree account is limited per month"
  },
  {
    "objectID": "posts/regular_expression/index.html",
    "href": "posts/regular_expression/index.html",
    "title": "正则表达式代码",
    "section": "",
    "text": "A guide to using regular expressions in R and Python for pattern matching and extraction.\nThis document serves as a practical guide to using regular expressions (regex) in both R and Python. It provides a series of examples demonstrating how to perform common tasks such as extracting numbers, capturing text between specific delimiters, and matching complex patterns, including those with special characters. The R section utilizes the stringr package for its intuitive functions, while the Python section is a placeholder for future content."
  },
  {
    "objectID": "posts/regular_expression/index.html#view",
    "href": "posts/regular_expression/index.html#view",
    "title": "正则表达式代码",
    "section": "view",
    "text": "view\n\n\nCode\nlibrary(stringr)\n\n\n\n\nCode\nlibrary(stringr)\npattern='cat'\nstr_view_all(\"The cat sat on the mat with another cat.\", pattern)"
  },
  {
    "objectID": "posts/regular_expression/index.html#extract-all-numbers-from-a-string",
    "href": "posts/regular_expression/index.html#extract-all-numbers-from-a-string",
    "title": "正则表达式代码",
    "section": "Extract all numbers from a string:",
    "text": "Extract all numbers from a string:\n\n\nCode\npattern=\"\\\\d+\"\nstr_view(\"I bought 3 apples, 12 bananas, and 5 oranges.\",pattern)\n\n\n\n\nCode\nstr_extract_all(\"I bought 3 apples, 12 bananas, and 5 oranges.\", pattern) |&gt; unlist()"
  },
  {
    "objectID": "posts/regular_expression/index.html#extract-string-between-two-string",
    "href": "posts/regular_expression/index.html#extract-string-between-two-string",
    "title": "正则表达式代码",
    "section": "Extract string between two string:",
    "text": "Extract string between two string:\n\n\nCode\na &lt;- \"STR1 11111 STR2 STR1 22222 STR2,\"\nres &lt;- str_extract_all(a, \"STR1\\\\s*(.*?)\\\\s*STR2\")\nres\n\na=res |&gt; unlist()\n\nprint(paste0(\"first match: \",a[1]))\n      \nprint(paste0(\"second match: \",a[2]))"
  },
  {
    "objectID": "posts/regular_expression/index.html#match-sperical",
    "href": "posts/regular_expression/index.html#match-sperical",
    "title": "正则表达式代码",
    "section": "match sperical",
    "text": "match sperical\nregular expression for getting string between ‘/’ and ’\\(' on \"The /1234cat\\) sat on the 1245ma with another 4444ee cat.”\n\n\nCode\npattern= \"/(.*?)\\\\$\"\nstr_view_all(\"The /1234cat$ sat on the 1245ma with another 4444ee cat.\", pattern)\n\n\n\n\nCode\npattern= \"/(.*?)\\\\$\"\nmatches &lt;- str_extract_all(\"The /1234cat$ sat on the 1245ma with another 4444ee cat.\",pattern)\nmatches"
  },
  {
    "objectID": "posts/usefullresource/index.html",
    "href": "posts/usefullresource/index.html",
    "title": "Useful resource",
    "section": "",
    "text": "A curated list of valuable resources, focusing on YouTube channels dedicated to R programming and data science.\nThis document provides a curated list of valuable resources for anyone interested in R programming and data science. It focuses on a selection of high-quality YouTube channels that offer tutorials, case studies, and expert insights into various aspects of the R ecosystem. This is a great starting point for both beginners and experienced users who are looking to expand their knowledge and skills.\nA curated list of helpful resources, specifically YouTube channels related to R programming and data science.\nSome useful resource\n\nYoutube\n\nRProgramming101\n\nPositPBC\n\nJuliaSilge\n\n\n\nthecoatlessprofessor\n\n\n\nEquitableEquations"
  },
  {
    "objectID": "posts/github trend/index.html",
    "href": "posts/github trend/index.html",
    "title": "Github trend",
    "section": "",
    "text": "github tending project since 2024.\n\n\nload package\n\n\nCode\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(plotly)\n\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:httr':\n\n    config\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nlibrary(scales)\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\n\nget data\n\n\nCode\n# Install if needed\n# install.packages(c(\"httr\", \"jsonlite\"))\n\n# Calculate the date one week ago\n#since &lt;- format(Sys.Date() - 30, \"%Y-%m-%d\")\n\nsince &lt;- \"2024-01-01\"\n\n# Query GitHub search API for repos created in the last week, ordered by stars\nres &lt;- GET(\n  url = \"https://api.github.com/search/repositories\",\n  query = list(\n    q = paste0(\"created:&gt;\", since),\n    sort = \"stars\",\n    order = \"desc\",\n    per_page = 20\n  ),\n  add_headers(Accept = \"application/vnd.github.v3+json\")\n)\n\nstop_for_status(res)\ndata &lt;- content(res, as = \"parsed\", simplifyVector = TRUE)\n\n# Extract details\ntop &lt;- data$items\ndf &lt;- data.frame(\n  name        = top$full_name,\n  stars       = top$stargazers_count,\n  forks       = top$forks_count,\n  watchers    = top$watchers_count,\n  created_at  = top$created_at,\n  summary     = top$description,\n  url         = top$html_url,\n  stringsAsFactors = FALSE\n)\n\nglimpse(df)\n\n\nRows: 20\nColumns: 7\n$ name       &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\", \"deepseek-ai/DeepSeek-R1\", \"Digi…\n$ stars      &lt;int&gt; 98160, 90473, 65966, 65775, 65124, 60190, 60125, 58762, 570…\n$ forks      &lt;int&gt; 15978, 11678, 1251, 19126, 7440, 7044, 3160, 6793, 5162, 83…\n$ watchers   &lt;int&gt; 98160, 90473, 65966, 65775, 65124, 60190, 60125, 58762, 570…\n$ created_at &lt;chr&gt; \"2024-12-26T09:52:40Z\", \"2025-01-20T11:57:28Z\", \"2024-05-30…\n$ summary    &lt;chr&gt; NA, NA, \"DigitalPlat FreeDomain: Free Domain For Everyone\",…\n$ url        &lt;chr&gt; \"https://github.com/deepseek-ai/DeepSeek-V3\", \"https://gith…\n\n\n\n\nclean data\n\n\nCode\ndf$name_label &lt;- paste0(df$name, \"\n\", format(as.Date(df$created_at), \"%Y-%m-%d\"))\n\n# Reshape data to long format for plotting\ndf_long &lt;- df %&gt;%\n  select(name,name_label, url, stars, forks, watchers) %&gt;%\n  pivot_longer(cols = c(\"stars\", \"forks\", \"watchers\"),\n               names_to = \"metric\", values_to = \"count\") |&gt; mutate(text =paste0(\"&lt;a href='\",url,\"' target='_blank'&gt;\",name_label)\n               ) |&gt; mutate(text = factor(text, levels = rev(unique(text[order(-count)]))))\n     \nglimpse(df_long)\n\n\nRows: 60\nColumns: 6\n$ name       &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\", \"deepseek-ai/DeepSeek-V3\", \"deep…\n$ name_label &lt;chr&gt; \"deepseek-ai/DeepSeek-V3\\n2024-12-26\", \"deepseek-ai/DeepSee…\n$ url        &lt;chr&gt; \"https://github.com/deepseek-ai/DeepSeek-V3\", \"https://gith…\n$ metric     &lt;chr&gt; \"stars\", \"forks\", \"watchers\", \"stars\", \"forks\", \"watchers\",…\n$ count      &lt;int&gt; 98160, 15978, 98160, 90473, 11678, 90473, 65966, 1251, 6596…\n$ text       &lt;fct&gt; &lt;a href='https://github.com/deepseek-ai/DeepSeek-V3' target…\n\n\n\n\nggplot\n\n\nCode\n# Bar chart\ngg &lt;- ggplot(df_long, aes(x = reorder(name_label, count), y = count, fill = metric, customdata = url)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_text(aes(label = scales::label_number(accuracy = 0.1, scale_cut = scales::cut_short_scale())(count)), position = position_dodge(width = 0.9), hjust = -0.1, size = 3) +\n  labs(\n    title = \"Top 20 Fastest Growing GitHub Projects (since 2024)\",\n    x = \"Repository\",\n    y = \"Count\",\n    fill = \"Metric\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  coord_flip()\n\ngg\n\n\n\n\n\n\n\n\n\n\n\nplotly\n\n\nCode\nfig &lt;- plot_ly(\n  data = df_long,\n  x = ~count,\n  y = ~text,\n  color = ~metric,\n  type = 'bar',\n  orientation = 'h',\n  customdata = ~url,\n  texttemplate = '%{x:.2s}',\n  textposition = 'outside',\n  hovertemplate = paste(\n    \"&lt;b&gt;Repository:&lt;/b&gt; %{y}&lt;br&gt;\",\n    \"&lt;b&gt;Count:&lt;/b&gt; %{x:.2s}&lt;br&gt;\",\n    \"&lt;b&gt;Metric:&lt;/b&gt; %{fullData.name}&lt;br&gt;\",\n    \"&lt;b&gt;URL:&lt;/b&gt; %{customdata}&lt;extra&gt;&lt;/extra&gt;\"\n  )\n\n) %&gt;%\n  layout(\n    title = \"Top 20 Fastest Growing GitHub Projects (since 2024)\",\n    xaxis = list(title = \"Count\", range = c(0, max(df_long$count) * 1.15)),\n    yaxis = list(title = \"Repository\", categoryorder = \"array\", categoryarray = levels(df_long$text)),\n    barmode = \"group\",\n    legend = list(title = list(text = \"Metric\")),\n    margin = list(b = 120)\n   ,height=900\n  )\n\n\nWarning: Specifying width/height in layout() is now deprecated.\nPlease specify in ggplotly() or plot_ly()\n\n\nCode\nfig"
  },
  {
    "objectID": "posts/subscribeYouTubeviaemail/index.html",
    "href": "posts/subscribeYouTubeviaemail/index.html",
    "title": "Subscribe to a YouTube channel via email",
    "section": "",
    "text": "A guide on how to subscribe to YouTube channels and receive updates via email using RSS feeds.\nIf you want to Subscribe to a YouTube channel but do not want to follow them.The trick is figuring out how to subscribe to a YouTube channel via email\n\nWhat is RSS?\nRSS (Really Simple Syndication) is a web feed that allows users and applications to access updates to online content in a standardized, computer-readable format. These feeds can, for example, allow a user to keep track of many different websites in a single news aggregator.\n\n\nStep 1: open youtube page of the channel want to subscribe\nfor example:https://www.youtube.com/@thecoatlessprofessor7674/videos\n\n\nStep 2: view page source\n\n\n\nStep 3: find ‘videos.xml’ in page source\nfor example: https://www.youtube.com/feeds/videos.xml?channel_id=UColncDCZ8SmTAHYr92QFclQ\n\n\nStep 4: Use an RSS-to-Email Tool to Subscribe\nusing free RSS tool https://feedrabbit.com and enter your email address to subscribe. \n\n\nStep 5: open email and activate feedrabbit from a email from feedrabbit\nWhen there is a new video you will get a email.\nyou can also view all subscribe at https://feedrabbit.com/subscriptions\n\n\nReference\nhttps://greggblanchard.com/how-to-subscribe-to-a-youtube-channel-via-email/"
  },
  {
    "objectID": "posts/versioncontrolpython/index.html",
    "href": "posts/versioncontrolpython/index.html",
    "title": "Version control for Python with uv",
    "section": "",
    "text": "A comprehensive guide to using uv for Python project and package management. This document covers installation, project initialization, Python version management, and various package operations.\nThis document provides a comprehensive guide to using uv, a fast and efficient tool for Python project and package management. It covers the entire workflow, from installation and project initialization to managing Python versions and handling package operations. The guide also demonstrates how to use uv to synchronize dependencies and even run scripts with specific package requirements. This is a valuable resource for any Python developer looking to streamline their development process.\nIntroduces uv as a fast and comprehensive tool for Python project and package management. It covers uv’s installation, project initialization, Python version management, package operations, and dependency synchronization."
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#there-is-no-rich-package-in-python",
    "href": "posts/versioncontrolpython/index.html#there-is-no-rich-package-in-python",
    "title": "Version control for Python with uv",
    "section": "there is no rich package in python",
    "text": "there is no rich package in python\n\n\nCode\ntry:\n    import rich\n    print('pacakge installed')\nexcept ImportError as e:\n    print('pacakge not installed')\n    pass  # module doesn't exist, deal with it."
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#but-can-add-rich-package-in-script",
    "href": "posts/versioncontrolpython/index.html#but-can-add-rich-package-in-script",
    "title": "Version control for Python with uv",
    "section": "but can add rich package in script",
    "text": "but can add rich package in script\n#| eval: false\n\n# /// script\n# requires-python = \"&gt;=3.12\"\n# dependencies = [\n#   \"requests&lt;3\",\n#   \"rich\",\n# ]\n# ///\n\nimport requests\nimport rich\nfrom rich.pretty import pprint\n\n\nimport rich\nfrom importlib.metadata import version\n\nprint('test.py is running')\nprint('version is :')\nprint(version('rich'))"
  },
  {
    "objectID": "posts/versioncontrolpython/index.html#run-.py-with-uv",
    "href": "posts/versioncontrolpython/index.html#run-.py-with-uv",
    "title": "Version control for Python with uv",
    "section": "run .py with uv",
    "text": "run .py with uv\n\n\nCode\n!uv run test.py\n\n\n░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0/0⠙ Resolving dependencies...                                                     ⠋ Resolving dependencies...                                                     ⠙ Resolving dependencies...                                                     ⠹ Resolving dependencies...                                                     ⠸ Resolving dependencies...                                                     ⠸ requests==2.32.4                                                              ⠸ rich==14.0.0                                                                  ⠼ rich==14.0.0                                                                  ⠴ rich==14.0.0                                                                  ⠦ rich==14.0.0                                                                  ⠦ charset-normalizer==3.4.2                                                     ⠦ idna==3.10                                                                    ⠦ urllib3==2.5.0                                                                ⠦ certifi==2025.6.15                                                            ⠦ markdown-it-py==3.0.0                                                         ⠦ pygments==2.19.2                                                              ⠦ mdurl==0.1.2                                                                  ⠦                                                                               ░░░░░░░░░░░░░░░░░░░░ [0/0] Installing wheels...                                 ░░░░░░░░░░░░░░░░░░░░ [0/9] Installing wheels...                                 ░░░░░░░░░░░░░░░░░░░░ [0/9] certifi==2025.6.15                                   ██░░░░░░░░░░░░░░░░░░ [1/9] certifi==2025.6.15                                   ██░░░░░░░░░░░░░░░░░░ [1/9] rich==14.0.0                                         ████░░░░░░░░░░░░░░░░ [2/9] rich==14.0.0                                         ████░░░░░░░░░░░░░░░░ [2/9] idna==3.10                                           ██████░░░░░░░░░░░░░░ [3/9] idna==3.10                                           ██████░░░░░░░░░░░░░░ [3/9] requests==2.32.4                                     ████████░░░░░░░░░░░░ [4/9] requests==2.32.4                                     ████████░░░░░░░░░░░░ [4/9] urllib3==2.5.0                                       ███████████░░░░░░░░░ [5/9] urllib3==2.5.0                                       ███████████░░░░░░░░░ [5/9] mdurl==0.1.2                                         █████████████░░░░░░░ [6/9] mdurl==0.1.2                                         █████████████░░░░░░░ [6/9] markdown-it-py==3.0.0                                ███████████████░░░░░ [7/9] markdown-it-py==3.0.0                                ███████████████░░░░░ [7/9] charset-normalizer==3.4.2                            █████████████████░░░ [8/9] charset-normalizer==3.4.2                            █████████████████░░░ [8/9] pygments==2.19.2                                     ████████████████████ [9/9] pygments==2.19.2                                     Installed 9 packages in 21ms\ntest.py is running\nversion is :\n14.0.0"
  },
  {
    "objectID": "posts/norway_pension_fund/index.html",
    "href": "posts/norway_pension_fund/index.html",
    "title": "挪威养老基金",
    "section": "",
    "text": "An overview of Norway’s Government Pension Fund Global, including its purpose and links to resources.\nThis document provides an overview of the Government Pension Fund Global of Norway, one of the world’s largest sovereign wealth funds. It explains the fund’s purpose, which is to manage the financial reserves from Norway’s oil and gas resources for the benefit of current and future generations. The document also includes links to the fund’s official website, investment data, and a related podcast, offering a comprehensive resource for those interested in learning more about this significant financial institution.\nThe Government Pension Fund Global was established after Norway discovered oil in the North Sea.\nThe fund was set up to shield the economy from ups and downs in oil revenue. It also serves as a financial reserve and as a long-term savings plan so that both current and future generations of Norway get to benefit from our oil wealth.\nhttps://www.nbim.no/en\n\n\nCode\nlibrary(ellmer)\nlibrary(tidyverse)\nlibrary(srt)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lares)\nlibrary(tuneR)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(av)\n\n\n\npodcast\nhttps://shows.acast.com/in-good-company-with-nicolai-tangen\n\n\nCode\none_podcast='https://shows.acast.com/in-good-company-with-nicolai-tangen/episodes/highlights-debra-crew-ceo-of-diageo'\n\naudio_page &lt;- read_html(one_podcast)\n    \n# 提取音频标题，property=\"og:title\"的meta元素的content值\ntitle &lt;- audio_page %&gt;%\nhtml_nodes('meta[property=\"og:title\"]') %&gt;%\nhtml_attr(\"content\")\n\ntitle  \n\n# 提取音频下载链接，property=\"og:audio\"的meta元素的content值\naudio_url &lt;- audio_page %&gt;%\n  html_nodes('meta[property=\"og:audio\"]') %&gt;%\n  html_attr(\"content\")\n\naudio_url\n\n\n\n\nCode\noutput_file_name=paste0(title,\".mp3\")\ndownload.file(url = audio_url, destfile = output_file_name)\n\n\n\n\ndata\nhttps://www.nbim.no/en/investments/all-investments/#/\n\n\nvideo\nhttps://www.youtube.com/watch?v=mT6mRJehJdw"
  },
  {
    "objectID": "posts/api_with_httr2/index.html",
    "href": "posts/api_with_httr2/index.html",
    "title": "使用R httr2 调用API",
    "section": "",
    "text": "A guide to using the httr2 R package for interacting with web APIs, with examples for the US National Weather Service and OpenWeatherMap APIs.\nThis document provides a practical guide to using the httr2 package in R for interacting with web APIs. It includes two detailed examples: one that demonstrates how to call the US National Weather Service (NWS) API to retrieve hourly weather forecasts, and another that shows how to use the OpenWeatherMap API to get current weather data for a specific city. The guide covers the entire process, from constructing the API request to performing the request and extracting the relevant data from the JSON response.\nThe httr2 package provides a pipeable API for working with web APIs."
  },
  {
    "objectID": "posts/api_with_httr2/index.html#api-link",
    "href": "posts/api_with_httr2/index.html#api-link",
    "title": "使用R httr2 调用API",
    "section": "API link",
    "text": "API link\n\n\nCode\nNWS_base_url &lt;- 'https://api.weather.gov'\n\nNWS_response_link &lt;- request(NWS_base_url) |&gt; \n  req_url_path_append(\n    'points',\n    '38.8894,-77.0352'\n  ) \n\nNWS_response_link"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#create-response-and-check-connection",
    "href": "posts/api_with_httr2/index.html#create-response-and-check-connection",
    "title": "使用R httr2 调用API",
    "section": "create response and check connection",
    "text": "create response and check connection\n\n\nCode\nNWS_response=NWS_response_link|&gt; req_perform()\nNWS_response"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-forecast-hourly-url-from-response",
    "href": "posts/api_with_httr2/index.html#get-forecast-hourly-url-from-response",
    "title": "使用R httr2 调用API",
    "section": "get forecast hourly url from response",
    "text": "get forecast hourly url from response\n\n\nCode\nNWS_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()\n\n\n\n\nCode\nforecast_url &lt;- NWS_response |&gt; \n  resp_body_json() |&gt; \n  pluck('properties', 'forecastHourly')\n\nforecast_url"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#make-forecast-hourly-response",
    "href": "posts/api_with_httr2/index.html#make-forecast-hourly-response",
    "title": "使用R httr2 调用API",
    "section": "make forecast hourly response",
    "text": "make forecast hourly response\n\n\nCode\nforecast_response &lt;- request(forecast_url) |&gt; \n  req_perform()\n\nforecast_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-forecast-hourly-data",
    "href": "posts/api_with_httr2/index.html#get-forecast-hourly-data",
    "title": "使用R httr2 调用API",
    "section": "get forecast hourly data",
    "text": "get forecast hourly data\n\n\nCode\nextracted_data &lt;- forecast_response |&gt; \n  resp_body_json() |&gt; \n  pluck('properties', 'periods') |&gt; \n  map_dfr( # iterates over each list and binds rows to a tibble\n    \\(x) {\n      tibble(\n        time = x |&gt; pluck('startTime'),\n        temp_F = x |&gt; pluck('temperature'),\n        rain_prob = x |&gt; pluck('probabilityOfPrecipitation', 'value'),\n        forecast = x |&gt; pluck('shortForecast')\n      )\n    }\n  )\n\nextracted_data"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#create-response",
    "href": "posts/api_with_httr2/index.html#create-response",
    "title": "使用R httr2 调用API",
    "section": "create response",
    "text": "create response\n\n\nCode\nlibrary(keyring)\nopenweathermap_base_url &lt;- 'https://api.openweathermap.org/data/2.5'\n\nopenweathermap_api_key=key_get(\"openweathermap_api_key\")\n\ncity='Bangkok'\n\nopenweathermap_response_link &lt;- request(openweathermap_base_url) |&gt; \n  req_url_path_append(\n    paste0('weather?q=',city,'&appid=',openweathermap_api_key,'&units=metric')\n  ) \n\nopenweathermap_response_link\n\n\n\n\nCode\nopenweathermap_response=openweathermap_response_link|&gt; req_perform()\nopenweathermap_response"
  },
  {
    "objectID": "posts/api_with_httr2/index.html#get-data-from-response",
    "href": "posts/api_with_httr2/index.html#get-data-from-response",
    "title": "使用R httr2 调用API",
    "section": "get data from response",
    "text": "get data from response\n\n\nCode\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  glimpse()\n\n\n\n\nCode\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('main', 'temp') \n\na=openweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('weather') \n\n(a[[1]])$main\n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('name') \n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('coord', 'lon') \n\nopenweathermap_response |&gt; \n  resp_body_json() |&gt; \n  pluck('coord', 'lat') \n\n\nLondon air_pollution:\nhttp://api.openweathermap.org/data/2.5/air_pollution?lat=51.5085&lon=-0.1257&appid=625ae405e4f11b5b957af484b77fbd62"
  },
  {
    "objectID": "posts/edit video/index.html",
    "href": "posts/edit video/index.html",
    "title": "剪切视频/音频",
    "section": "",
    "text": "A guide to video and audio editing in R, covering tasks like checking and changing resolution, length, and size, as well as cropping and converting formats.\nvideo/audio editing include change resolution and length\nThis document provides a comprehensive guide to video and audio editing using R, with a focus on the av package. It covers a wide range of tasks, from basic checks like determining video resolution and length to more advanced operations like changing video resolution, trimming video length, cropping, and converting video to images or audio-only formats. The audio section demonstrates how to manipulate MP3 files, including changing their length and converting them to WAV format.\nOriginal video:"
  },
  {
    "objectID": "posts/edit video/index.html#check-video-resolution",
    "href": "posts/edit video/index.html#check-video-resolution",
    "title": "剪切视频/音频",
    "section": "check video resolution",
    "text": "check video resolution\n\n\nCode\nget_video_resolution_ffmpeg &lt;- function(file_path) {\n  if (!file.exists(file_path)) {\n    stop(\"File does not exist.\")\n  }\n  # Run ffmpeg command and capture output\n  cmd &lt;- sprintf(\"ffmpeg -i %s 2&gt;&1\", shQuote(normalizePath(file_path)))\n  output &lt;- system(cmd, intern = TRUE, ignore.stderr = FALSE)\n  # Find the line containing video stream details\n  video_line &lt;- grep(\"Video:\", output, value = TRUE)\n  if (length(video_line) == 0) {\n    stop(\"No video stream found.\")\n  }\n  # Extract resolution using regex (e.g., 1920x1080)\n  resolution &lt;- regmatches(video_line, regexpr(\"\\\\d{3,}x\\\\d{3,}\", video_line))\n  if (length(resolution) == 0) {\n    stop(\"Resolution not detected.\")\n  }\n  dimensions &lt;- as.numeric(strsplit(resolution, \"x\")[[1]])\n  return(dimensions)\n}\n\n\n\n\nCode\nresolution &lt;- get_video_resolution_ffmpeg(\"demo.mp4\")\ncat(sprintf(\"Resolution: %dx%d\", resolution[1], resolution[2]))\n\n\nResolution: 960x720"
  },
  {
    "objectID": "posts/edit video/index.html#check-video-length-and-size",
    "href": "posts/edit video/index.html#check-video-length-and-size",
    "title": "剪切视频/音频",
    "section": "check video length and size",
    "text": "check video length and size\n\n\nCode\nvideo_info &lt;- av::av_media_info(\"demo.mp4\")\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 30.02501\n\n\nCode\nvideo_size_mb &lt;- file.info(\"demo.mp4\")$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 1.029325"
  },
  {
    "objectID": "posts/edit video/index.html#change-video-resolution",
    "href": "posts/edit video/index.html#change-video-resolution",
    "title": "剪切视频/音频",
    "section": "change video resolution",
    "text": "change video resolution\n\n\nCode\n# Input video file path\ninput_video &lt;- \"demo.mp4\"\n\n# Output video file path\noutput_video &lt;- \"demo_resolution.mp4\"\n\n# Desired width and height\nnew_width &lt;- 960/3*2\nnew_height &lt;- 720/3*2\n\n# Construct the FFmpeg command for resizing\nffmpeg_command &lt;- paste0(\n  \"ffmpeg -i '\", input_video, \"' -vf scale=\", new_width, \":\", new_height, \" '\", output_video, \"'\"\n)\n\n# Execute the FFmpeg command\nsystem(ffmpeg_command)\n\ncat(\"Video resized to\", new_width, \"x\", new_height, \"and saved to\", output_video, \"\\n\")\n\n\nVideo resized to 640 x 480 and saved to demo_resolution.mp4 \n\n\nVideo after change resolution:\n\n\n\nCode\nresolution &lt;- get_video_resolution_ffmpeg(output_video)\ncat(sprintf(\"Resolution: %dx%d\", resolution[1], resolution[2]))\n\n\nResolution: 640x480\n\n\n\n\nCode\nvideo_info &lt;- av::av_media_info(output_video)\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 30.02501\n\n\nCode\nvideo_size_mb &lt;- file.info(output_video)$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 0.72155"
  },
  {
    "objectID": "posts/edit video/index.html#change-length-of-video",
    "href": "posts/edit video/index.html#change-length-of-video",
    "title": "剪切视频/音频",
    "section": "change length of video",
    "text": "change length of video\n\n\nCode\n# Define input/output files and timestamps\ninput_file &lt;- \"demo.mp4\"\n\n# Define input and output file paths\ninput_video &lt;- \"demo.mp4\"\noutput_video &lt;- \"demo_change_length.mp4\"\n\n# --- Example 1: Trimming from the beginning ---\nstart_time &lt;- \"00:00:05\" # Start at 5 seconds\nduration &lt;- \"00:00:10\"  # Keep for 10 seconds\n\ncommand_trim &lt;- sprintf(\"ffmpeg -i %s -ss %s -t %s  %s\",\n                        input_video, start_time, duration, output_video)\n\n#command_trim\nsystem(command_trim)\ncat(paste(\"Trimmed video saved to:\", output_video, \"\\n\"))\n\n\nTrimmed video saved to: demo_change_length.mp4 \n\n\nVideo after change length:\n\n\n\nCode\nvideo_info &lt;- av::av_media_info(\"demo_change_length.mp4\")\nvideo_length &lt;- video_info$duration\ncat(\"video length:\",video_length)\n\n\nvideo length: 10\n\n\nCode\nvideo_size_mb &lt;- file.info(\"demo_change_length.mp4\")$size / (1024^2)\ncat(\"video size in mb:\",video_size_mb)\n\n\nvideo size in mb: 0.275506"
  },
  {
    "objectID": "posts/edit video/index.html#video-crop",
    "href": "posts/edit video/index.html#video-crop",
    "title": "剪切视频/音频",
    "section": "video Crop",
    "text": "video Crop\n\n\nCode\n# Define the path to the input video file\ninput_video_path &lt;- \"demo.mp4\"  # Replace with your video file path\n\n# Define the path to save the cropped video\noutput_video_path &lt;- \"demo_crop.mp4\"  # Replace with your desired output path\n\n# Define crop parameters\ncrop_width &lt;- 640   # Desired width of the cropped video\ncrop_height &lt;- 360  # Desired height of the cropped video\ncrop_x &lt;- 100       # X offset for cropping\ncrop_y &lt;- 50        # Y offset for cropping\n\n# Define the crop filter\ncrop_filter &lt;- sprintf(\"crop=%d:%d:%d:%d\", crop_width, crop_height, crop_x, crop_y)\n\n# Crop the video\nav::av_encode_video(\n  input = input_video_path,\n  output = output_video_path,\n  vfilter = crop_filter,\n  audio=input_video_path\n)\n\n\n[1] \"/Users/jinchaoduan/Documents/Project/Tech-blog/posts/edit video/demo_crop.mp4\"\n\n\nCode\ncat(\"Video cropped successfully and saved to:\", output_video_path, \"\\n\")\n\n\nVideo cropped successfully and saved to: demo_crop.mp4 \n\n\nVideo after crop:"
  },
  {
    "objectID": "posts/edit video/index.html#changing-length-of-mp3",
    "href": "posts/edit video/index.html#changing-length-of-mp3",
    "title": "剪切视频/音频",
    "section": "Changing length of mp3",
    "text": "Changing length of mp3\n\n\nCode\nvideo_info=av::av_media_info(\"demo.mp3\" )\nvideo_info$duration\n\n\n[1] 30.04082\n\n\n\n\n\nCode\npcm_data &lt;- read_audio_bin(\"demo.mp3\" , channels = 1, end_time = 2.0)\nplot(pcm_data, type = 'l')\n\n\n\n\n\n\n\n\n\n\n\nCode\nstart_time &lt;- 2 # Start at 1 seconds\ntotal_time &lt;- 4  # Keep for 10 seconds\n\nav_audio_convert(audio=\"demo.mp3\",output=\"demo_cut.mp3\",start_time=start_time,total_time=total_time)\n\n\n[1] \"/Users/jinchaoduan/Documents/Project/Tech-blog/posts/edit video/demo_cut.mp3\"\n\n\n\n\nCode\nvideo_info=av::av_media_info(\"demo_cut.mp3\")\nvideo_info$duration\n\n\n[1] 4.101224"
  },
  {
    "objectID": "posts/edit video/index.html#convert-mp3-to-wav",
    "href": "posts/edit video/index.html#convert-mp3-to-wav",
    "title": "剪切视频/音频",
    "section": "convert mp3 to wav",
    "text": "convert mp3 to wav"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html",
    "href": "posts/data_transfer_with_pin/index.html",
    "title": "使用R pin数据传输",
    "section": "",
    "text": "A guide to using the pins package in R for data transfer and version control between local and online storage.\nThis document provides a comprehensive guide to using the pins package in R for efficient data transfer and version control. It demonstrates how to set up and use both local and online boards (with OneDrive as an example) to store and retrieve data and other files. The guide covers essential pins functions for uploading, downloading, listing, and managing different versions of your data, making it a valuable resource for creating reproducible and collaborative data science workflows.\nThe pins package is used for uploading and downloading data/models to online drives.\nCode\npak::pkg_install(\"pins\")\nCode\nlibrary(pins)\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#use-local-location-as-a-board",
    "href": "posts/data_transfer_with_pin/index.html#use-local-location-as-a-board",
    "title": "使用R pin数据传输",
    "section": "use local location as a board",
    "text": "use local location as a board\n\n\nCode\nboard=board_folder(getwd())\n\n\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-to-local-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-to-local-board",
    "title": "使用R pin数据传输",
    "section": "upload to local board",
    "text": "upload to local board\n\n\nCode\nboard %&gt;% pin_write(head(mtcars), \"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-from-local-board",
    "href": "posts/data_transfer_with_pin/index.html#download-from-local-board",
    "title": "使用R pin数据传输",
    "section": "download from local board",
    "text": "download from local board\n\n\nCode\na=board %&gt;% pin_read(\"mtcars\")\na"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-file-to-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-file-to-board",
    "title": "使用R pin数据传输",
    "section": "upload file to board",
    "text": "upload file to board\n\n\nCode\nboard %&gt;% pin_upload('thumbnail.jpg','new.thumbnail.jpg')"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#list-file-in-the-board",
    "href": "posts/data_transfer_with_pin/index.html#list-file-in-the-board",
    "title": "使用R pin数据传输",
    "section": "list file in the board",
    "text": "list file in the board\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-file-from-board",
    "href": "posts/data_transfer_with_pin/index.html#download-file-from-board",
    "title": "使用R pin数据传输",
    "section": "download file from board",
    "text": "download file from board\n\n\nCode\nboard %&gt;% pin_download('new.thumbnail.jpg')"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#one-drive-as-as-a-board",
    "href": "posts/data_transfer_with_pin/index.html#one-drive-as-as-a-board",
    "title": "使用R pin数据传输",
    "section": "one drive as as a board",
    "text": "one drive as as a board\n\n\nCode\nod &lt;- Microsoft365R::get_personal_onedrive()\nboard365 &lt;- board_ms365(od, \"myboard\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#upload-to-one-drive-board",
    "href": "posts/data_transfer_with_pin/index.html#upload-to-one-drive-board",
    "title": "使用R pin数据传输",
    "section": "upload to one drive board",
    "text": "upload to one drive board\n\n\nCode\nboard365 %&gt;% pin_write(tail(mtcars), \"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-from-one-drive-board",
    "href": "posts/data_transfer_with_pin/index.html#download-from-one-drive-board",
    "title": "使用R pin数据传输",
    "section": "download from one drive board",
    "text": "download from one drive board\n\n\nCode\nboard365 %&gt;% pin_read(\"mtcars\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#list-file-in-the-board-1",
    "href": "posts/data_transfer_with_pin/index.html#list-file-in-the-board-1",
    "title": "使用R pin数据传输",
    "section": "list file in the board",
    "text": "list file in the board\n\n\nCode\nboard %&gt;% pin_list()"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#there-will-be-two-version",
    "href": "posts/data_transfer_with_pin/index.html#there-will-be-two-version",
    "title": "使用R pin数据传输",
    "section": "there will be two version",
    "text": "there will be two version\n\n\nCode\nboard %&gt;% pin_versions(\"mtcars_version\")"
  },
  {
    "objectID": "posts/data_transfer_with_pin/index.html#download-version-file-from-board",
    "href": "posts/data_transfer_with_pin/index.html#download-version-file-from-board",
    "title": "使用R pin数据传输",
    "section": "download version file from board",
    "text": "download version file from board\n\n\nCode\n# board %&gt;% pin_read(\"mtcars_version\",version = '20230704T095208Z-8df40')\nboard %&gt;% pin_read(\"mtcars_version\",version = .Last.value$version[[1]])"
  },
  {
    "objectID": "posts/Rpackage/index.html",
    "href": "posts/Rpackage/index.html",
    "title": "R pacakge download and managment tool",
    "section": "",
    "text": "A guide to R package management using the pak and cranlogs packages, covering installation, version checking, and analyzing download statistics.\nThis document provides a comprehensive guide to R package management, focusing on the pak and cranlogs packages. It demonstrates how to use pak for installing, updating, and managing packages from various sources, including CRAN, GitHub, and local files. The guide also covers how to use cranlogs to analyze package download statistics and retrieve information about packages from GitHub. Additionally, it briefly mentions other useful tools for building R packages.\npak installs R packages from CRAN, Bioconductor, GitHub, URLs, git repositories, local files and directories. It is an alternative to install.packages() and devtools::install_github(). pak is fast, safe and convenient."
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pak",
    "href": "posts/Rpackage/index.html#install-pak",
    "title": "R pacakge download and managment tool",
    "section": "install pak",
    "text": "install pak\n\n\nCode\ninstall.packages(\"pak\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#load-pak",
    "href": "posts/Rpackage/index.html#load-pak",
    "title": "R pacakge download and managment tool",
    "section": "load pak",
    "text": "load pak\n\n\nCode\nlibrary(pak)"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-pak-version",
    "href": "posts/Rpackage/index.html#check-pak-version",
    "title": "R pacakge download and managment tool",
    "section": "check pak version",
    "text": "check pak version\n\n\nCode\npak_sitrep()"
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pacakge-from-cran",
    "href": "posts/Rpackage/index.html#install-pacakge-from-cran",
    "title": "R pacakge download and managment tool",
    "section": "install pacakge from cran",
    "text": "install pacakge from cran\n\n\nCode\npkg_install(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#install-pacakge-file-tar.gz-from-website",
    "href": "posts/Rpackage/index.html#install-pacakge-file-tar.gz-from-website",
    "title": "R pacakge download and managment tool",
    "section": "install pacakge file tar.gz from website",
    "text": "install pacakge file tar.gz from website\n\n\nCode\npkg_install(\n  \"url::https://cran.r-project.org/src/contrib/Archive/tibble/tibble_3.1.7.tar.gz\"\n)"
  },
  {
    "objectID": "posts/Rpackage/index.html#uninstall-package",
    "href": "posts/Rpackage/index.html#uninstall-package",
    "title": "R pacakge download and managment tool",
    "section": "uninstall package",
    "text": "uninstall package\n\n\nCode\npkg_remove(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-package",
    "href": "posts/Rpackage/index.html#check-package",
    "title": "R pacakge download and managment tool",
    "section": "check package",
    "text": "check package\n\n\nCode\npkg_deps_tree(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#show-all-dependencies",
    "href": "posts/Rpackage/index.html#show-all-dependencies",
    "title": "R pacakge download and managment tool",
    "section": "show all Dependencies",
    "text": "show all Dependencies\n\n\nCode\npkg_deps(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#explain-dependencies",
    "href": "posts/Rpackage/index.html#explain-dependencies",
    "title": "R pacakge download and managment tool",
    "section": "Explain dependencies",
    "text": "Explain dependencies\n\n\nCode\npkg_deps_explain(\"tibble\", \"rlang\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#check-pacakge-history-on-cran",
    "href": "posts/Rpackage/index.html#check-pacakge-history-on-cran",
    "title": "R pacakge download and managment tool",
    "section": "check pacakge history on cran",
    "text": "check pacakge history on cran\n\n\nCode\npkg_history(\"tibble\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#update-package",
    "href": "posts/Rpackage/index.html#update-package",
    "title": "R pacakge download and managment tool",
    "section": "update package",
    "text": "update package\n\n\nCode\npkg_install(\"tibble\")\n\n\nUpdate all dependencies of a package\n\n\nCode\npkg_install(\"tibble\", upgrade = TRUE)"
  },
  {
    "objectID": "posts/Rpackage/index.html#total-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#total-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "total pacakge download from last week",
    "text": "total pacakge download from last week\n\n\nCode\nlibrary(cranlogs)\ncran_downloads(when = \"last-week\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#total-pacakge-download-from-2014",
    "href": "posts/Rpackage/index.html#total-pacakge-download-from-2014",
    "title": "R pacakge download and managment tool",
    "section": "total pacakge download from 2014",
    "text": "total pacakge download from 2014\n\n\nCode\ndata=cran_downloads(from = \"2014-01-01\", to = \"2024-12-31\")\nlibrary(plotly)\nplot_ly(data, x = ~date, y = ~count, mode = \"lines\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#top-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#top-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "top pacakge download from last week",
    "text": "top pacakge download from last week\n\n\nCode\ncran_top_downloads(\"last-week\")"
  },
  {
    "objectID": "posts/Rpackage/index.html#one-pacakge-download-from-last-week",
    "href": "posts/Rpackage/index.html#one-pacakge-download-from-last-week",
    "title": "R pacakge download and managment tool",
    "section": "one pacakge download from last week",
    "text": "one pacakge download from last week\n\n\nCode\npacakge_name=\"tibble\"\nlastweek=cran_downloads(when = \"last-week\", package = pacakge_name)\nlastweek\n\n\n\n\nCode\nprint(paste(pacakge_name,\"last week been downloaded\",sum(lastweek$count),\"times\"))"
  },
  {
    "objectID": "posts/git/index.html",
    "href": "posts/git/index.html",
    "title": "使用git代码版本管理",
    "section": "",
    "text": "A quick reference guide for essential Git commands, covering basic to advanced operations.\nThis document serves as a quick reference guide for essential Git commands, providing a comprehensive overview of basic to advanced operations. It covers everything from initializing a repository and managing branches to committing changes and interacting with remote repositories. This guide is designed to be a helpful resource for both beginners and experienced users who need a quick reminder of Git’s powerful features.\n\ndownload github desktop\nhttps://desktop.github.com/download/\n\n\nset up github account\nhttps://github.com/\n\n\nClone a repository into a new directory\ngit clone \n\n\nInitialize a new Git repository\ngit init\n\n\nAdd to the staging area\ngit add  git add .\n\n\nCommit changes to the repository\ngit commit -m “commit message”\n\n\nView the commit history\ngit log\n\n\nCheck the status of changes\ngit status\n\n\nShow the changes in the working directory\ngit diff\n\n\nCreate a new branch\ngit branch \n\n\nList all branches\ngit branch\n\n\nSwitch to a different branch\ngit checkout \n\n\nCreate and switch to a new branch\ngit checkout -b \n\n\nMerge a branch into the current branch\ngit merge \n\n\nchanges from a remote repository\ngit pull\n\n\nPush changes to a remote repository\ngit push\n\n\nDelete a branch\ngit branch -d  git push origin –delete \n\n\nStash changes\ngit stash\n\n\nApply stashed changes\ngit stash apply\n\n\nShow stashed changes\ngit stash list\n\n\nRemove a file from the staging area\ngit reset \n\n\nreset to the last commit with commit id but keep your actual file unchange\ngit reset –soft HEAD~1\n\n\nreset to the last commit with commit id\ngit reset –hard e4a59dd6b356b93f914db2a2a253dc55582bd61e"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tech blog",
    "section": "",
    "text": "Sheet 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvert file like pdf to markdown\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeather App with Streamlit\n\n\n\n\n\n\nAI\n\nPython\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Gemini CLI\n\n\nYour AI assistant in the terminal\n\n\n\nTool\n\nAI\n\nCLI\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nKimi2 with openrouter\n\n\n\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nJul 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nGithub trend\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nJul 10, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n多语言 quarto blog\n\n\nbabelquarto\n\n\n\nquarto\n\n\n\n\n\n\n\n\n\nJul 3, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n剪切视频/音频\n\n\nvideo/audio editing\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMay 5, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n世界GDP\n\n\nGlobal GDP\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n挪威养老基金\n\n\nNorway The Government Pension Fund Global\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nAI图片识别文字\n\n\nAI Optical character recognition\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 21, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n数据星期二\n\n\nTidyTuesday\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 10, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n表格展示\n\n\nDisplay table\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用代码发邮件\n\n\nUsing code to send email\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用AI给播客语音转文字并作摘要\n\n\nUsing AI to create Summary for podcast\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n路径管理\n\n\nPath management\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 27, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用AI给视频自动生成中英文字幕\n\n\nUsing AI to create Chinese and English Subtitles\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 27, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n密码管理\n\n\nPassword management\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n正则表达式代码\n\n\nregular expression\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用git代码版本管理\n\n\nUsing git for version control\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 25, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nDocker使用介绍\n\n\nDocker intro\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nLinux系统操作代码\n\n\nLinux command\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n调用网络端AI模型\n\n\nRun AI model online\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n本地运行AI模型\n\n\nRun AI model on local machine\n\n\n\nAI\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n（LLM）大语言模型\n\n\n(LLM)Large language model\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 18, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nMake QR code\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 16, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nR code optimization with lintr and styler\n\n\n\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nAI Code assistant\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用R httr2 调用API\n\n\nUsing R httr2 to call API\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用R pin数据传输\n\n\nFor data transfer between local and cloud\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nPython code optimization with ruff\n\n\n\n\n\n\nTool\n\nPython\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nVersion control for Python with uv\n\n\n\n\n\n\nTool\n\nPython\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nR pacakge download and managment tool\n\n\n\n\n\n\nTool\n\nR\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nCPU and GPU\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nClassification Metrics\n\n\n\n\n\n\nMachine learning\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\n使用iphone或ipad下载youtube\n\n\n\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping in R with rvest\n\n\n\n\n\n\nTool\n\nWebscrap\n\nR\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping in Python\n\n\n\n\n\n\nTool\n\nWebscrap\n\nPython\n\n\n\n\n\n\n\n\n\nMar 12, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nSubscribe to a YouTube channel via email\n\n\n\n\n\n\nTool\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nVersion control with renv\n\n\n\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nYoutube下载工具：yt-dlp\n\n\nYoutube download tool:yt-dlp\n\n\n\nTool\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nTony D\n\n\n\n\n\n\n\n\n\n\n\n\nUseful resource\n\n\n\n\n\n\nnews\n\nresource\n\n\n\n\n\n\n\n\n\nMar 1, 2025\n\n\nTony D\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n\n\n\n\n \n\n\nSheet 1\n\n\n \n\n\n\n\n\n\nJul 24, 2025\n\n\nConvert file like pdf to markdown\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nWeather App with Streamlit\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nIntroduction to Gemini CLI\n\n\nTony D\n\n\n\n\n\n\nJul 18, 2025\n\n\nKimi2 with openrouter\n\n\nTony D\n\n\n\n\n\n\nJul 10, 2025\n\n\nGithub trend\n\n\nTony D\n\n\n\n\n\n\nJul 3, 2025\n\n\n多语言 quarto blog\n\n\nTony D\n\n\n\n\n\n\nMay 5, 2025\n\n\n剪切视频/音频\n\n\nTony D\n\n\n\n\n\n\nApr 24, 2025\n\n\n世界GDP\n\n\nTony D\n\n\n\n\n\n\nApr 24, 2025\n\n\n挪威养老基金\n\n\nTony D\n\n\n\n\n\n\nApr 21, 2025\n\n\nAI图片识别文字\n\n\nTony D\n\n\n\n\n\n\nApr 10, 2025\n\n\n数据星期二\n\n\nTony D\n\n\n\n\n\n\nApr 7, 2025\n\n\n表格展示\n\n\nTony D\n\n\n\n\n\n\nMar 31, 2025\n\n\n使用代码发邮件\n\n\nTony D\n\n\n\n\n\n\nMar 28, 2025\n\n\n使用AI给播客语音转文字并作摘要\n\n\nTony D\n\n\n\n\n\n\nMar 27, 2025\n\n\n路径管理\n\n\nTony D\n\n\n\n\n\n\nMar 27, 2025\n\n\n使用AI给视频自动生成中英文字幕\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\n密码管理\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\n正则表达式代码\n\n\nTony D\n\n\n\n\n\n\nMar 25, 2025\n\n\n使用git代码版本管理\n\n\nTony D\n\n\n\n\n\n\nMar 24, 2025\n\n\nDocker使用介绍\n\n\nTony D\n\n\n\n\n\n\nMar 24, 2025\n\n\nLinux系统操作代码\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\n调用网络端AI模型\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\n本地运行AI模型\n\n\nTony D\n\n\n\n\n\n\nMar 18, 2025\n\n\n（LLM）大语言模型\n\n\nTony D\n\n\n\n\n\n\nMar 16, 2025\n\n\nMake QR code\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\nR code optimization with lintr and styler\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\nAI Code assistant\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\n使用R httr2 调用API\n\n\nTony D\n\n\n\n\n\n\nMar 15, 2025\n\n\n使用R pin数据传输\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nPython code optimization with ruff\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nVersion control for Python with uv\n\n\nTony D\n\n\n\n\n\n\nMar 14, 2025\n\n\nR pacakge download and managment tool\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nCPU and GPU\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nClassification Metrics\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\n使用iphone或ipad下载youtube\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nWeb scraping in R with rvest\n\n\nTony D\n\n\n\n\n\n\nMar 12, 2025\n\n\nWeb scraping in Python\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nSubscribe to a YouTube channel via email\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nVersion control with renv\n\n\nTony D\n\n\n\n\n\n\nMar 11, 2025\n\n\nYoutube下载工具：yt-dlp\n\n\nTony D\n\n\n\n\n\n\nMar 1, 2025\n\n\nUseful resource\n\n\nTony D\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/gemini_cli/index.html",
    "href": "posts/gemini_cli/index.html",
    "title": "Introduction to Gemini CLI",
    "section": "",
    "text": "This post is an introduction to the Gemini CLI, a powerful tool that brings Google’s Gemini models to your command line interface."
  },
  {
    "objectID": "posts/gemini_cli/index.html#what-is-gemini-cli",
    "href": "posts/gemini_cli/index.html#what-is-gemini-cli",
    "title": "Introduction to Gemini CLI",
    "section": "What is Gemini CLI?",
    "text": "What is Gemini CLI?\nGemini CLI is a command-line interface that allows you to interact with Google’s Gemini large language models directly from your terminal. It’s designed for developers, data scientists, and anyone who wants to leverage the power of AI for their daily tasks without leaving the command line."
  },
  {
    "objectID": "posts/gemini_cli/index.html#key-features",
    "href": "posts/gemini_cli/index.html#key-features",
    "title": "Introduction to Gemini CLI",
    "section": "Key Features",
    "text": "Key Features\n\nDirect access to Gemini models: Interact with Gemini Pro and other models.\nCode generation and understanding: Ask for code snippets, get explanations of code, and even get help with debugging.\nFile system interaction: Gemini CLI can read your files, help you search for content, and even apply changes to your code.\nShell command execution: Run shell commands directly through the CLI.\nContext-aware: Gemini CLI can understand the context of your project and provide more relevant assistance."
  },
  {
    "objectID": "posts/gemini_cli/index.html#getting-started",
    "href": "posts/gemini_cli/index.html#getting-started",
    "title": "Introduction to Gemini CLI",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstallation\n(This is a hypothetical installation command)\nYou can install Gemini CLI using npm:\nnpm install -g @google/gemini-cli\n\n\nBasic Usage\nOnce installed, you can start a chat with Gemini CLI by running:\ngemini chat\nYou can ask it questions, ask it to write code, or ask it to perform tasks on your local file system.\nFor example, to list the files in the current directory, you can just ask: list files here\nTo read a file: read the file path/to/your/file.txt\nTo write a new file: write a new file named hello.txt with the content \"Hello, Gemini!\""
  },
  {
    "objectID": "posts/gemini_cli/index.html#use-cases",
    "href": "posts/gemini_cli/index.html#use-cases",
    "title": "Introduction to Gemini CLI",
    "section": "Use Cases",
    "text": "Use Cases\n\nRapid Prototyping: Quickly generate code for new ideas.\nLearning and Exploration: Get explanations for complex code or concepts.\nAutomation: Automate repetitive tasks by asking Gemini to write scripts.\nContent Creation: Draft emails, write documentation, or generate blog posts.\n\nGemini CLI is a versatile tool that can significantly boost your productivity. Explore its capabilities and integrate it into your workflow!"
  },
  {
    "objectID": "posts/gemini_cli/index.html#upgrading-the-gemini-cli",
    "href": "posts/gemini_cli/index.html#upgrading-the-gemini-cli",
    "title": "Introduction to Gemini CLI",
    "section": "Upgrading the Gemini CLI",
    "text": "Upgrading the Gemini CLI\nTo ensure you have the latest features and bug fixes, you can upgrade the package from time to time.\n\n\nCode\n# Upgrade the Gemini CLI to the latest version\nnpm upgrade -g @google/gemini-cli"
  },
  {
    "objectID": "posts/gemini_cli/index.html#login-with-your-google-account",
    "href": "posts/gemini_cli/index.html#login-with-your-google-account",
    "title": "Introduction to Gemini CLI",
    "section": "Login with Your Google Account",
    "text": "Login with Your Google Account\nYou can either log in with your Google Cloud account or use an API key.\n\nOption 1: Login with Google Cloud Account\n\n\nCode\n# Set your Google Cloud project ID\nexport GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"\n\n\nor save the GOOGLE_CLOUD_PROJECT into environment variable.So that do not need to re enter everytime\n\ncheck using zsh or bash\n\n\nCode\necho $SHELL\n\n\n\n\nfor zsh\n\n\nCode\necho 'export GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"' &gt;&gt; ~/.zshrc\n\nsource ~/.zshrc\n\n\n\n\nfor bash\n\n\nCode\necho 'export GOOGLE_CLOUD_PROJECT=\"your-google-cloud-project-id\"' &gt;&gt; ~/.bashrc\n\nsource ~/.bashrc\n\n\n\n\ncheck wheather added or not\n\n\nCode\necho $GOOGLE_CLOUD_PROJECT\n\n\n\n\n\nOption 2: Login with API Key\nAlternatively, you can use an API key for authentication.\n\n\nCode\n# Set your Gemini API key as an environment variable\nexport GEMINI_API_KEY=\"your-gemini-api-key\""
  },
  {
    "objectID": "posts/gemini_cli/index.html#set-the-location",
    "href": "posts/gemini_cli/index.html#set-the-location",
    "title": "Introduction to Gemini CLI",
    "section": "Set the Location",
    "text": "Set the Location\nYou also need to specify the Google Cloud location where your resources will be managed.\n\n\nCode\n# Set the Google Cloud location\nexport GOOGLE_CLOUD_LOCATION='us-central1'"
  },
  {
    "objectID": "posts/gemini_cli/index.html#memory-tool-save_memory",
    "href": "posts/gemini_cli/index.html#memory-tool-save_memory",
    "title": "Introduction to Gemini CLI",
    "section": "Memory Tool (save_memory)",
    "text": "Memory Tool (save_memory)\nThe tool appends the provided fact to a special GEMINI.md file located in the user’s home directory (~/.gemini/GEMINI.md). This file can be configured to have a different name.\nOnce added, the facts are stored under a ## Gemini Added Memories section. This file is loaded as context in subsequent sessions, allowing the CLI to recall the saved information.\n\n\nCode\nsave_memory(fact=\"R program code chunk in quarto:\n```{r}  \n  \n```\n\")\n\n\n\n\nCode\nsave_memory(fact=\"Python program code chunk in quarto:\n```{python}  \n  \n```\n\")\n\n\nview the saved memory file\n\n\nCode\ncat ~/.gemini/GEMINI.md\n\n\nor open with sublime text editor\n\n\nCode\necho 'export PATH=\"/Applications/Sublime Text.app/Contents/SharedSupport/bin:$PATH\"' &gt;&gt; ~/.zprofile\n\nsubl ~/.gemini/GEMINI.md"
  },
  {
    "objectID": "posts/kimi2/index.html",
    "href": "posts/kimi2/index.html",
    "title": "Kimi2 with openrouter",
    "section": "",
    "text": "OpenRouter is a platform that provides a unified API for accessing a wide variety of large language models (LLMs) from different providers like Anthropic, Google, and Meta. It simplifies the process of integrating and using these models for developers, offering a single point of access instead of managing multiple APIs and accounts\n\n\nget api key from https://openrouter.ai/\n\n\nload package\n\n\nCode\nfrom openai import OpenAI\nimport keyring\n\n\n\n\ndefine model\n\n\nCode\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=keyring.get_password(\"system\", \"openrouter\"),\n)\n\n\n\n\ncall model\n\n\nCode\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;YOUR_SITE_URL&gt;\", # Optional. Site URL for rankings on openrouter.ai.\n    \"X-Title\": \"&lt;YOUR_SITE_NAME&gt;\", # Optional. Site title for rankings on openrouter.ai.\n  },\n  extra_body={},\n  model=\"moonshotai/kimi-k2:free\",\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"What is the meaning of life?\"\n    }\n  ]\n)\n\n\n\n\nget result\n\n\nCode\nprint(completion.choices[0].message.content)"
  },
  {
    "objectID": "posts/Streamlit/index.html",
    "href": "posts/Streamlit/index.html",
    "title": "Weather App with Streamlit",
    "section": "",
    "text": "Streamlit is an open-source Python library designed for building interactive web applications for data science and machine learning projects.\nWith Streamlit, you can quickly create web apps to visualize data, share machine learning models, and interact with datasets—all using simple Python scripts.\nThis project is to create a website using python and streamlit weather APP example\nCity Weather App"
  },
  {
    "objectID": "posts/Streamlit/index.html#first-setup-virtual-environment-with-python-version-3.13-using-uv-and-add-package",
    "href": "posts/Streamlit/index.html#first-setup-virtual-environment-with-python-version-3.13-using-uv-and-add-package",
    "title": "Weather App with Streamlit",
    "section": "1. First setup virtual environment with python version 3.13 using uv and add package",
    "text": "1. First setup virtual environment with python version 3.13 using uv and add package\nuv init --python python3.13\nuv add streamlit pandas requests great_tables plotly"
  },
  {
    "objectID": "posts/Streamlit/index.html#download-data-from-api",
    "href": "posts/Streamlit/index.html#download-data-from-api",
    "title": "Weather App with Streamlit",
    "section": "2. Download data from API",
    "text": "2. Download data from API\npython script download_data.py to download weather forcast data from open-meteo.com. This script will be run by a github action every day.\n\n\nCode\nimport pandas as pd\nimport requests\nfrom datetime import date, timedelta\nimport concurrent.futures\n\ndef generate_weather_data(city_name, lat, lon):\n    \"\"\"\n    Fetches weather and air quality data for a given city.\n    \"\"\"\n    # 1. Define Date Range\n    today = date.today()\n    start_date = today - timedelta(days=7)\n    end_date = today + timedelta(days=7)\n\n    # 2. Fetch Weather and Rain Probability Data\n    weather_df = None\n    try:\n        weather_url = \"https://api.open-meteo.com/v1/forecast\"\n        params = {\n            \"latitude\": lat,\n            \"longitude\": lon,\n            \"daily\": \"weather_code,temperature_2m_max,temperature_2m_min,precipitation_probability_mean\",\n            \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n            \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n            \"timezone\": \"auto\"\n        }\n        resp_weather = requests.get(weather_url, params=params)\n        resp_weather.raise_for_status()\n        weather_data_raw = resp_weather.json()\n        \n        weather_df = pd.DataFrame(weather_data_raw['daily'])\n        weather_df = weather_df.rename(columns={\n            \"time\": \"date\",\n            \"temperature_2m_max\": \"temperature_max\",\n            \"temperature_2m_min\": \"temperature_min\",\n            \"precipitation_probability_mean\": \"rain_prob\"\n        })\n        weather_df['date'] = pd.to_datetime(weather_df['date'])\n        weather_df['day'] = weather_df['date'].dt.strftime('%a')\n\n        weather_mapping = {\n            0: \"Clear\", 1: \"Mainly Clear\", 2: \"Partly Cloudy\", 3: \"Overcast\",\n            45: \"Fog\", 48: \"Rime Fog\", 51: \"Light Drizzle\", 53: \"Drizzle\", 55: \"Heavy Drizzle\",\n            56: \"Light Freezing Drizzle\", 57: \"Freezing Drizzle\", 61: \"Light Rain\", 63: \"Rain\",\n            65: \"Heavy Rain\", 66: \"Light Freezing Rain\", 67: \"Freezing Rain\", 71: \"Light Snow\",\n            73: \"Snow\", 75: \"Heavy Snow\", 77: \"Snow Grains\", 80: \"Light Showers\", 81: \"Showers\",\n            82: \"Heavy Showers\", 85: \"Light Snow Showers\", 86: \"Snow Showers\", 95: \"Thunderstorm\",\n            96: \"Thunderstorm with Hail\", 99: \"Heavy Thunderstorm with Hail\"\n        }\n        weather_df['weather'] = weather_df['weather_code'].map(weather_mapping)\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to fetch weather data for {city_name}: {e}\")\n        return None\n\n    # 3. Fetch Air Quality Data\n    aqi_df = None\n    try:\n        aqi_start_date = today - timedelta(days=7)\n        aqi_end_date = today\n        aqi_url = \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n        params = {\n            \"latitude\": lat,\n            \"longitude\": lon,\n            \"start_date\": aqi_start_date.strftime(\"%Y-%m-%d\"),\n            \"end_date\": aqi_end_date.strftime(\"%Y-%m-%d\"),\n            \"hourly\": \"pm2_5,us_aqi\",\n            \"timezone\": \"auto\"\n        }\n        resp_aqi = requests.get(aqi_url, params=params)\n        resp_aqi.raise_for_status()\n        aqi_data_raw = resp_aqi.json()\n        \n        if 'hourly' in aqi_data_raw:\n            aqi_df = pd.DataFrame(aqi_data_raw['hourly'])\n            aqi_df['date'] = pd.to_datetime(aqi_df['time']).dt.date\n            aqi_df = aqi_df.groupby('date').agg(\n                pm2_5=('pm2_5', 'median'),\n                us_aqi=('us_aqi', 'median')\n            ).reset_index()\n            aqi_df['date'] = pd.to_datetime(aqi_df['date'])\n\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to fetch AQI data for {city_name}: {e}\")\n\n    # 4. Combine and Process Data\n    combined_df = weather_df\n    if aqi_df is not None:\n        combined_df = pd.merge(combined_df, aqi_df, on=\"date\", how=\"left\")\n\n    combined_df['City'] = city_name\n    combined_df['lat'] = lat\n    combined_df['lon'] = lon\n    combined_df['forecast_flag'] = combined_df['date'].apply(lambda x: 'forecast' if x.date() &gt; today else 'current')\n    \n    def get_aqi_status(us_aqi):\n        if pd.isna(us_aqi):\n            return \"N/A\"\n        if us_aqi &lt;= 50:\n            return \"Good\"\n        if us_aqi &lt;= 100:\n            return \"Moderate\"\n        if us_aqi &lt;= 150:\n            return \"Unhealthy for Sensitive Groups\"\n        if us_aqi &lt;= 200:\n            return \"Unhealthy\"\n        if us_aqi &lt;= 300:\n            return \"Very Unhealthy\"\n        return \"Hazardous\"\n\n    if 'us_aqi' in combined_df.columns:\n        combined_df['us_aqi_status'] = combined_df['us_aqi'].apply(get_aqi_status)\n    else:\n        combined_df['us_aqi_status'] = \"N/A\"\n        combined_df['pm2_5'] = None\n        combined_df['us_aqi'] = None\n\n\n    return combined_df"
  },
  {
    "objectID": "posts/Streamlit/index.html#create-a-streamlit-app-to-display-the-plot-and-table",
    "href": "posts/Streamlit/index.html#create-a-streamlit-app-to-display-the-plot-and-table",
    "title": "Weather App with Streamlit",
    "section": "3. Create a streamlit app to display the plot and table",
    "text": "3. Create a streamlit app to display the plot and table\na streamlit app weather_app.py to display the weather with plotly and greate table\n\n\nCode\nimport pandas as pd\nimport streamlit as st\nfrom great_tables import GT, loc, style\nimport plotly.express as px\n\nst.set_page_config(layout=\"wide\")\n\n# Load the data\n@st.cache_data\ndef load_data():\n    return pd.read_csv(\"weather_data.csv\")\n\nweather_df = load_data()\n\n# City selection\ncities = weather_df[\"City\"].unique()\nselected_city = st.selectbox(\"Select a city\", cities)\n\n# Filter data for the selected city\ncity_df = weather_df[weather_df[\"City\"] == selected_city].reset_index(drop=True)\n\n@st.cache_data\ndef convert_df_to_csv(df):\n    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n    return df.to_csv(index=False).encode(\"utf-8\")\n\n\ncsv = convert_df_to_csv(city_df)\n\nst.download_button(\n    label=\"Download Weather Data (CSV)\",\n    data=csv,\n    file_name=f\"{selected_city}_weather_data.csv\",\n    mime=\"text/csv\",\n)\n\n\n# Display the Plotly chart\nst.header(\"Temperature Trend\")\nfig = px.line(city_df, x=\"date\", y=[\"temperature_max\", \"temperature_min\"], \n              labels={\"value\": \"Temperature (°C)\", \"variable\": \"Temperature Type\"},\n              title=\"Max and Min Daily Temperatures\")\nst.plotly_chart(fig, use_container_width=True)\n\n\n\n# Display the Great Table\nst.header(f\"Weather Forecast for {selected_city}\")\n\ngt = GT(city_df)\n\ngt = gt.tab_header(\n    title=f\"{selected_city}\",\n    subtitle=f\"Weather from {pd.to_datetime(city_df['date'].min()).strftime('%B %d')} to {pd.to_datetime(city_df['date'].max()).strftime('%B %d, %Y')}\"\n)\n\n# Color AQI status\naqi_colors = {\n    \"Good\": \"#90EE90\",\n    \"Moderate\": \"#FFFF00\",\n    \"Unhealthy for Sensitive Groups\": \"#FFA500\",\n    \"Unhealthy\": \"#FF0000\",\n    \"Very Unhealthy\": \"#800080\",\n    \"Hazardous\": \"#808080\"\n}\n\nfor status, color in aqi_colors.items():\n    gt = gt.tab_style(\n        style=style.fill(color=color),\n        locations=loc.body(\n            columns=\"us_aqi_status\",\n            rows=lambda df: df[\"us_aqi_status\"] == status\n        )\n    )\n\n\ngt = gt.data_color(\n    columns=[\"rain_prob\"],\n    domain=[50, 100],\n    palette=[\"#ffcdd2\", \"#f44336\"],\n    na_color=\"#FFFFFF00\"\n)\n\ngt = gt.fmt_number(columns=[\"temperature_max\", \"temperature_min\", \"pm2_5\", \"us_aqi\"], decimals=1)\ngt = gt.fmt_percent(columns=[\"rain_prob\"], scale_values=False, decimals=0)\n\ngt = gt.cols_label(\n    date=\"Date\",\n    day=\"Day\",\n    temperature_max=\"Max Temp (°C)\",\n    temperature_min=\"Min Temp (°C)\",\n    weather=\"Weather\",\n    rain_prob=\"Rain Probability\",\n    pm2_5=\"PM2.5\",\n    us_aqi=\"US AQI\",\n    us_aqi_status=\"AQI Status\"\n)\n\nst.html(gt._repr_html_())"
  },
  {
    "objectID": "posts/Streamlit/index.html#run-the-streamlit-app-using-github-action",
    "href": "posts/Streamlit/index.html#run-the-streamlit-app-using-github-action",
    "title": "Weather App with Streamlit",
    "section": "4. Run the streamlit app using github action",
    "text": "4. Run the streamlit app using github action\ngithub action to run the streamlit app: .github/workflows/schedule-email.yml. it run every day 6:00PM Beijing time (22:00 UTC).And it will also run when a new push to the main branch.\nname: Refresh weather data\n\non: \n  push:\n    branches:\n      - main\n  schedule:\n    - cron: '0 22 * * *' # 6:00 AM Beijing time is 22:00 UTC\n\njobs:\n  refresh-data:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version-file: \"pyproject.toml\"\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v6\n\n      - name: Install the project\n        run: uv sync --locked --all-extras --dev\n            \n      - name: Run data download script\n        run: uv run download_data.py\n\n      - name: Commit and push if it changed\n        run: |-\n          git config user.name \"Automated Publisher\"\n          git config user.email \"actions@users.noreply.github.com\"\n          git add -A\n          timestamp=$(date -u)\n          git commit -m \"Latest data: ${timestamp}\" || exit 0\n          git push"
  },
  {
    "objectID": "posts/intro_markitdown/index.html",
    "href": "posts/intro_markitdown/index.html",
    "title": "Convert file like pdf to markdown",
    "section": "",
    "text": "MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines\n\n\ninstall markitdown\ngit clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e 'packages/markitdown[all]'\n\n\nconvert xlsx to md\n\n\nCode\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"weight.xlsx\")\nprint(result.text_content)\n\n\n\n\nCode\nwith open(\"weight.md\", \"w\") as f:\n    f.write(result.text_content)\n\n\n\n\nconvert pdf to md\n\n\nCode\nfrom markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"Modern_intro_probability_statistics.pdf\")\n#print(result.text_content)\n\n\n\n\nCode\nwith open(\"Modern_intro_probability_statistics.md\", \"w\") as f:\n    f.write(result.text_content)\n\n\n\n\nconvert image to md with LLM model(currently only support Open AI)\nhttps://github.com/microsoft/markitdown/issues/1129\n\n\nCode\nfrom markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)\n\n\n\n\nreference:\nhttps://github.com/microsoft/markitdown"
  }
]