{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Classification Metrics\"\n",
        "\n",
        "author: \"Tony D\"\n",
        "date: \"2025-03-12\"\n",
        "categories: \n",
        "  - Machine learning\n",
        "  - R\n",
        "  - Python\n",
        "  \n",
        "image: \"image_14_4f4fc2cf7d.png\"\n",
        "---\n",
        "\n",
        "Classification Metrics Explained | Sensitivity, Precision, AUROC, & More\n",
        "\n",
        "\n",
        "# install pacakge"
      ],
      "id": "8b91cb12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "pip install -U scikit-learn\n",
        "pip install -U kaggle\n",
        "pip install -U kagglehub"
      ],
      "id": "a43ed24c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# load pacakge"
      ],
      "id": "ff1e1c8b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "#from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, roc_curve,\n",
        "    accuracy_score, f1_score, roc_auc_score,\n",
        "    average_precision_score, confusion_matrix,\n",
        "    precision_recall_curve\n",
        ")"
      ],
      "id": "64d8bf8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# download data from kaggle"
      ],
      "id": "d19b0b80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\n",
        "path = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "id": "7cff358f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "show data file under download folder"
      ],
      "id": "38b7f400"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.listdir(path)"
      ],
      "id": "61fb19c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# read data\n"
      ],
      "id": "21d59072"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(path+'/'+os.listdir(path)[0])\n",
        "df.head()"
      ],
      "id": "ff272adb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.Outcome.value_counts()"
      ],
      "id": "d5ea64b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# separate features from response\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']"
      ],
      "id": "5f2fc04c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# split data into test and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "id": "c9a3f1f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# initialize and train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)"
      ],
      "id": "9cee9c04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# predict on the test set and get the probas\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1] "
      ],
      "id": "e44b3783",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# quickly look at the distribution of the probas\n",
        "percentiles = np.percentile(y_pred_proba, [5, 25, 50, 75, 95])\n",
        "percentiles"
      ],
      "id": "635e9ef9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# confusion matrix"
      ],
      "id": "fc550318"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xticks([0.5, 1.5], ['No Diabetes', 'Diabetes'])\n",
        "plt.yticks([0.5, 1.5], ['No Diabetes', 'Diabetes'], va='center')\n",
        "plt.show()"
      ],
      "id": "4dd3e125",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# recall / sensitivity\n",
        "recall = recall_score(y_test, y_pred)\n",
        "recall"
      ],
      "id": "14ad3eb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# precision / positive predictive value\n",
        "precision = precision_score(y_test, y_pred)\n",
        "precision"
      ],
      "id": "9e5b52f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "specificity"
      ],
      "id": "e479e06a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "id": "98fb7aa4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# f1\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "f1"
      ],
      "id": "15bf3579",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get ROC curve values\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# get PR curve values\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# get areas under the curves\n",
        "auroc = roc_auc_score(y_test, y_pred_proba)\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)"
      ],
      "id": "13414e5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# plot both curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auroc:.2f}')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "ax2.plot(recall, precision, color='purple', lw=2, label=f'PR-AUC = {pr_auc:.2f}')\n",
        "ax2.set_xlabel('Recall')\n",
        "ax2.set_ylabel('Precision')\n",
        "ax2.set_title('Precision-Recall Curve')\n",
        "ax2.legend(loc=\"lower left\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "22e0be64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test.value_counts()"
      ],
      "id": "a36dc03e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reference\n",
        "\n",
        "https://www.youtube.com/watch?v=KdUrfY1yM0w\n",
        "\n",
        "https://github.com/RichardOnData/YouTube/blob/main/Python%20Notebooks/classification_metrics.ipynb\n"
      ],
      "id": "c42faf94"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Library/Frameworks/Python.framework/Versions/3.13/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}